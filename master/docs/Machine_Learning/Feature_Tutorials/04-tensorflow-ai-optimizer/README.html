


<!DOCTYPE HTML>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
	<head>
		<meta charset="utf-8">
		
		<meta http-equiv="content-type" content="text/html; charset=UTF-8"/>
		<link rel="stylesheet" href="https://static.cloud.coveo.com/searchui/v2.4382/css/CoveoFullSearch.css"/>
		<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
		<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
		<meta name="description"/>
		<meta name="keywords"/>
		<meta property="og:title" content=""/>
		<meta property="og:description"/>
		<!-- favicon -->
		<link rel="icon" type="image/vnd.microsoft.icon" href="../../../_static/favicon.ico"/>
		<link rel="shortcut icon" type="image/vnd.microsoft.icon" href="../../../_static/favicon.ico"/>
		<!-- Fonts -->
		<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500" rel="stylesheet" type="text/css"/>

  
  
  
  

  
      <script type="text/javascript" src="../../../_static/js/jquery.min.js"></script>
	  <script type="text/javascript" src="../../../_static/js/gtm.js"></script>
  <script type="text/javascript" src="../../../_static/js/modernizr.min.js"></script>
    <script type="text/javascript" src="../../../_static/js/d3dd8c60ed.js"></script>
    <script type="text/javascript" src="../../../_static/js/common-ui-all.min.js"></script>
    <script type="text/javascript" src="../../../_static/js/header-footer.min.js"></script>
    <script type="text/javascript" src="../../../_static/js/jquery-ui.min.js"></script>
    <script type="text/javascript" src="../../../_static/js/CoveoJsSearch.Lazy.min.js"></script>
    <script type="text/javascript" src="../../../_static/js/linkid.js"></script>
    <script type="text/javascript" src="../../../_static/js/Searchbox.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/common-ui-all.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/header-footer.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/pro.min.css" media="all" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
	</head>
	<body>
		<div class="xilinx-bs3"/>
		<div class="root responsivegrid">
			<div class="aem-Grid aem-Grid--16 aem-Grid--default--16 aem-Grid--large--16 aem-Grid--xlarge--16 aem-Grid--xxlarge--16 aem-Grid--xxxlarge--16 ">
				<div class="xilinxExperienceFragments experiencefragment aem-GridColumn aem-GridColumn--default--12">
					<div class="xf-content-height">
						<div class="aem-Grid aem-Grid--16 aem-Grid--default--16 ">
							<div class="header parbase aem-GridColumn aem-GridColumn--default--12">
								<noindex>
									<header data-component="header">
										<nav class="navbar navbar-default aem-Grid aem-Grid--16">
											<div class="aem-GridColumn aem-GridColumn--xxxlarge--none aem-GridColumn--xsmall--16 aem-GridColumn--offset--xsmall--0 aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--xsmall--none aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
												<div class="container-fluid main-nav">
													<div class="row">
														<div class="col-xs-12">
															<div class="logo-column">
																<div class="logo">
																	<a href="https://www.xilinx.com/">
																	<img src="https://www.xilinx.com/etc.clientlibs/site/clientlibs/xilinx/all/resources/imgs/header/xilinx-header-logo.svg" title="Xilinx Inc"/>
																	</a>
																</div>
															</div>
															<div class="navbar-column">
																<div class="navbar navbar-collapse collapse" id="xilinx-main-menu">
																	<div class="mobile-search-container">
																		<div id="headerSearchBox" class="headerSearch"
																			data-component="header-search"
																			data-redirect-if-empty="false"
																			data-coveo-access-token="xxa237d4dd-f0aa-47fc-9baa-af9121851b33"
																			data-coveo-organization-id="xilinxcomprode2rjoqok">
																			<div class='coveo-search-section'>
																				<div class="CoveoAnalytics" data-search-hub="Site"></div>
																				<ul class="dropdown-menu options">
																					<li class="option" data-label="All" data-action-link="https://www.xilinx.com/search/site-keyword-search.html" data-search-hub="Site">
																						<a href="#">
																						All</a>
																					</li>
																					<li data-label="Silicon Devices" data-action-link="https://www.xilinx.com//products/silicon-devices/si-keyword-search.html" data-search-hub="Product">
																						<a href="#">
																						Silicon Devices</a>
																					</li>
																					<li data-label="Boards and Kits" data-action-link="https://www.xilinx.com//products/boards-and-kits/bk-keyword-search.html" data-search-hub="Product">
																						<a href="#">
																						Boards and Kits</a>
																					</li>
																					<li data-label="Intellectual Property" data-action-link="https://www.xilinx.com//products/intellectual-property/ip-keyword-search.html" data-search-hub="Product">
																						<a href="#">
																						Intellectual Property</a>
																					</li>
																					<li data-label="Support" class="option" data-action-link="https://www.xilinx.com/search/support-keyword-search.html" data-search-hub="Support">
																						<a href="#">
																						Support</a>
																						<ul>
																							<li data-label="Documentation" data-action-link="https://www.xilinx.com//support/documentation-navigation/documentation-keyword-search.html" data-search-hub="Document">
																								<a href="#">
																								Documentation</a>
																							</li>
																							<li data-label="Knowledge Base" data-action-link="https://www.xilinx.com//support/answer-navigation/answer-keyword-search.html" data-search-hub="AnswerRecord">
																								<a href="#">
																								Knowledge Base</a>
																							</li>
																							<li data-label="Community Forums" data-action-link="https://www.xilinx.com/search/forums-keyword-search.html" data-search-hub="Forums">
																								<a href="#">
																								Community Forums</a>
																							</li>
																						</ul>
																					</li>
																					<li data-label="Partners" data-action-link="https://www.xilinx.com//alliance/member-keyword-search.html" data-search-hub="Partner">
																						<a href="#">
																						Partners</a>
																					</li>
																					<li data-label="Videos" data-action-link="https://www.xilinx.com/video/video-keyword-search.html" data-search-hub="Video">
																						<a href="#">
																						Videos</a>
																					</li>
																					<li data-label="Press" data-action-link="https://www.xilinx.com/search/press-keyword-search.html" data-search-hub="Press">
																						<a href="#">
																						Press</a>
																					</li>
																				</ul>
																				<a href="#" class="btn dropdown-toggle value" data-toggle="dropdown"></a>
																				<div class="CoveoSearchbox" data-id="coveosearchbox" data-action-link="https://www.xilinx.com/search/site-keyword-search.html" data-placeholder="Search Xilinx"></div>
																			</div>
																		</div>
																	</div>
																	<ul class="nav navbar-nav nav-justified">
																		<li class="accordion-toggle-icons" data-component="toggle-dropdown">
																			<a href="https://www.xilinx.com/applications.html">
																			Applications</a>
																		</li>
																		<li class="accordion-toggle-icons" data-component="toggle-dropdown">
																			<a href="https://www.xilinx.com/products/silicon-devices.html">
																			Products</a>
																		</li>
																		<li class="accordion-toggle-icons" data-component="toggle-dropdown">
																			<a href="https://developer.xilinx.com/">
																			Developers</a>
																		</li>
																		<li class="accordion-toggle-icons" data-component="toggle-dropdown">
																			<a href="https://www.xilinx.com/support.html">
																			Support</a>
																		</li>
																		<li class="accordion-toggle-icons" data-component="toggle-dropdown">
																			<a href="https://www.xilinx.com/about/company-overview.html">
																			About</a>
																		</li>
																	</ul>
																</div>
															</div>
															<script type="text/javascript" src="../../../_static/js/gtm.js"></script>
															<!--<div class="mini-nav">
																<button type="button" data-function="xilinx-mobile-menu" id="nav-toggle" class="navbar-toggle collapsed visible-xs-block" aria-expanded="false">
																<span></span>
																<span></span>
																<span></span>
																<span></span>
																</button>
																<ul class="list-inline">
																	<li class="dropdown user-menu">
																		<button data-toggle="dropdown">
																		<span class="sr-only">Account</span>
																		<span class="fas fa-user"></span>
																		</button>
																		<ul class="dropdown-menu">
																			<li>
																				<a href="https://www.xilinx.com/myprofile/subscriptions.html">
																				My Account</a>
																			</li>
																			<li>
																				<a href="https://www.xilinx.com/registration/create-account.html">
																				Create Account</a>
																			</li>
																			<li>
																				<a href="https://www.xilinx.com/bin/protected/en/signout">
																				Sign Out</a>
																			</li>
																		</ul>
																	</li>
																	<li class="hidden-xs">
																		<button data-function="search-toggle">
																		<span class="sr-only">Search</span>
																		<span class="far fa-search"></span>
																		</button>
																	</li>
																</ul>
															</div>
															-->
															<div class="search-container">
																<div id="headerSearchBox" class="headerSearch"
																	data-component="header-search"
																	data-redirect-if-empty="false"
																	data-coveo-access-token="xxa237d4dd-f0aa-47fc-9baa-af9121851b33"
																	data-coveo-organization-id="xilinxcomprode2rjoqok">
																	<div class='coveo-search-section'>
																		<div class="CoveoAnalytics" data-search-hub="Site"></div>
																		<ul class="dropdown-menu options">
																			<li class="option" data-label="All" data-action-link="https://www.xilinx.com/search/site-keyword-search.html" data-search-hub="Site">
																				<a href="#">
																				All</a>
																			</li>
																			<li data-label="Silicon Devices" data-action-link="https://www.xilinx.com/products/silicon-devices/si-keyword-search.html" data-search-hub="Product">
																				<a href="#">
																				Silicon Devices</a>
																			</li>
																			<li data-label="Boards and Kits" data-action-link="https://www.xilinx.com/products/boards-and-kits/bk-keyword-search.html" data-search-hub="Product">
																				<a href="#">
																				Boards and Kits</a>
																			</li>
																			<li data-label="Intellectual Property" data-action-link="https://www.xilinx.com/products/intellectual-property/ip-keyword-search.html" data-search-hub="Product">
																				<a href="#">
																				Intellectual Property</a>
																			</li>
																			<li data-label="Support" class="option" data-action-link="https://www.xilinx.com/search/support-keyword-search.html" data-search-hub="Support">
																				<a href="#">
																				Support</a>
																				<ul>
																					<li data-label="Documentation" data-action-link="https://www.xilinx.com/support/documentation-navigation/documentation-keyword-search.html" data-search-hub="Document">
																						<a href="#">
																						Documentation</a>
																					</li>
																					<li data-label="Knowledge Base" data-action-link="https://www.xilinx.com/support/answer-navigation/answer-keyword-search.html" data-search-hub="AnswerRecord">
																						<a href="#">
																						Knowledge Base</a>
																					</li>
																					<li data-label="Community Forums" data-action-link="https://www.xilinx.com/search/forums-keyword-search.html" data-search-hub="Forums">
																						<a href="#">
																						Community Forums</a>
																					</li>
																				</ul>
																			</li>
																			<li data-label="Partners" data-action-link="https://www.xilinx.com/alliance/member-keyword-search.html" data-search-hub="Partner">
																				<a href="#">
																				Partners</a>
																			</li>
																			<li data-label="Videos" data-action-link="https://www.xilinx.com/video/video-keyword-search.html" data-search-hub="Video">
																				<a href="#">
																				Videos</a>
																			</li>
																			<li data-label="Press" data-action-link="https://www.xilinx.com/search/press-keyword-search.html" data-search-hub="Press">
																				<a href="#">
																				Press</a>
																			</li>
																		</ul>
																		<a href="#" class="btn dropdown-toggle value" data-toggle="dropdown"></a>
																		<div class="CoveoSearchbox" data-id="coveosearchbox" data-action-link="https://www.xilinx.com/search/site-keyword-search.html" data-placeholder="Search Xilinx"></div>
																	</div>
																</div>
																<button data-function="search-toggle">
																<span class="sr-only">Search</span>
																<span class="far fa-times"></span>
																</button>
															</div>
														</div>
													</div>
												</div>
											</div>
										</nav>
									</header>
								</noindex>
							</div>
						</div>
					</div>
				</div>
				<div class="parsys aem-GridColumn--xxxlarge--none aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
						<div class="container-fluid">
							<div class="row">
							<div class="col-xs-12">
   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home" alt="Documentation Home"> Vitis In-Depth Tutorials
          

          
          </a>

          
            
            
              <div class="version">
                2020.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

      
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
            
            
            
              
            
            
              <p class="caption"><span class="caption-text">日本語版</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/Vitis-Tutorials/master/docs-jp/README.html">Master</a></li>
</ul>
<p class="caption"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Getting_Started/Vitis/README.html">Vitis Flow 101 Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Getting_Started/Vitis_HLS/README.html">Vitis HLS Analysis and Optimization</a></li>
</ul>
<p class="caption"><span class="caption-text">Machine Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../README.html">Introduction to Machine Learning with Vitis AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../README.html#design-tutorials">Design Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../README.html#feature-tutorials">Feature Tutorials</a></li>
</ul>
<p class="caption"><span class="caption-text">Acceleration</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Hardware_Accelerators/README.html">Introduction to Vitis Hardware Accelerators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Hardware_Accelerators/README.html#design-tutorials">Design Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Hardware_Accelerators/README.html#feature-tutorials">Feature Tutorials</a></li>
</ul>
<p class="caption"><span class="caption-text">AI Engine Development</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../AI_Engine_Development/README.html">AI Engine Development</a></li>
</ul>
<p class="caption"><span class="caption-text">Platform Creation Tutorial</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Vitis_Platform_Creation/README.html">Platform Creation</a></li>
</ul>
<p class="caption"><span class="caption-text">XRT and Vitis System Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/README.html">Xilinx Runtime (XRT) and Vitis System Optimization Tutorials</a></li>
</ul>
<p class="caption"><span class="caption-text">Versions</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/Vitis-Tutorials/2020-1/docs/README.html">2020.1</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/Xilinx/Vitis-Tutorials/blob/Vitis-Tutorials-2019.2-Hotfix1/README.md">2019.2</a></li>
</ul>

            
			
			<p class="caption"><span class="caption-text">This Page</span></p>
				<ul class="current">
				  <li class="toctree-l1"><a href="../../../_sources/Machine_Learning/Feature_Tutorials/04-tensorflow-ai-optimizer/README.md.txt"
						rel="nofollow">Show Source</a></li>
				</ul>
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Vitis In-Depth Tutorials</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Current Status</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../../_sources/Machine_Learning/Feature_Tutorials/04-tensorflow-ai-optimizer/README.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <!--
Copyright 2020 Xilinx Inc.
 
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0
 
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

Author: Mark Harvey, Xilinx Inc
--><table class="sphinxhide">
 <tr>
   <td align="center"><img src="https://www.xilinx.com/content/dam/xilinx/imgs/press/media-kits/corporate/xilinx-logo.png" width="30%"/><h1>Vitis AI Tutorials</h1>
  </td>
 </tr>
 <tr>
 <td align="center"><h1>TensorFlow AI Optimizer example using low-level coding style</h1>
 </td>
 </tr>
</table><div class="section" id="current-status">
<h1>Current Status<a class="headerlink" href="#current-status" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>Tested with Vitis-AI 1.3 and TensorFlow 1.15</p></li>
<li><p>Tested on ZCU102 evaluation board and Alveo U50 accelerator card</p></li>
</ul>
</div>
<div class="section" id="tutorial-overview">
<h1>Tutorial Overview<a class="headerlink" href="#tutorial-overview" title="Permalink to this headline">¶</a></h1>
<p>The Vitis-AI Optimizer can optimize convolutional neural networks (CNN) by exploiting redundancies and near-zero parameters to reduce the number of mathematical operations required to execute the network. This process is often known as ‘pruning’. The reduction of mathematical operations leads to several benefits:</p>
<ul class="simple">
<li><p>Increased throughput.</p></li>
<li><p>Reduced latency.</p></li>
<li><p>Reduced memory footprint of the compiled model.</p></li>
<li><p>Reduced number of accesses to memory.</p></li>
</ul>
<p>This tutorial will show you how to use AI Optimizer for TensorFlow to prune an AlexNet CNN by 80% whilst maintaining the original accuracy.</p>
<p>The scripts provided in this design will allow users to either run a complete pruning flow or to run a ‘baseline’ design without pruning. Having the baseline design is useful to provide a comparison of performance and accuracy with the pruned design.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">run_no_prune.sh</span></code> shell script creates the baseline design whereas <code class="docutils literal notranslate"><span class="pre">run_prune.sh</span></code> will prune the AlexNet design by approximately 80%. Users are invited to open both scripts with a text editor to get an idea of the differences between the two flows.</p>
<p>The remainder of this tutorial is dedicated to running the pruning flow.</p>
</div>
<div class="section" id="tensorflow-ai-optimizer-design-steps">
<h1>TensorFlow AI Optimizer design steps<a class="headerlink" href="#tensorflow-ai-optimizer-design-steps" title="Permalink to this headline">¶</a></h1>
<p>Pruning a CNN is an iterative process and requires an initial analysis phase in which the trained CNN is analysed using the test dataset and then is pruned in steps. The following diagrams summarize the complete TensorFlow AI Optimizer flow:</p>
<p align="center">
  <br><br>
  <img src="./img/steps_0_4.png">
  <b>Steps 0 to 4</b>
  <br><br>
  <br><br>
  <img src="./img/step_5.png">
  <b>Step 5</b>
  <br><br>
  <br><br>
  <img src="./img/steps_6_12.png">
  <b>Steps 6 to 12</b>
  <br><br>
</p><p>The numbering of the steps in the above flow diagrams correspond to the numbering of the paragraphs below and to the numbering the of the shell scripts. For example, step 4 -pruna analysis step in the diagram corresponds to the <a class="reference external" href="#step-4---run-pruning-analysis">Step 4 - Run Pruning Analysis</a> paragraph and to the <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">4_prune_analysis.sh</span></code> shell script.</p>
</div>
<div class="section" id="before-you-begin">
<h1>Before You Begin<a class="headerlink" href="#before-you-begin" title="Permalink to this headline">¶</a></h1>
<p>The host machine has several requirements that need to be met before we begin. You will need:</p>
<ul class="simple">
<li><p>A license for the AI Optimizer - contact your Xilinx sales representative to obtain one.</p></li>
<li><p>An x86 host machine with a supported OS and the GPU version of the Vitis-AI docker installed - see <a class="reference external" href="https://github.com/Xilinx/Vitis-AI/blob/master/docs/system_requirements.md">System Requirements</a>.</p></li>
<li><p>The host machine will require Docker to be installed and the Vitis-AI GPU docker image to be built - see <a class="reference external" href="https://github.com/Xilinx/Vitis-AI#getting-started">Getting Started</a>.</p></li>
<li><p>A GPU card suitable for ML training - a GPU with at least 8GB of memory is recommended.</p></li>
<li><p>If you plan to use the ZCU102 evaluation board, it should be prepared with the board image as per the <a class="reference external" href="https://github.com/Xilinx/Vitis-AI/tree/master/setup/mpsoc/VART#step2-setup-the-target">Setup the Target</a> instructions. Hints on how to connect the various cables to the ZCU102 are also available <a class="reference external" href="https://www.xilinx.com/html_docs/vitis_ai/1_3/installation.html#yjf1570690235238">here</a>.</p></li>
<li><p>For the Alveo U50, follow the <a class="reference external" href="https://github.com/Xilinx/Vitis-AI/tree/master/setup/alveo/u50_u50lv_u280#setup-alveo-accelerator-card-with-hbm-for-dpucahx8hl">Setup Alveo Accelerator Card with HBM for DPUCAHX8H/L</a> instructions. You will need to install the specified version of XRT on your host system (i.e. <em>not</em> in the Vitis-AI docker container), install the Alveo U50 card target platform also on your host system and then flash the Alveo U50 card. Note that a cold reboot will be necessary afer flashing the Alveo U50.</p></li>
</ul>
<p>For more details, refer to the latest version of the <em>Vitis AI User Guide</em> (<a class="reference external" href="https://www.xilinx.com/html_docs/vitis_ai/1_3/zmw1606771874842.html">UG1414</a>).</p>
<p>This tutorial assumes the user is familiar with Python3, TensorFlow and has some knowledge of machine learning principles.</p>
</div>
<div class="section" id="step-0-setting-up-the-workspace-dataset-and-ai-optimizer-license">
<h1>Step 0 - Setting up the workspace, dataset and AI Optimizer license<a class="headerlink" href="#step-0-setting-up-the-workspace-dataset-and-ai-optimizer-license" title="Permalink to this headline">¶</a></h1>
<ol>
<li><p>Copy the repository by doing either of the following:</p>
<ul class="simple">
<li><p>Download the repository as a ZIP file to the host machine, and then unzip the archive.</p></li>
<li><p>From a terminal, use the <code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">clone</span></code> command.</p></li>
</ul>
</li>
<li><p>Download the Kaggle dogs-vs-cats dataset.</p>
<ul class="simple">
<li><p>Go to the <a class="reference external" href="https://www.kaggle.com/c/dogs-vs-cats/data">Kaggle website</a> and register a new account if necessary.</p></li>
<li><p>Download the <a class="reference external" href="https://www.kaggle.com/c/dogs-vs-cats/data">dataset</a>.</p></li>
<li><p>Move dogs-vs-cats.zip into the <code class="docutils literal notranslate"><span class="pre">files</span></code> folder in the design repository, which is the same folder that contains the python (<code class="docutils literal notranslate"><span class="pre">.py</span></code>) and shell (<code class="docutils literal notranslate"><span class="pre">.sh</span></code>) scripts.</p></li>
</ul>
<p>The Kaggle dog-vs-cats dataset consists of 25,000 images of varying dimensions, divided into two classes: cat and dog. Each image is intrinsically labelled or classified in its filename (for example, <code class="docutils literal notranslate"><span class="pre">cat.12.jpg</span></code>).</p>
<p>There is a set of unlabelled images which were part of the original Kaggle dogs-vs-cats challenge, but we will not use it in this tutorial. Only the 25000 images that are contained in the <code class="docutils literal notranslate"><span class="pre">train.zip</span></code> archive will be used.</p>
</li>
<li><p>Place a copy of the AI Optimizer license file on your host machine - it needs to be placed under the ‘files’ folder so that it is visible to the Vitis-AI docker. The exact location is defined in the <code class="docutils literal notranslate"><span class="pre">0_setenv_pr.sh</span></code> script:</p></li>
</ol>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># Xilinx pruning licenses</span>
<span class="nb">export</span> <span class="nv">XILINXD_LICENSE_FILE</span><span class="o">=</span>AI_OPTIMIZER.lic
</pre></div>
</div>
<ol>
<li><p>Open a linux terminal, <code class="docutils literal notranslate"><span class="pre">cd</span></code> to the repository folder, and then <code class="docutils literal notranslate"><span class="pre">cd</span></code> to the <code class="docutils literal notranslate"><span class="pre">files</span></code> folder.</p></li>
<li><p>Start the Vitis AI GPU docker:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># navigate to densenet tutorial folder</span>
<span class="nb">cd</span> &lt;path_to_densenet_design&gt;/files

<span class="c1"># to start GPU docker container</span>
./docker_run.sh xilinx/vitis-ai-gpu:latest
</pre></div>
</div>
</li>
</ol>
<p>The docker container will start and after accepting the license agreement, you should see something like this in the terminal:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> ```shell
 ==========================================
 
 __      ___ _   _                   _____
 \ \    / (_) | (_)            /\   |_   _|
  \ \  / / _| |_ _ ___ ______ /  \    | |
   \ \/ / | | __| / __|______/ /\ \   | |
    \  /  | | |_| \__ \     / ____ \ _| |_
     \/   |_|\__|_|___/    /_/    \_\_____|
 
 ==========================================

 Docker Image Version:  1.3 
 Build Date: 2020-12-20
 VAI_ROOT: /opt/vitis_ai

 For TensorFlow Workflows do:
      conda activate vitis-ai-tensorflow 
 For Caffe Workflows do:
      conda activate vitis-ai-caffe 
 For Neptune Workflows do:
      conda activate vitis-ai-neptune 
 For PyTorch Workflows do:
      conda activate vitis-ai-pytorch 
 For TensorFlow 2.3 Workflows do:
      conda activate vitis-ai-tensorflow2 
 For Darknet Optimizer Workflows do:
      conda activate vitis-ai-optimizer_darknet 
 For Caffe Optimizer Workflows do:
      conda activate vitis-ai-optimizer_caffe 
 For TensorFlow 1.15 Workflows do:
      conda activate vitis-ai-optimizer_tensorflow 
 For LSTM Workflows do:
      conda activate vitis-ai-lstm 
 Vitis-AI /workspace &gt; 
 ```
</pre></div>
</div>
<blockquote>
<div><p>:bulb: If you get a “Permission Denied” error when starting the docker container, it is almost certainly because the docker_run.sh script is not set to be executable. You can fix this by running the following command:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span> chmod +x docker_run.sh
</pre></div>
</div>
</div></blockquote>
<p><em>The remainder of this tutorial shows a step-by-step pruning flow however users can just run the complete flow using <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">run_prune.sh</span></code> if they wish. The baseline flow can be run with <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">run_no_prune.sh</span></code></em></p>
<ol class="simple">
<li><p>Use <code class="docutils literal notranslate"><span class="pre">setenv</span></code> scripts to set up all the environment variables.</p></li>
</ol>
<p>To set up the environment variables used in pruning flow, run the environment setup script: <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">0_setenv_pr.sh</span></code>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">0_setenv_np.sh</span></code> script is only used in the non-pruning flow,</p>
<p>The <code class="docutils literal notranslate"><span class="pre">0_setenv_common.sh</span></code> is called by both <code class="docutils literal notranslate"><span class="pre">0_setenv_pr.sh</span></code> and <code class="docutils literal notranslate"><span class="pre">0_setenv_np.sh</span></code> and defines all the paths and names of files and directories that the user can edit (as required). It also defines the GPUs to be used, which might require modification to match the user’s system, such as:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="s2">&quot;0&quot;</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">0_setenv_common.sh</span></code> also defines some of the hyperparameters and users can also modify these as required:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">BATCHSIZE</span><span class="o">=</span><span class="m">250</span>
<span class="nb">export</span> <span class="nv">INIT_LR</span><span class="o">=</span><span class="m">0</span>.001
<span class="nb">export</span> <span class="nv">TRAIN_EPOCHS</span><span class="o">=</span><span class="m">200</span>
</pre></div>
</div>
</div>
<div class="section" id="step-1-convert-dataset-images-to-numpy-files">
<h1>Step 1 - Convert Dataset Images to numpy Files<a class="headerlink" href="#step-1-convert-dataset-images-to-numpy-files" title="Permalink to this headline">¶</a></h1>
<p>Run <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">1_create_dataset.sh</span></code>, which will take some time to complete.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">1_create_dataset.sh</span></code> script will call the <code class="docutils literal notranslate"><span class="pre">create_dataset.py</span></code> Python script, which in turn will:</p>
<ul class="simple">
<li><p>Unzip the <code class="docutils literal notranslate"><span class="pre">dogs-vs-cats.zip</span></code> archive.</p></li>
<li><p>Split the full set of images into training and test subsets.</p></li>
<li><p>Resize and center crop the images to the size specified by the <code class="docutils literal notranslate"><span class="pre">--input_height</span></code> and <code class="docutils literal notranslate"><span class="pre">--input_width</span></code> arguments.</p></li>
<li><p>Normalize the images, so that pixel values are in the range 0 to 1.</p></li>
<li><p>Pack the resized, normalized train and test images and their associated labels into numpy files, which will be used as input for training and test in TensorFlow.</p></li>
<li><p>Put all the test images in a separate folder (<code class="docutils literal notranslate"><span class="pre">test_images</span></code>), so that they can be used later to create the files and folders to be run on the ZCU102 evaluation board.</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">create_dataset.py</span></code> Python script has three arguments.</p>
<p>| Argument | Data Type | Default | Description |
|———-|:———:|:——-:|————-|
| <code class="docutils literal notranslate"><span class="pre">--dataset_dir</span></code> or <code class="docutils literal notranslate"><span class="pre">-d</span></code> | string | ./dataset | Path to folder where <code class="docutils literal notranslate"><span class="pre">.npz</span></code> files and test images will be created |
| <code class="docutils literal notranslate"><span class="pre">--input_height</span></code> or <code class="docutils literal notranslate"><span class="pre">-ih</span></code> | integer | 224 | All images will be resized to this height |
| <code class="docutils literal notranslate"><span class="pre">--input_width</span></code> or <code class="docutils literal notranslate"><span class="pre">-iw</span></code>  | integer | 224 | All images will be resized to this width |</p>
<p>After this script is completed, you should find two numpy files in the dataset folder, <code class="docutils literal notranslate"><span class="pre">trainData.npz</span></code> and <code class="docutils literal notranslate"><span class="pre">testData.npz</span></code>, and a subfolder called <code class="docutils literal notranslate"><span class="pre">test_images</span></code> that contains the resized test images.</p>
</div>
<div class="section" id="step-2-initial-training">
<h1>Step 2 - Initial Training<a class="headerlink" href="#step-2-initial-training" title="Permalink to this headline">¶</a></h1>
<p>Run <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">2_train.sh</span></code>, which calls the <code class="docutils literal notranslate"><span class="pre">train_ft.py</span></code> Python script.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">train_ft.py</span></code> script is used at two different points in the complete flow — initial training of the original network and also in fine-tuning the pruned checkpoints.</p>
<p>If an input checkpoint is specified using the <code class="docutils literal notranslate"><span class="pre">--input_ckpt</span></code> argument, the script will assume that it is fine-tuning a pruned checkpoint and sets the pruning mode. For fine-tuning it is necessary to call the <code class="docutils literal notranslate"><span class="pre">tf.set_pruning_mode()</span></code> API which enables a ‘sparse training’ mode that keeps the weights of pruned channels at a zero value during fine-tuning:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># if an input checkpoint is specified, we are doing pruning fine-tune</span>
<span class="k">if</span> <span class="p">(</span><span class="n">input_ckpt</span><span class="o">!=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">set_pruning_mode</span><span class="p">()</span>
</pre></div>
</div>
<p>Then the script will restore that checkpoint in the TensorFlow session.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># if input checkpoint specified, restore it</span>
<span class="k">if</span> <span class="p">(</span><span class="n">input_ckpt</span><span class="o">!=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
  <span class="n">saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">input_ckpt</span><span class="p">)</span>
</pre></div>
</div>
<p>There is a minimal amount of image augmentation done during training; the images are randomly flipped from left to right around the vertical axis.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># random flip</span>
<span class="k">if</span> <span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">==</span><span class="mi">1</span><span class="p">):</span>
  <span class="n">np</span><span class="o">.</span><span class="n">fliplr</span><span class="p">(</span><span class="n">x_batch</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>  
</pre></div>
</div>
<p>The initial learning rate is set by the <code class="docutils literal notranslate"><span class="pre">INIT_LR</span></code> environment variable, which you will find in <code class="docutils literal notranslate"><span class="pre">0_setenv_common.sh</span></code>.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">INIT_LR</span><span class="o">=</span><span class="m">0</span>.001
</pre></div>
</div>
<p>This learning rate will be used for the first half of the training and will then be divided by 10 for the second half of the training.</p>
<p>At the end of each training epoch, the script evaluates the accuracy of the network using the test dataset. A checkpoint will be saved at the end of each epoch only if the accuracy improves over the current best score. The final accuracy should be approximately 92%.</p>
<p>After training has completed, TensorBoard can be launched using the command reported in the console and log file.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">train_ft.py</span></code> Python script has the following arguments.</p>
<p>| Argument | Data Type | Default | Description
|———-|:———:|:——-:|——————————————————————|
| <code class="docutils literal notranslate"><span class="pre">--target_acc</span></code> or <code class="docutils literal notranslate"><span class="pre">-a</span></code> | float | 1.0 | Minimum accuracy level that causes training/fine-tune to exit |
| <code class="docutils literal notranslate"><span class="pre">--dataset_dir</span></code> or <code class="docutils literal notranslate"><span class="pre">-d</span></code> | string | ‘./dataset’ | Path to folder containing <code class="docutils literal notranslate"><span class="pre">testData.npz</span></code> and <code class="docutils literal notranslate"><span class="pre">trainData.npz</span></code> files |
| <code class="docutils literal notranslate"><span class="pre">--input_ckpt</span></code> or <code class="docutils literal notranslate"><span class="pre">-i</span></code> | string | ‘’  | Path to input checkpoint for fine-tuning. Empty string means run initial training |
| <code class="docutils literal notranslate"><span class="pre">--epochs</span></code> or <code class="docutils literal notranslate"><span class="pre">-e</span></code> | integer | 1 | Number of epochs for training or fine-tuning |
| <code class="docutils literal notranslate"><span class="pre">--batchsize</span></code> or <code class="docutils literal notranslate"><span class="pre">-b</span></code> | integer | 100 | Batch size for training or fine-tuning |
| <code class="docutils literal notranslate"><span class="pre">--init_lr</span></code> or <code class="docutils literal notranslate"><span class="pre">-il</span></code> | float | 0.1 | Initial learning rate for optimizer |
| <code class="docutils literal notranslate"><span class="pre">--output_ckpt</span></code> or <code class="docutils literal notranslate"><span class="pre">-o</span></code>  | string | output.ckpt | Path to output checkpoint |
| <code class="docutils literal notranslate"><span class="pre">--tboard_logs</span></code> or <code class="docutils literal notranslate"><span class="pre">-tb</span></code> | string | ‘./tb_logs’ | Path to folder where TensorBoard event logs will be saved |
| <code class="docutils literal notranslate"><span class="pre">--input_height</span></code> or <code class="docutils literal notranslate"><span class="pre">-ih</span></code> | integer | 224 | Input height size |
| <code class="docutils literal notranslate"><span class="pre">--input_width</span></code> or <code class="docutils literal notranslate"><span class="pre">-iw</span></code> | integer | 224 | Input width size |
| <code class="docutils literal notranslate"><span class="pre">--input_chan</span></code> or <code class="docutils literal notranslate"><span class="pre">-ic</span></code> | integer | 3 | Number of input channels |
| <code class="docutils literal notranslate"><span class="pre">--gpu</span></code> or <code class="docutils literal notranslate"><span class="pre">-g</span></code> | string | ‘0’ | List of GPUs to be used for training or fine-tuning |</p>
<p>The <code class="docutils literal notranslate"><span class="pre">--target_acc</span></code> option can be used to cause the training/fine-tuning to exit early if the minimum specified accuracy is reached. This is mainly intended for use during fine-tuning - one strategy for fine-tuning would be to set <code class="docutils literal notranslate"><span class="pre">--target_acc</span></code> to the same accuracy value obtained during initial training.</p>
<p>The training/fine-tuning will either run until the target accuracy or maximum epochs (<code class="docutils literal notranslate"><span class="pre">--epochs</span></code>) is reached.</p>
<p>For initial training, <code class="docutils literal notranslate"><span class="pre">--target_acc</span></code> would normally be left at the default value of 1.0 (100% accuracy target).</p>
</div>
<div class="section" id="step-3-export-inference-graph">
<h1>Step 3 - Export Inference Graph<a class="headerlink" href="#step-3-export-inference-graph" title="Permalink to this headline">¶</a></h1>
<p>Run <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">3_export_inf.sh</span></code>, which calls the <code class="docutils literal notranslate"><span class="pre">export_inf_graph.py</span></code> Python script.</p>
<p>An inference graph is required for the pruning. The <code class="docutils literal notranslate"><span class="pre">export_inf_graph.py</span></code> Python script will write out an inference graph in the text protobuf format. The AlexNet is instantiated with dropout rate set to 0 and the <code class="docutils literal notranslate"><span class="pre">is_training</span></code> argument set to False.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">network</span> <span class="o">=</span> <span class="n">alexnet</span><span class="p">(</span><span class="n">net_in</span><span class="o">=</span><span class="n">input_tensor</span><span class="p">,</span><span class="n">classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">drop_rate</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span><span class="n">is_training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Note</strong>: This inference graph is not the same as a frozen graph because it does not contain any values.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">export_inf_graph.py</span></code> Python script has the following arguments.</p>
<p>| Argument | Data Type | Default | Description
|:———|:———:|:——-:|:————————————————————|
| <code class="docutils literal notranslate"><span class="pre">--output_file</span></code> or <code class="docutils literal notranslate"><span class="pre">-o</span></code> | string | ‘’ | Full path name of inference graph file to be created |
| <code class="docutils literal notranslate"><span class="pre">--input_nodes</span></code> or <code class="docutils literal notranslate"><span class="pre">-i</span></code> | string | ‘’ | List of input nodes |</p>
<p>Before moving on, ensure that the output file has been created.</p>
</div>
<div class="section" id="step-4-run-pruning-analysis">
<h1>Step 4 - Run Pruning Analysis<a class="headerlink" href="#step-4-run-pruning-analysis" title="Permalink to this headline">¶</a></h1>
<p>Run <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">4_prune_analysis.sh</span></code>, which will take some time to complete.</p>
<p>The pruning analysis command analyzes the trained checkpoint and inference graph and writes the analysis results into a file named <code class="docutils literal notranslate"><span class="pre">.ana</span></code> in the folder indicated by the <code class="docutils literal notranslate"><span class="pre">--workspace</span></code> argument.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">--eval_fn_path</span></code> argument must point to a Python file that contains a function named <code class="docutils literal notranslate"><span class="pre">model_fn()</span></code>. This function will be called once for every analysis batch, the number of analysis batches is set by the <code class="docutils literal notranslate"><span class="pre">--max_num_batches</span></code> argument.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">model_fn()</span></code> must instantiate the network (for inference, not training) and provide input data (usually the test dataset) and an evaluation metric. In this case, you calculate accuracy.</p>
<p>After the script completes, before proceeding to the next step, ensure that you have a file named <code class="docutils literal notranslate"><span class="pre">.ana</span></code> in the folder indicated by the <code class="docutils literal notranslate"><span class="pre">--workspace</span></code> argument.</p>
<p><strong>Note</strong>: You may need to enable viewing of hidden files to see the .ana file as Linux usually treats any file that begins with ‘.’ as a hidden file.</p>
</div>
<div class="section" id="step-5-run-pruning">
<h1>Step 5 - Run Pruning<a class="headerlink" href="#step-5-run-pruning" title="Permalink to this headline">¶</a></h1>
<p>Run <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">5_pruning.sh</span></code>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">5_pruning.sh</span></code> shell script invokes the commands necessary to iteratively prune the network. The pruning loop will run eight pruning iterations, each one reduces the network by approximately 10%.</p>
<p>Inside the pruning loop, the sparsity value (i.e. the amount of pruning) is incremented by 0.1 each loop iteration. Pruning is run using the sparsity value then fine-tuning (basically re-training) is run on the pruned checkpoint.</p>
<p>For the first 7 fine-tuning iterations, the target accuracy is set to 90% to speed up the flow, the eighth and last iteration has a target accuracy of 92% to match the accuracy obtained after initial training.</p>
</div>
<div class="section" id="step-6-create-dense-checkpoint">
<h1>Step 6 - Create Dense Checkpoint<a class="headerlink" href="#step-6-create-dense-checkpoint" title="Permalink to this headline">¶</a></h1>
<p>Run <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">6_transform.sh</span></code>.</p>
<p>This step will convert the sparse checkpoint that is created by the pruning/fine-tune iterations into a dense checkpoint.</p>
<p>The checkpoint created in step 5 contains exactly the same number of parameters as there were in the original model but mnay of them are now ‘zeroed out’.  The <code class="docutils literal notranslate"><span class="pre">vai_p_tensorflow</span> <span class="pre">--action</span> <span class="pre">transform</span></code> command called in the <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">6_transform.sh</span></code> script will remove the zero values to reduce the checkpoint.</p>
</div>
<div class="section" id="step-7-freeze-pruned-graph-and-checkpoint">
<h1>Step 7 - Freeze Pruned Graph and Checkpoint<a class="headerlink" href="#step-7-freeze-pruned-graph-and-checkpoint" title="Permalink to this headline">¶</a></h1>
<p>Run <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">7_freeze.sh</span></code>.</p>
<p>The Vitis AI tools require a  TensorFlow frozen graph as the input to the quantization stage. The <code class="docutils literal notranslate"><span class="pre">7_freeze.sh</span></code> shell script will create the frozen graph from the dense checkpoint. The frozen graph is in the binary protobuf format and is gets the name because all variables are converted into constants and graph nodes associated with training, such as the optimizer and loss function, are stripped out.</p>
</div>
<div class="section" id="step-8-evaluate-the-frozen-graph">
<h1>Step 8 - Evaluate the Frozen Graph<a class="headerlink" href="#step-8-evaluate-the-frozen-graph" title="Permalink to this headline">¶</a></h1>
<p>Run <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">8_eval_frozen.sh</span></code>.</p>
<p>This is an optional step because the frozen graph is still in floating-point format and should give almost identical accuracy results as the evaluation done during the training phase (step 2). All images of the test set are passed through the frozen model and the accuracy is calculated.</p>
</div>
<div class="section" id="step-9-quantize">
<h1>Step 9 - Quantize<a class="headerlink" href="#step-9-quantize" title="Permalink to this headline">¶</a></h1>
<p>Run <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">9_quant.sh</span></code>.</p>
<p>The DPU accelerator IP executes all calculations in 8bit integer format, so we must quantize our floating-point frozen graph. This is done by the Vitis AI tools, in particular by the <code class="docutils literal notranslate"><span class="pre">vai_q_tensorflow</span> <span class="pre">quantize</span></code> command. This command can be seen in the <code class="docutils literal notranslate"><span class="pre">9_quant.sh</span></code> script and has several arguments that you must provide values for.</p>
<p>| Argument              | Description                                                    |
|:——————— | :————————————————————- |
|<code class="docutils literal notranslate"><span class="pre">--input_frozen_graph</span></code> | Path and name of the input .pb frozen graph                    |
|<code class="docutils literal notranslate"><span class="pre">--input_fn</span></code>           | Name of input function used in calibration pre-processing      |
|<code class="docutils literal notranslate"><span class="pre">--output_dir</span></code>         | Name of the output folder where the quantized models are saved |
|<code class="docutils literal notranslate"><span class="pre">--input_nodes</span></code>        | Name(s) of the input nodes                                     |
|<code class="docutils literal notranslate"><span class="pre">--output_nodes</span></code>       | Name(s) of the output nodes                                    |
|<code class="docutils literal notranslate"><span class="pre">--input_shapes</span></code>       | Shape(s) of the input nodes                                    |
|<code class="docutils literal notranslate"><span class="pre">--calib_iter</span></code>         | Number of calibration iterations                               |
|<code class="docutils literal notranslate"><span class="pre">--gpu</span></code>                | List of CUDA devices to be used for quantization               |</p>
<p><strong>Note</strong>: Any error messages relating to <code class="docutils literal notranslate"><span class="pre">./bin/ptxas</span></code> can be ignored.</p>
<p>Most of the arguments are self-explanatory but special mention needs to be made for the <code class="docutils literal notranslate"><span class="pre">--input_fn</span></code> and <code class="docutils literal notranslate"><span class="pre">--calib_iter</span></code> arguments.</p>
<p>You must use a sample set of data to calibrate the quantization process. This data will be passed through the model, so the data must be pre-processed in exactly the same way as the data is pre-processed in training. The function pointed to by the <code class="docutils literal notranslate"><span class="pre">--input_fn</span></code> argument will need to contain all of the pre-processing steps.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">image_input_fn.py</span></code> Python script contains a single function called calib_input (the <code class="docutils literal notranslate"><span class="pre">--input_fn</span></code> argument is set to image_input_fn.calib_input in the <code class="docutils literal notranslate"><span class="pre">9_quant.sh</span></code> shell script) which unpacks the training dataset from its numpy format and then creates a list of numpy arrays. The number of arrays in the list is given by calib_batch_size * calib_iter and should be at least 1000.</p>
<p>After quantization has completed, you will have the quantized deployment model (<code class="docutils literal notranslate"><span class="pre">deploy_model.pb</span></code>) and the evaluation model (<code class="docutils literal notranslate"><span class="pre">quantize_eval_model.pb</span></code>) in the <code class="docutils literal notranslate"><span class="pre">./files/build_pr/quantize</span></code> folder.</p>
</div>
<div class="section" id="step-10-evaluate-quantized-graph">
<h1>Step 10 - Evaluate Quantized Graph<a class="headerlink" href="#step-10-evaluate-quantized-graph" title="Permalink to this headline">¶</a></h1>
<p>Run <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">10_eval_quant.sh</span></code>.</p>
<p>This step is optional but <em>highly</em> recommended. The conversion from a floating-point model where the values can have a very wide dynamic range to an 8-bit model where values can only have one of 256 values almost inevitably leads to a small loss of accuracy. You use the quantized evaluation model to see exactly how much impact the quantization process has had.</p>
<p>To ensure consistency, the same Python script, <code class="docutils literal notranslate"><span class="pre">eval_graph.py</span></code>, that was used to evaluate the frozen graph is also used to evaluate the quantized model.</p>
</div>
<div class="section" id="step-11-compile">
<h1>Step 11 - Compile<a class="headerlink" href="#step-11-compile" title="Permalink to this headline">¶</a></h1>
<p>For the ZCU10, run <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">11_compile_zcu102.sh</span></code>.
For the Alveo U50, run <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">11_compile_u50.sh</span></code>.</p>
<p>The DPU is a soft-core IP whose only function is to accelerate the execution of convolutional neural networks. It acts as a co-processor to the host processor and has its own instruction set;those instructions are passed to the DPU in .xmodel file format.</p>
<p>The Vitis AI compiler will convert and optimize where possible, the quantized model to a set of micro-instructions and then output them to an .xmodel file.</p>
<p>The compile scripts are written into a folder called <code class="docutils literal notranslate"><span class="pre">files/build_pr/compile_&lt;board_name&gt;</span></code></p>
</div>
<div class="section" id="step-12-run-the-application-on-the-target-board">
<h1>Step 12 - Run the Application on the Target Board<a class="headerlink" href="#step-12-run-the-application-on-the-target-board" title="Permalink to this headline">¶</a></h1>
<p>For the ZCU10, run <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">12_make_target_zcu102.sh</span></code>.
For the Alveo U50, run <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">12_make_target_u50.sh</span></code>.</p>
<p>This final step will copy all the required files for running on the chosen target board board into the <code class="docutils literal notranslate"><span class="pre">files/build_pr/target_&lt;board_name&gt;</span></code> folder.</p>
<div class="section" id="zcu102">
<h2>ZCU102<a class="headerlink" href="#zcu102" title="Permalink to this headline">¶</a></h2>
<p>Ensure that the ZCU102 SDCard has been flashed with the correct version of the image file and boots correctly before proceeding.</p>
<p>The entire <code class="docutils literal notranslate"><span class="pre">files/build_pr/target_zcu102</span></code> folder will need to be copied to the <code class="docutils literal notranslate"><span class="pre">/home/root</span></code> folder of ZCU102’s SDcard. This can be done in one of several ways:</p>
<ol class="simple">
<li><p>Direct copy to SD card:</p>
<ul class="simple">
<li><p>If the host machine has an SD card slot, insert the flashed SD card, and when it is recognized, you will see two volumes, BOOT and ROOTFS.</p></li>
<li><p>Navigate into the ROOTFS and then into the <code class="docutils literal notranslate"><span class="pre">/home</span></code> folder.  Make the <code class="docutils literal notranslate"><span class="pre">./root</span></code> folder writeable by issuing the command <code class="docutils literal notranslate"><span class="pre">sudo</span> <span class="pre">chmod</span> <span class="pre">-R</span> <span class="pre">777</span> <span class="pre">root</span></code>, and then copy the entire target folder from the host machine into the <code class="docutils literal notranslate"><span class="pre">/home/root</span></code> folder of the SD card.</p></li>
<li><p>Unmount both the BOOT and ROOTFS volumes from the host machine, and then eject the SD card from the host machine.</p></li>
</ul>
</li>
<li><p>With the scp command:</p>
<ul class="simple">
<li><p>If the ZCU102 is connected to a network and reachable by the host machine, the target folder can be copied using the scp command. If you connect directly from your host machine to the ZCU102 using ethernet, you might need to set up static IP addresses.</p></li>
<li><p>The command will be something like <code class="docutils literal notranslate"><span class="pre">scp</span> <span class="pre">-r</span> <span class="pre">./build_pr/target_zcu102</span> <span class="pre">root&#64;192.168.1.227:~/.</span></code> assuming that the ZCU102 IP address is 192.168.1.227. Adjust this and the path to the target folder as appropriate for your system.</p></li>
<li><p>If the password is asked for, enter <code class="docutils literal notranslate"><span class="pre">root</span></code>.</p></li>
</ul>
</li>
</ol>
<p>With the target folder copied to the SD card and the ZCU102 booted, you can issue the command to launch the application.</p>
<p><strong>Note</strong>: This process is done on the ZCU102 board, not the host machine, so it requires a connection to the ZCU102, such as a serial connection to the UART or an SSH connection via Ethernet.</p>
<p>The application can be started on the ZCU102 by navigating into the <code class="docutils literal notranslate"><span class="pre">target_zcu102</span></code> folder (<code class="docutils literal notranslate"><span class="pre">cd</span> <span class="pre">target_zcu102</span></code>) and then issuing the command <code class="docutils literal notranslate"><span class="pre">python3</span> <span class="pre">app_mt.py</span> <span class="pre">-m</span> <span class="pre">model_dir/alexnet_pr.xmodel</span></code>. The application will start and after a few seconds show the throughput (in frames/sec) and the accuracy:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>root@xilinx-zcu102-2020_2:~/target_zcu102# python3 app_mt.py -m model_dir/alexnet_pr.xmodel 
-----------------------------------------------
Command line options:
 --image_dir :  images
 --threads   :  <span class="m">1</span>
 --model     :  model_dir/alexnet_pr.xmodel
-----------------------------------------------
Found <span class="m">5000</span> images - processing <span class="m">2500</span> of them
Found <span class="m">1</span> subgraphs in model_dir/alexnet_pr.xmodel
Pre-processing <span class="m">2500</span> images...
Starting <span class="m">1</span> threads...
-----------------------------------------------
Correct:2307, Wrong:193, Accuracy:0.9228
-----------------------------------------------
FPS: <span class="m">161</span>.02, total frames: <span class="m">2500</span>, total time: <span class="m">15</span>.526 seconds
-----------------------------------------------
</pre></div>
</div>
<p>The throughput can be increased by using more than 1 thread with the <code class="docutils literal notranslate"><span class="pre">--threads</span></code> option. For example, to use 4 threads:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>root@xilinx-zcu102-2020_2:~/target_zcu102# python3 app_mt.py -m model_dir/alexnet_pr.xmodel --threads <span class="m">4</span>
-----------------------------------------------
Command line options:
 --image_dir :  images
 --threads   :  <span class="m">4</span>
 --model     :  model_dir/alexnet_pr.xmodel
-----------------------------------------------
Found <span class="m">5000</span> images - processing <span class="m">2500</span> of them
Found <span class="m">1</span> subgraphs in model_dir/alexnet_pr.xmodel
Pre-processing <span class="m">2500</span> images...
Starting <span class="m">4</span> threads...
-----------------------------------------------
Correct:2307, Wrong:193, Accuracy:0.9228
-----------------------------------------------
FPS: <span class="m">309</span>.76, total frames: <span class="m">2500</span>, total time: <span class="m">8</span>.071 seconds
-----------------------------------------------
</pre></div>
</div>
</div>
<div class="section" id="alveo-u50">
<h2>Alveo U50<a class="headerlink" href="#alveo-u50" title="Permalink to this headline">¶</a></h2>
<p>Note that these steps need to be run from inside of the Vitis-AI Docker container.</p>
<p>Run the <code class="docutils literal notranslate"><span class="pre">U50_overlay.sh</span></code> script (internet connection required) to download and install the correct overlay. Note that the U50 will need to have been flashed with the correct deployment shell - this should have been done in the <a class="reference external" href="#before-you-begin">Before You Begin</a> section above. The complete steps to run on the Alveo U50 are as follows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">source</span> U50_overlay.sh
<span class="nb">cd</span> build_pr/target_u50
/usr/bin/python3 app_mt.py -m model_dir/alexnet_pr.xmodel
</pre></div>
</div>
<p>You should see something like this:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>Vitis-AI /workspace/build_pr/target_u50 &gt; /usr/bin/python3 app_mt.py -m model_dir/alexnet_pr.xmodel
-----------------------------------------------
Command line options:
 --image_dir :  images
 --threads   :  <span class="m">1</span>
 --model     :  model_dir/alexnet_pr.xmodel
-----------------------------------------------
Found <span class="m">5000</span> images - processing <span class="m">2500</span> of them
Found <span class="m">1</span> subgraphs in model_dir/alexnet_pr.xmodel
Pre-processing <span class="m">2500</span> images...
Starting <span class="m">1</span> threads...
-----------------------------------------------
Correct:2312, Wrong:188, Accuracy:0.9248
-----------------------------------------------
FPS: <span class="m">471</span>.33, total frames: <span class="m">2500</span>, total time: <span class="m">5</span>.304 seconds
-----------------------------------------------
</pre></div>
</div>
<p>As with the ZCU102, the performance can be increased by using more threads:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>Vitis-AI /workspace/build_pr/target_u50 &gt; /usr/bin/python3 app_mt.py -m model_dir/alexnet_pr.xmodel --threads <span class="m">4</span>
-----------------------------------------------
Command line options:
 --image_dir :  images
 --threads   :  <span class="m">4</span>
 --model     :  model_dir/alexnet_pr.xmodel
-----------------------------------------------
Found <span class="m">5000</span> images - processing <span class="m">2500</span> of them
Found <span class="m">1</span> subgraphs in model_dir/alexnet_pr.xmodel
Pre-processing <span class="m">2500</span> images...
Starting <span class="m">4</span> threads...
-----------------------------------------------
Correct:2312, Wrong:188, Accuracy:0.9248
-----------------------------------------------
FPS: <span class="m">2959</span>.87, total frames: <span class="m">2500</span>, total time: <span class="m">0</span>.845 seconds
-----------------------------------------------
</pre></div>
</div>
</div>
</div>
<div class="section" id="references">
<h1>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p><a class="reference external" href="https://www.xilinx.com/support/documentation/sw_manuals/vitis_ai/1_3/ug1333-ai-optimizer.pdf">Vitis AI Optimizer User Guide (UG1333)</a></p></li>
<li><p><a class="reference external" href="https://www.xilinx.com/support/documentation/sw_manuals/vitis_ai/1_3/ug1414-vitis-ai.pdf">Vitis AI User Guide (UG1414)</a></p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/c/dogs-vs-cats">Kaggle Dogs-vs-Cats dataset</a></p></li>
<li><p><a class="reference external" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">ImageNet Classification with Deep Convolutional Neural Networks</a></p></li>
</ul>
</hr>
<p class="sphinxhide" align="center"><sup>Copyright&copy; 2020-2021 Xilinx</sup></p></div>


           </div>
           
          </div>
          <footer>
<!-- Atalwar: Moved the footer code to layout.html to resolve conflict with the Xilinx template -->
</footer>

        </div>
      </div>


	  <!-- Sphinx Page Footer block -->
  

  <hr/>

  <div role="contentinfo" class="copyright">
    <p class="footerinfo">

    </p>
	<br>
  </div>
      </div>
    </section>


  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

   <script type="text/javascript">
    jQuery(function() { Search.loadIndex("searchindex.js"); });
  </script>

  <script type="text/javascript" id="searchindexloader"></script>


  
  
    
  



  <!--  Xilinx template footer block -->
							</div>
						</div>
					</div>
				</div>
				<div class="xilinxExperienceFragments experiencefragment aem-GridColumn--default--none aem-GridColumn aem-GridColumn--offset--default--0 aem-GridColumn--default--16">
					<div class="xf-content-height">
						<div class="aem-Grid aem-Grid--16 aem-Grid--default--16 ">
							<div class="footer parbase aem-GridColumn--default--none aem-GridColumn aem-GridColumn--offset--default--0 aem-GridColumn--default--16">
								<noindex>
                  <!-- make footer fixed - NileshP -->
                  <style>
                        .footer {
                        position: fixed;
                        left: 0;
                        bottom: 0;
                        width: 100%;
                        }
                  </style>
                  <!-- make footer fixed NileshP-->
									<footer>
										<div class="aem-Grid aem-Grid--16">
											<div class="aem-GridColumn aem-GridColumn--xxxlarge--none aem-GridColumn--xsmall--16 aem-GridColumn--offset--xsmall--0 aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--xsmall--none aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
												<div class="container-fluid sub-footer">
													<div class="row">
														<div class="footerSocial parbase">
															<div class="col-md-push-6 col-lg-push-6 col-md-6 col-lg-6">
																<ul class="list-inline pull-right social-menu">
																	<li>
																		<a href="https://www.linkedin.com/company/xilinx">
																		<span class="linkedin icon"></span>
																		<span class="sr-only">Connect on LinkedIn</span>
																		</a>
																	</li>
																	<li>
																		<a href="https://www.twitter.com/XilinxInc">
																		<span class="twitter icon"></span>
																		<span class="sr-only">Follow us on Twitter</span>
																		</a>
																	</li>
																	<li>
																		<a href="https://www.facebook.com/XilinxInc">
																		<span class="facebook icon"></span>
																		<span class="sr-only">Connect on Facebook</span>
																		</a>
																	</li>
																	<li>
																		<a href="https://www.youtube.com/XilinxInc">
																		<span class="youtube icon"></span>
																		<span class="sr-only">Watch us on YouTube</span>
																		</a>
																	</li>
																	<li>
																		<a href="https://www.xilinx.com/registration/subscriber-signup.html">
																		<span class="newsletter icon"></span>
																		<span class="sr-only">Subscribe to Newsletter</span>
																		</a>
																	</li>
																</ul>
															</div>
														</div>
														<div class="col-md-pull-6 col-lg-pull-6 col-md-6 col-lg-6">
															<span class="copyright">
                                  
                                  &copy; 2020–2021, Xilinx, Inc.
                              </span>
															<ul class="list-inline sub-menu">
																<li>
																	<a href="https://www.xilinx.com/about/privacy-policy.html">Privacy</a>
																</li>
																<li>
																	<a href="https://www.xilinx.com/about/legal.html">Legal</a>
																</li>
																<li>
																	<a href="https://www.xilinx.com/about/contact.html">Contact</a>
																</li>
															</ul>
														</div>
													</div>
												</div>
											</div>
										</div>
									</footer>
								</noindex>
							</div>
						</div>
					</div>
				</div>
				<div class="quicklinks parbase aem-GridColumn--default--none aem-GridColumn aem-GridColumn--offset--default--0 aem-GridColumn--default--16">
					<noindex>
						<span class="quickLinks">
							<ul>
								<li>
									<a href="#top" class="btn backToTop">
									<span class="fas fa-angle-up" aria-hidden="true"></span>
									</a>
								</li>
							</ul>
						</span>
					</noindex>
				</div>
			</div>
		</div>
		<script>window.CQ = window.CQ || {}</script>
		<script src="https://static.cloud.coveo.com/searchui/v2.4382/js/CoveoJsSearch.Lazy.min.js"></script>
		<script>
			var underscoreSetup = function () {
			  _.templateSettings.interpolate = /\{\{=([^-][\S\s]+?)\}\}/g;
			  _.templateSettings.evaluate = /\{\{([^-=][\S\s]+?)\}\}/g;
			  _.templateSettings.escape = /\{\{-([^=][\S\s]+?)\}\}/g;
			}

			underscoreSetup();
		</script>
	</body>
</html>