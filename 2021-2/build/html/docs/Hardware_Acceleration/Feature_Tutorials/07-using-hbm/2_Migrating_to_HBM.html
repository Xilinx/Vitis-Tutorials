<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
<!-- OneTrust Cookies Consent Notice start for xilinx.github.io -->

<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="03af8d57-0a04-47a6-8f10-322fa00d8fc7" ></script>
<script type="text/javascript">
function OptanonWrapper() { }
</script>
<!-- OneTrust Cookies Consent Notice end for xilinx.github.io -->
  <title>Application Overview &mdash; Vitis™ Tutorials 2021.2 documentation</title>
      <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
            <a href="../../../../index.html" class="icon icon-home"> Vitis™ Tutorials
            <img src="../../../../_static/xilinx-header-logo.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                2021.2
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">日本語版</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/Vitis-Tutorials/master/docs-jp/index.html">Master</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Getting_Started/Vitis-Getting-Started.html">Getting Started</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Acceleration</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Hardware-Acceleration.html">Hardware Acceleration</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AI Engine</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../AI_Engine_Development/AI_Engine_Development.html">AI Engine Development</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Platforms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Vitis_Platform_Creation/Vitis_Platform_Creation.html">Vitis Platform Creation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other Versions</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/Vitis-Tutorials/index.html">Main</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/Vitis-Tutorials/2021-1/build/html/index.html">2021.1</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/Vitis-Tutorials/2020-2/docs/build/html/index.html">2020.2</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/Vitis-Tutorials/2020-1/docs/build/html/README.html">2020.1</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: black" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">Vitis™ Tutorials</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Application Overview</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../_sources/docs/Hardware_Acceleration/Feature_Tutorials/07-using-hbm/2_Migrating_to_HBM.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <table class="sphinxhide">
 <tr>
   <td align="center"><img src="https://www.xilinx.com/content/dam/xilinx/imgs/press/media-kits/corporate/xilinx-logo.png" width="30%"/><h1>Vitis™ Application Acceleration Development Flow Tutorials</h1>
   </td>
 </tr>
 <tr>
 <td>
 </td>
 </tr>
</table><div class="section" id="application-overview">
<h1>Application Overview<a class="headerlink" href="#application-overview" title="Permalink to this heading">¶</a></h1>
<p>This tutorial uses a simple example of vector addition with DDR based implementation. Ports <code class="docutils literal notranslate"><span class="pre">in1</span></code> and <code class="docutils literal notranslate"><span class="pre">in2</span></code> are reading from DDR banks 0 and 1, respectively, and port <code class="docutils literal notranslate"><span class="pre">out</span></code> is writing the results in DDR bank 2. The tutorial will walk through the necessary changes to the existing application to migrate to HBM.</p>
<div class="section" id="using-ddr">
<h2>Using DDR<a class="headerlink" href="#using-ddr" title="Permalink to this heading">¶</a></h2>
<p>The kernel code is a simple vector addition with the following function signature.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">void</span> <span class="n">vadd</span><span class="p">(</span>
  <span class="n">const</span> <span class="n">unsigned</span> <span class="nb">int</span> <span class="o">*</span><span class="n">in1</span><span class="p">,</span> <span class="o">//</span> <span class="n">Read</span><span class="o">-</span><span class="n">Only</span> <span class="n">Vector</span> <span class="mi">1</span>
  <span class="n">const</span> <span class="n">unsigned</span> <span class="nb">int</span> <span class="o">*</span><span class="n">in2</span><span class="p">,</span> <span class="o">//</span> <span class="n">Read</span><span class="o">-</span><span class="n">Only</span> <span class="n">Vector</span> <span class="mi">2</span>
  <span class="n">unsigned</span> <span class="nb">int</span> <span class="o">*</span><span class="n">out</span><span class="p">,</span>       <span class="o">//</span> <span class="n">Output</span> <span class="n">Result</span>
  <span class="nb">int</span> <span class="n">dsize</span><span class="p">,</span>                <span class="o">//</span> <span class="n">Size</span> <span class="ow">in</span> <span class="n">integer</span>
  <span class="n">const</span> <span class="n">unsigned</span> <span class="nb">int</span> <span class="n">kernel_loop</span><span class="p">,</span> <span class="o">//</span> <span class="n">Running</span> <span class="n">the</span> <span class="n">same</span> <span class="n">kernel</span> <span class="n">operations</span> <span class="n">kernel_loop</span> <span class="n">times</span>
  <span class="nb">bool</span> <span class="n">addRandom</span>           <span class="o">//</span> <span class="n">Address</span> <span class="n">Pattern</span> <span class="ow">is</span> <span class="n">random</span>
  <span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>in1 and in2: inputs for streaming data from DDR over AXI interfaces</p></li>
<li><p>out: output for streaming output results of vector addition writing in DDR over AXI interface</p></li>
<li><p>dsize: sets the size of memory access from kernel ports accessing DDR</p></li>
<li><p>kernel_loop : number of times the kernel operations are being called to keep the kernel busy accessing memory.</p></li>
<li><p>addRandom   : enables random access if set to 1</p></li>
</ul>
<p>For more information on the kernel source code, refer to  <code class="docutils literal notranslate"><span class="pre">&lt;Project&gt;/reference_files/kernel.cpp</span></code></p>
<p>The ports to DDR banks connectivity is established with the system port mapping option using the <code class="docutils literal notranslate"><span class="pre">--sp</span></code> switch. This switch allows the developer to map the kernel ports to specific global memory banks.</p>
<p>For more information refer to Mapping Kernel Ports to Memory, refer to    <a href="https://docs.xilinx.com/r/en-US/ug1393-vitis-application-acceleration"> Vitis User Guide.</a></p>
<p>The contents of the example connectivity file, DDR_connectivity.cfg are shown below. Makefile target will create this file automatically.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>connectivity<span class="o">]</span>
<span class="nv">sp</span><span class="o">=</span>vadd_1.in1:DDR<span class="o">[</span><span class="m">0</span><span class="o">]</span>
<span class="nv">sp</span><span class="o">=</span>vadd_1.in2:DDR<span class="o">[</span><span class="m">1</span><span class="o">]</span>
<span class="nv">sp</span><span class="o">=</span>vadd_1.out:DDR<span class="o">[</span><span class="m">2</span><span class="o">]</span>
</pre></div>
</div>
<p>The host code creates three buffers, one each in DDR0, DDR1, and DDR2. Refer to host code available in <code class="docutils literal notranslate"><span class="pre">&lt;Project&gt;/reference_files/host.cpp</span></code>. Each buffer connects to a single DDR bank with a capacity of 16GB, which is higher than the buffer size used in this application. You should be able to migrate up to max 4GB due to limitations on the Linux kernel.</p>
<p>The following code creates the three buffers of size vector_size_bytes.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">134</span> <span class="p">:</span> <span class="n">cl</span><span class="p">::</span><span class="n">Buffer</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="n">CL_MEM_USE_HOST_PTR</span> <span class="o">|</span> <span class="n">CL_MEM_READ_ONLY</span><span class="p">,</span> <span class="n">vector_size_bytes</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">source_in1</span><span class="p">[</span><span class="n">total_data_size</span><span class="p">]);</span>
<span class="mi">135</span> <span class="p">:</span> <span class="n">cl</span><span class="p">::</span><span class="n">Buffer</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="n">CL_MEM_USE_HOST_PTR</span> <span class="o">|</span> <span class="n">CL_MEM_READ_ONLY</span><span class="p">,</span> <span class="n">vector_size_bytes</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">source_in2</span><span class="p">[</span><span class="n">total_data_size</span><span class="p">]);</span>
<span class="mi">136</span> <span class="p">:</span> <span class="n">cl</span><span class="p">::</span><span class="n">Buffer</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="n">CL_MEM_USE_HOST_PTR</span> <span class="o">|</span> <span class="n">CL_MEM_WRITE_ONLY</span><span class="p">,</span> <span class="n">vector_size_bytes</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">source_hw_results</span><span class="p">[</span><span class="n">total_data_size</span><span class="p">]);</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">140</span> <span class="p">:</span> <span class="n">krnl_vector_add</span><span class="o">.</span><span class="n">setArg</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">buffer_in2</span><span class="p">[</span><span class="n">j</span><span class="p">]));</span>
<span class="mi">141</span> <span class="p">:</span> <span class="n">krnl_vector_add</span><span class="o">.</span><span class="n">setArg</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">buffer_in1</span><span class="p">[</span><span class="n">j</span><span class="p">]));</span>
<span class="mi">142</span> <span class="p">:</span> <span class="n">krnl_vector_add</span><span class="o">.</span><span class="n">setArg</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">buffer_output</span><span class="p">[</span><span class="n">j</span><span class="p">]));</span>
</pre></div>
</div>
<p>For more information on the kernel source code, refer to  <code class="docutils literal notranslate"><span class="pre">&lt;Project&gt;/reference_files/host.cpp</span></code></p>
</div>
<div class="section" id="run-application-using-ddr">
<h2>Run application using DDR<a class="headerlink" href="#run-application-using-ddr" title="Permalink to this heading">¶</a></h2>
<p>Let’s run the hardware application using DDR with a size of 600MB, sequential address pattern, and enqueue the kernel one time. The host will migrate 600MB to DDR0 (buffer_in1) and DDR1(buffer_in2) respectively. The kernel will perform the compute and store the results in DDR2, buffer_output.</p>
<p>Here is the makefile command to run ()</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1">#make ddr_addSeq_build  - executed already in first module.</span>
make ddr_addSeq
</pre></div>
</div>
<p>The above run command essentially expands to the following.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>make run <span class="nv">TARGET</span><span class="o">=</span>hw <span class="nv">memtype</span><span class="o">=</span>DDR <span class="nv">dsize</span><span class="o">=</span><span class="m">600</span> <span class="nv">addrndm</span><span class="o">=</span><span class="m">0</span> <span class="nv">krnl_loop</span><span class="o">=</span><span class="m">1</span> <span class="nv">buildxclbin</span><span class="o">=</span><span class="m">0</span>
</pre></div>
</div>
<ul class="simple">
<li><p>memtype sets memory as DDR or HBM</p></li>
<li><p>dsize is the amount of data migrated by the host to memory banks and accessed by the kernel ports, in1 and in2</p></li>
<li><p>kernel_loop sets the number of time the kernel loop repeats</p></li>
<li><p>buildxclbin=0 will not generate the new xclbin.</p></li>
<li><p>txSize is set to 64 by default. It’s the size of transactions issued by kernel port while accessing memory.</p></li>
</ul>
<p>The make command will geneated build directory shown as ../build/DDR_Banks_d512_txSize64</p>
<p>TARGET=hw_emu can also be used for running hardware emulation, but this will take significant time to run the application for a 600MB size buffer. For this reason, the application is run on hardware by using TARGET=hw</p>
<p>The above commands to run the application on hardware show the following results</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>*** Running hw mode ***  Use Command Line to run application!
cd ./../build/DDR_Banks_d512_txSize64 &amp;&amp;  ./host vadd_hw.xclbin 600 0 1 64;

 Total Data of 600.000 Mbytes to be written to global memory from host

 Kernel is invoked 1 time and repeats itself 1 times

Found Platform
Platform Name: Xilinx
DEVICE xilinx_u200_gen3x16_xdma_1_202110_1
INFO: Reading vadd_hw.xclbin
Loading: &#39;vadd_hw.xclbin&#39;
- host loop iteration #0 of 1 total iterations
kernel_time_in_sec = 0.0416315
Duration using events profiling: 41473086 ns
 match_count = 157286400 mismatch_count = 0 total_data_size = 157286400
Throughput Achieved = 15.17 GB/s
TEST PASSED
</pre></div>
</div>
<p>The host is migrating 600MB of data to both DDR0 and DDR1. The kernel accesses this data using in1, in2 ports from DDR0 and DDR1, respectively. The vector addition is performed by kernel, and results are written to DDR2. These results from DDR2 are migrated back to the host. The next section goes over the steps required to migrate this DDR based application to HBM.</p>
</div>
</div>
<div class="section" id="migration-to-hbm">
<h1>Migration to HBM<a class="headerlink" href="#migration-to-hbm" title="Permalink to this heading">¶</a></h1>
<p>The host code and kernel code are agnostic to the memory type used, whether DDR is used or HBM, or even PLRAMs. The only change you will need to make here is to modify the connectivity file.</p>
<p>Vitis flow makes it easy to switch memory connection using <code class="docutils literal notranslate"><span class="pre">-sp</span></code> switches, and in this case, we need to replace DDR with HBM. The capacity of each HBM bank is 256MB. Since our application requires 600MB of data to be added, we will need 3 HBM banks as contiguous memory. Vitis flow enables this by grouping the memory as shown below in the connectivity file.</p>
<div class="section" id="run-application-using-hbm">
<h2>Run application using HBM<a class="headerlink" href="#run-application-using-hbm" title="Permalink to this heading">¶</a></h2>
<p>You will perform the following 3 experiments here.</p>
<ol class="simple">
<li><p>Kernel ports, in1 and in2 read from 2 HBM PCs. Host sends 512MB data to HBM.</p></li>
<li><p>Kernel port, in1, and in2 read from 2 HBM PCs. The host sends more data than 512MB. This configuration will result in an application error since you are accessing more than 512MB.</p></li>
<li><p>Kernel ports, in1 and in2 share the same HBM PC.</p></li>
</ol>
<p>The contents of the example connectivity file, HBM_connectivity.cfg are shown below. Makefile target will create this file automatically based on argument, banks.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>connectivity<span class="o">]</span>
<span class="nv">sp</span><span class="o">=</span>vadd_1.in1:HBM<span class="o">[</span><span class="m">0</span>:1<span class="o">]</span>
<span class="nv">sp</span><span class="o">=</span>vadd_1.in2:HBM<span class="o">[</span><span class="m">2</span>:3<span class="o">]</span>
<span class="nv">sp</span><span class="o">=</span>vadd_1.out:HBM<span class="o">[</span><span class="m">4</span>:5<span class="o">]</span>
</pre></div>
</div>
<ol class="simple">
<li><p>Run the following command to use the application with HBM memory of size 512MB for in1,in2, and out ports.</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1">#make hbm_addSeq_2Banks_build  - executed already in first module.</span>
make hbm_addSeq_2Banks
</pre></div>
</div>
<p>The above command is equivalent of</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">run</span> <span class="n">TARGET</span><span class="o">=</span><span class="n">hw</span> <span class="n">memtype</span><span class="o">=</span><span class="n">HBM</span> <span class="n">banks</span><span class="o">=</span><span class="mi">0_1</span> <span class="n">dsize</span><span class="o">=</span><span class="mi">512</span> <span class="n">buildxclbin</span><span class="o">=</span><span class="mi">0</span>
</pre></div>
</div>
<ul class="simple">
<li><p>dsize=512 sets the data size to be accessed from HBM by kernel port in1 and in2.</p></li>
<li><p>banks=0_1 will create HBM_connectivity.cfg file with contents shown as above in appropriate builddir, ../build/HBM_2Banks_d512_txSize64</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="o">./../</span><span class="n">build</span><span class="o">/</span><span class="n">HBM_addSeq_2Banks_d512_txSize64</span> <span class="o">&amp;&amp;</span>  <span class="o">./</span><span class="n">host</span> <span class="n">vadd_hw</span><span class="o">.</span><span class="n">xclbin</span> <span class="mi">512</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">64</span><span class="p">;</span>

 <span class="n">Total</span> <span class="n">Data</span> <span class="n">of</span> <span class="mf">512.000</span> <span class="n">Mbytes</span> <span class="n">to</span> <span class="n">be</span> <span class="n">written</span> <span class="n">to</span> <span class="k">global</span> <span class="n">memory</span> <span class="kn">from</span> <span class="nn">host</span>

 <span class="n">The</span> <span class="n">kernel</span> <span class="ow">is</span> <span class="n">invoked</span> <span class="mi">1</span> <span class="n">time</span> <span class="ow">and</span> <span class="n">repeats</span> <span class="n">itself</span> <span class="n">one</span> <span class="n">time</span>

<span class="n">Found</span> <span class="n">Platform</span>
<span class="n">Platform</span> <span class="n">Name</span><span class="p">:</span> <span class="n">Xilinx</span>
<span class="n">DEVICE</span> <span class="n">xilinx_u50_gen3x16_xdma_201920_3</span>
<span class="n">INFO</span><span class="p">:</span> <span class="n">Reading</span> <span class="n">vadd_hw</span><span class="o">.</span><span class="n">xclbin</span>
<span class="n">Loading</span><span class="p">:</span> <span class="s1">&#39;vadd_hw.xclbin&#39;</span>
<span class="o">-</span> <span class="n">host</span> <span class="n">loop</span> <span class="n">iteration</span> <span class="c1">#0 of 1 total iterations</span>
<span class="n">kernel_time_in_sec</span> <span class="o">=</span> <span class="mf">0.0413112</span>
<span class="n">Duration</span> <span class="n">using</span> <span class="n">events</span> <span class="n">profiling</span><span class="p">:</span> <span class="mi">41136148</span> <span class="n">ns</span>
 <span class="n">match_count</span> <span class="o">=</span> <span class="mi">134217728</span> <span class="n">mismatch_count</span> <span class="o">=</span> <span class="mi">0</span> <span class="n">total_data_size</span> <span class="o">=</span> <span class="mi">134217728</span>
<span class="n">Throughput</span> <span class="n">Achieved</span> <span class="o">=</span> <span class="mf">13.0511</span> <span class="n">GB</span><span class="o">/</span><span class="n">s</span>
<span class="n">TEST</span> <span class="n">PASSED</span>
</pre></div>
</div>
<ol class="simple">
<li><p>If the host transfers data equivalent to more than 512MB, the application will have the following error.</p></li>
</ol>
<p>Run the following command</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">run</span> <span class="n">TARGET</span><span class="o">=</span><span class="n">hw</span> <span class="n">memtype</span><span class="o">=</span><span class="n">HBM</span> <span class="n">banks</span><span class="o">=</span><span class="mi">0_1</span> <span class="n">dsize</span><span class="o">=</span><span class="mi">600</span>
</pre></div>
</div>
<p>The application run results into error as shown below.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="o">./../</span><span class="n">build</span><span class="o">/</span><span class="n">HBM_addSeq_2Banks_d512_txSize64</span> <span class="o">&amp;&amp;</span>  <span class="o">./</span><span class="n">host</span> <span class="n">vadd_hw</span><span class="o">.</span><span class="n">xclbin</span> <span class="mi">600</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">64</span><span class="p">;</span>

 <span class="n">Total</span> <span class="n">Data</span> <span class="n">of</span> <span class="mf">600.000</span> <span class="n">Mbytes</span> <span class="n">to</span> <span class="n">be</span> <span class="n">written</span> <span class="n">to</span> <span class="k">global</span> <span class="n">memory</span> <span class="kn">from</span> <span class="nn">host</span>

 <span class="n">The</span> <span class="n">kernel</span> <span class="ow">is</span> <span class="n">invoked</span> <span class="mi">1</span> <span class="n">time</span> <span class="ow">and</span> <span class="n">repeats</span> <span class="n">itself</span> <span class="mi">1</span> <span class="n">times</span><span class="o">.</span>

<span class="n">Found</span> <span class="n">Platform</span>
<span class="n">Platform</span> <span class="n">Name</span><span class="p">:</span> <span class="n">Xilinx</span>
<span class="n">DEVICE</span> <span class="n">xilinx_u50_gen3x16_xdma_201920_3</span>
<span class="n">INFO</span><span class="p">:</span> <span class="n">Reading</span> <span class="n">vadd_hw</span><span class="o">.</span><span class="n">xclbin</span>
<span class="n">Loading</span><span class="p">:</span> <span class="s1">&#39;vadd_hw.xclbin&#39;</span>
<span class="o">-</span> <span class="n">host</span> <span class="n">loop</span> <span class="n">iteration</span> <span class="c1">#0 of 1 total iterations</span>
<span class="n">XRT</span> <span class="n">build</span> <span class="n">version</span><span class="p">:</span> <span class="mf">2.8.743</span>
<span class="n">Build</span> <span class="nb">hash</span><span class="p">:</span> <span class="mi">77</span><span class="n">d5484b5c4daa691a7f78235053fb036829b1e9</span>
<span class="n">Build</span> <span class="n">date</span><span class="p">:</span> <span class="mi">2020</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">16</span> <span class="mi">00</span><span class="p">:</span><span class="mi">19</span><span class="p">:</span><span class="mi">11</span>
<span class="n">Git</span> <span class="n">branch</span><span class="p">:</span> <span class="mf">2020.2</span>
<span class="n">PID</span><span class="p">:</span> <span class="mi">17233</span>
<span class="n">UID</span><span class="p">:</span> <span class="mi">31781</span>
<span class="p">[</span><span class="n">Mon</span> <span class="n">Jan</span> <span class="mi">11</span> <span class="mi">19</span><span class="p">:</span><span class="mi">28</span><span class="p">:</span><span class="mi">15</span> <span class="mi">2021</span> <span class="n">GMT</span><span class="p">]</span>
<span class="n">HOST</span><span class="p">:</span> <span class="n">xcodpeascoe40</span>
<span class="n">EXE</span><span class="p">:</span> <span class="o">/</span><span class="n">scratch</span><span class="o">/</span><span class="n">ravic</span><span class="o">/</span><span class="n">Vitis</span><span class="o">-</span><span class="n">In</span><span class="o">-</span><span class="n">Depth</span><span class="o">-</span><span class="n">Tutorial</span><span class="o">/</span><span class="n">Runtime_and_System_Optimization</span><span class="o">/</span><span class="n">Feature_Tutorials</span><span class="o">/</span><span class="mi">04</span><span class="o">-</span><span class="n">using</span><span class="o">-</span><span class="n">hbm</span><span class="o">/</span><span class="n">build</span><span class="o">/</span><span class="n">HBM_addSeq_2Banks_d512_txSize64</span><span class="o">/</span><span class="n">host</span>
<span class="p">[</span><span class="n">XRT</span><span class="p">]</span> <span class="n">ERROR</span><span class="p">:</span> <span class="n">std</span><span class="p">::</span><span class="n">bad_alloc</span>
<span class="o">./../</span><span class="n">reference_files</span><span class="o">/</span><span class="n">host</span><span class="o">.</span><span class="n">cpp</span><span class="p">:</span><span class="mi">162</span> <span class="n">Error</span> <span class="n">calling</span> <span class="n">err</span> <span class="o">=</span> <span class="n">krnl_vector_add</span><span class="o">.</span><span class="n">setArg</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">buffer_output</span><span class="p">[</span><span class="n">j</span><span class="p">]),</span> <span class="n">error</span> <span class="n">code</span> <span class="ow">is</span><span class="p">:</span> <span class="o">-</span><span class="mi">5</span>
<span class="p">[</span><span class="n">XRT</span><span class="p">]</span> <span class="n">WARNING</span><span class="p">:</span> <span class="n">Profiling</span> <span class="n">may</span> <span class="n">contain</span> <span class="n">incomplete</span> <span class="n">information</span><span class="o">.</span> <span class="n">Please</span> <span class="n">ensure</span> <span class="nb">all</span> <span class="n">OpenCL</span> <span class="n">objects</span> <span class="n">are</span> <span class="n">released</span> <span class="n">by</span> <span class="n">your</span> <span class="n">host</span> <span class="n">code</span> <span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">g</span><span class="o">.</span><span class="p">,</span> <span class="n">clReleaseProgram</span><span class="p">())</span><span class="o">.</span>
<span class="n">Makefile</span><span class="p">:</span><span class="mi">102</span><span class="p">:</span> <span class="n">recipe</span> <span class="k">for</span> <span class="n">target</span> <span class="s1">&#39;run&#39;</span> <span class="n">failed</span>
<span class="n">make</span><span class="p">:</span> <span class="o">***</span> <span class="p">[</span><span class="n">run</span><span class="p">]</span> <span class="n">Error</span> <span class="mi">1</span>
</pre></div>
</div>
<p>As expected, the application results in error as you are trying to create a 600 MB buffer in HBM[0:1]. XRT sees this as a contiguous memory of 256*2 = 512MB, but the host exceeds this size limit, resulting in an application error.</p>
<p>The provided Makefile adds the flexibility of creating your custom connectivity file by either using the <code class="docutils literal notranslate"><span class="pre">banks</span></code> argument. Make target has functionality available in mem_connectivity.mk to create the memory connectivity file.</p>
<ol class="simple">
<li><p>If the application doesn’t require the full memory bank, Vitis flow also provides the capability of sharing the memory banks across the ports. Here is one example of connectivity for sharing banks between ports in1 and in2.</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>connectivity<span class="o">]</span>
<span class="nv">sp</span><span class="o">=</span>vadd_1.in1:HBM<span class="o">[</span><span class="m">0</span>:1<span class="o">]</span>
<span class="nv">sp</span><span class="o">=</span>vadd_1.in2:HBM<span class="o">[</span><span class="m">1</span>:2<span class="o">]</span>
<span class="nv">sp</span><span class="o">=</span>vadd_1.out:HBM<span class="o">[</span><span class="m">3</span>:4<span class="o">]</span>
</pre></div>
</div>
<p>The ports in1 and in2 and sharing bank 1 of HBM. So the application can create buffers for each kernel port with 384MB as maximum size.</p>
<p>Run the following command to use the application with HBM memory of size 384MB for in1,in2, and out ports.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1">#make hbm_addSeq_overlap_build  - executed already in first module.</span>
make hbm_addSeq_overlap
</pre></div>
</div>
<p>The above command shows the following results.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>*** Running hw mode ***  Use Command Line to run application!
cd ./../build/HBM_overlapBanks_d512_txSize64 &amp;&amp;  ./host vadd_hw.xclbin 384 0 1 64;

 Total Data of 384.000 Mbytes to be written to global memory from host

 Kernel is invoked 1 time and repeats itself 1 times

Found Platform
Platform Name: Xilinx
DEVICE xilinx_u50_gen3x16_xdma_201920_3
INFO: Reading vadd_hw.xclbin
Loading: &#39;vadd_hw.xclbin&#39;
- host loop iteration #0 of 1 total iterations
kernel_time_in_sec = 0.0311151
Duration using events profiling: 30897093 ns
 match_count = 100663296 mismatch_count = 0 total_data_size = 100663296
Throughput Achieved = 13.0321 GB/s
TEST PASSED

</pre></div>
</div>
<p>When multiple ports are sharing overlapping bank and one (or more) of the buffer trying to utilize the overlapping portion, the order of assigning buffers (in the host code) to the corresponding kernel ports can become important. In this particular example both buffers for the ports in1 and  in2 are trying to utilize the overlapping bank 1 when each of them allocating 384Mb. Hence the host application must assigns buffer for in1 first and then assigns buffer for in2. Reversing this sequence will result into the <code class="docutils literal notranslate"><span class="pre">bad</span> <span class="pre">alloc</span></code> error. This is demonstrated in the following Figure.</p>
<p><img alt="Buffer Assignment for overlapping banks " src="../../../../_images/Buffer_allocation.png" /></p>
<p>In other words, there is no Lazy Allocation. The buffers are allocated upfront (and immediately) following the host code buffer handling order.</p>
<p>Additionally, you can also connect all the 32 HBM banks to each of the kernel ports based on the application requirement. This way, the whole memory space will be available to all the ports. The overall HBM efficiency will vary based on the access pattern and how many channels are being accessed, as described in the previous tutorial module.</p>
</div>
</div>
<div class="section" id="next-step">
<h1>Next Step<a class="headerlink" href="#next-step" title="Permalink to this heading">¶</a></h1>
<p>In the next steps, you will experiment with how to achieve the maximum bandwidth using all 32 channels as connectivity but accessing either 1 PC or a group of PCs from a single kernel port and varying the address patterns as transaction size.</p>
<p align="center"><b>
Start the next step: <a href="3_BW_Explorations.md"> HBM Bandwidth Results</a>
</b></p>
</br>
<hr/>
<p align="center"><b><a href="README.md">Return to Start of Tutorial</a></b></p><p align="center"><sup>Copyright&copy; 2021 Xilinx</sup></p></div>


           </div>
          </div>
          
                  <style>
                        .footer {
                        position: fixed;
                        left: 0;
                        bottom: 0;
                        width: 100%;
                        }
                  </style>
				  
				  <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019-2022, Xilinx, Inc. Xilinx is now a part of AMD.
      <span class="lastupdated">Last updated on July 27, 2022.
      </span></p>
  </div>



										<div class="aem-Grid aem-Grid--16">
											<div class="aem-GridColumn aem-GridColumn--xxxlarge--none aem-GridColumn--xsmall--16 aem-GridColumn--offset--xsmall--0 aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--xsmall--none aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
												<div class="container-fluid sub-footer">

													                    <div class="row">
                        <div class="col-xs-24">
                          <p><a target="_blank" href="https://www.amd.com/en/corporate/copyright">Terms and Conditions</a> | <a target="_blank" href="https://www.amd.com/en/corporate/privacy">Privacy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/cookies">Cookie Policy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/trademarks">Trademarks</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/statement-human-trafficking-forced-labor.pdf">Statement on Forced Labor</a> | <a target="_blank" href="https://www.amd.com/en/corporate/competition">Fair and Open Competition</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/amd-uk-tax-strategy.pdf">UK Tax Strategy</a> | <a target="_blank" href="https://docs.xilinx.com/v/u/9x6YvZKuWyhJId7y7RQQKA">Inclusive Terminology</a> | <a href="#cookiessettings" class="ot-sdk-show-settings">Cookies Settings</a></p>
                        </div>
                    </div>
												</div>
											</div>
										</div>
										
</br>


  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>