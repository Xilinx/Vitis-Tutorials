{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Copyright 2021 Xilinx Inc.\n",
    "# \n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "# \n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# \n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UQW00mw3ymJX",
    "outputId": "03391fb0-0e63-4fd0-dc62-cb0da60055e7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from pytorch_nndct.apis import torch_quantizer, dump_xmodel\n",
    "print(\"PyTorch version is \", torch.__version__)\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import random\n",
    "import time\n",
    "from random import shuffle\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from progressbar import ProgressBar\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "!pip3 install torchsummary \n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select GPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GPU if available   \n",
    "if (torch.cuda.device_count() > 0):\n",
    "    print('You have',torch.cuda.device_count(),'CUDA devices available')\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(' Device',str(i),': ',torch.cuda.get_device_name(i))\n",
    "    print('Selecting device 0..')\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    print('No CUDA devices available..selecting CPU')\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QEwdbt6MBcjS"
   },
   "source": [
    "## Download the 2018.01 Dataset from Deepsig\n",
    "Deepsig has released multiple data sets that can be found here https://www.deepsig.io/datasets\n",
    "\n",
    "This data set contains RF data with 24 different modulations at various SNR. Each of the 2555904 data inputs is 1024 samples long of complex (I Q) data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rCXtKzI3BiJ-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " !wget http://opendata.deepsig.io/datasets/2018.01/2018.01.OSC.0001_1024x2M.h5.tar.gz\n",
    " !pwd\n",
    " !ls\n",
    " !tar -xvzf 2018.01.OSC.0001_1024x2M.h5.tar.gz\n",
    " !ls\n",
    " !rm 2018.01.OSC.0001_1024x2M.h5.tar.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "46uELugqymJa"
   },
   "source": [
    "## 2018 Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in RF Data\n",
    "3 Arrays will be created. <br>\n",
    "myData holds the 1024 I and Q time values for each input sample. <br>\n",
    "myMods holds the one hot encoded RF class for each sample.<br>\n",
    "mySNRs holds the SNR value for each sample.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Adeih-_lymJa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_file = '/workspace/2018.01/GOLD_XYZ_OSC.0001_1024.hdf5'\n",
    "file_handle = h5.File(data_file,'r+')\n",
    "\n",
    "myData = file_handle['X'][:]  #1024x2 samples \n",
    "myMods = file_handle['Y'][:]  #mods \n",
    "mySNRs = file_handle['Z'][:]  #snrs  \n",
    "\n",
    "print(np.shape(myData))\n",
    "print(np.shape(myMods))\n",
    "print(np.shape(mySNRs))\n",
    "file_handle.close()\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jBYK1dSWAKyA"
   },
   "source": [
    "### List the SNRs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "n6tCNR5ky6TN",
    "outputId": "7ae528cf-72d5-4bb2-a795-8aa358a863b7"
   },
   "outputs": [],
   "source": [
    "snrs = list(np.unique(mySNRs.T[0]))  \n",
    "print(snrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Modulaton classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods = [\n",
    "    'OOK',      '4ASK',      '8ASK',      'BPSK',   'QPSK',    '8PSK',\n",
    "    '16PSK',    '32PSK',     '16APSK',    '32APSK', '64APSK',  '128APSK',\n",
    "    '16QAM',    '32QAM',     '64QAM',     '128QAM', '256QAM',  \n",
    "    'AM-SSB-WC','AM-SSB-SC', 'AM-DSB-WC', 'AM-DSB-SC', 'FM', 'GMSK','OQPSK']\n",
    "\n",
    "num_classes = np.shape(mods)[0]\n",
    "print(\"The number of classes is \", num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine RF input samples\n",
    "The samples in data set are ordered by class, let's print out one example from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn off warning about more than 10 figures plotted\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "def my_range(start, end, step):\n",
    "    while start <= end:\n",
    "        yield start\n",
    "        start += step\n",
    "\n",
    "size = np.size(myData, axis = 0)\n",
    "step = size//24\n",
    "\n",
    "for x in my_range(100000, (size-1), step):\n",
    "  plt.figure()\n",
    "  plt.suptitle( mods[np.argmax(myMods[x])])\n",
    "  plt.plot(myData[x,:,0])\n",
    "  plt.plot(myData[x,:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Input Data Range\n",
    "The input datat is close to being centered around 0, and since the standard deviation is around 1.57, most of the data lies between -6 an +6 with some outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Max value of the data set = \", np.max(myData))\n",
    "print (\"Min value of the data set = \", np.min(myData))\n",
    "print (\"Mean value of the data set = \", np.mean(myData))\n",
    "print (\"Standard Deviation of the data set \", np.std(myData) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets examine where the outlyers are comming from. We will see below that all data is between -5 an 5 expect for AM-SSB-WC and the AM-SSB-SC modulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = (myData.shape[0])\n",
    "limit = 5\n",
    "Max = np.zeros(length)\n",
    "Min = np.zeros(length)\n",
    "for i in range(0,length):\n",
    "  Max[i] = (np.max(myData[i,:,0]))\n",
    "  Min[i] = (np.min(myData[i,:,0]))\n",
    "  if(Max[i] > limit or Min[i] < -limit):\n",
    "   print (\"index =\", i, mods[np.argmax(myMods[i])])\n",
    "plt.figure()\n",
    "plt.plot(Max)\n",
    "plt.plot(Min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove AM-SSB-WC and AM-SSB_SC from the data set\n",
    "If we leave the AM-SSB-WC and AM-SSB-SC modulations in the data set we will see lower accuracy after quantizing the model to INT8. This is becuase we can more accurately quantize the floating point input data if it is over a smaller range with fewer outlyers as in seen in the other modulations \n",
    "\n",
    "In the next step we will remove these two modulations from the data set. If you want to leave these modulations in, you can skip the next step. Leaving these in will cause an additonal 5% accuracy drop after quantizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skip this entire panel if you want to leave AM-SSB-WC and AM-SSB-SC modulations in the data set\n",
    "myData = np.concatenate((myData[0:1810432], myData[2023424:2555904]),axis=0)\n",
    "mySNRs = np.concatenate((mySNRs[0:1810432], mySNRs[2023424:2555904]),axis=0)\n",
    "myMods = np.concatenate((myMods[0:1810432], myMods[2023424:2555904]),axis=0)\n",
    "\n",
    "#re-onehot encode myMods to 22 from 24\n",
    "length = (np.size(myMods, axis=0))\n",
    "temp = np.concatenate((myMods[:,0:17],myMods[:,19:24]), axis=1)\n",
    "myMods = temp\n",
    "\n",
    "mods = [\n",
    "    'OOK',      '4ASK',      '8ASK',      'BPSK',   'QPSK',    '8PSK',\n",
    "    '16PSK',    '32PSK',     '16APSK',    '32APSK', '64APSK',  '128APSK',\n",
    "    '16QAM',    '32QAM',     '64QAM',     '128QAM', '256QAM',  \n",
    "    'AM-DSB-WC', 'AM-DSB-SC', 'FM', 'GMSK','OQPSK']\n",
    "\n",
    "num_classes = np.shape(mods)[0]\n",
    "print(\"The number of classes is \", num_classes)\n",
    "\n",
    "\n",
    "print(np.shape(myData))\n",
    "print(np.shape(mySNRs))\n",
    "print(np.shape(myMods))\n",
    "\n",
    "print (\"Max value of the data set = \", np.max(myData))\n",
    "print (\"Min value of the data set = \", np.min(myData))\n",
    "print (\"Mean value of the data set = \", np.mean(myData))\n",
    "print (\"Standard Deviation of the data set \", np.std(myData) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets look at how the SNRs are distributed across the data set\n",
    "As you can see each SNR appears an equal number of times across the data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.suptitle(\"SNR Distribution\")\n",
    "plt.hist(mySNRs, bins = [-20, -18, -16, -14, -12, -10, -8, -6, -4, -2, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape RF data to 2D Matrix\n",
    "We will reshape both the I and Q data from a 1024 long vector to 2D matrix to be conpatabile with 2D convolution commands supported by the DPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = myData.reshape(myData.shape[0], 32, 32, 2) \n",
    "# Change to N,C,H,W\n",
    "myData = np.transpose(myData, (0,3,1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slpit Data into Trainnig and Validation set\n",
    "We will use 80% of the data for the Training set and 20% for the Test set. \n",
    "The random_state input to the the train_test_split function is set to 0, which means the 80/20 split will be done in a repeatable manner. The splt is done using the scikir-learn tran_test_split function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "En0je_7oymJg",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train ,X_test ,Y_train ,Y_test, Z_train, Z_test =train_test_split(myData, myMods, mySNRs, test_size=0.2, random_state=0)\n",
    "\n",
    "print (np.shape(X_test))\n",
    "print (np.shape(Y_test))\n",
    "print (np.shape(Z_test))\n",
    "print (np.shape(X_train))\n",
    "print (np.shape(Y_train))\n",
    "print (np.shape(Z_train))\n",
    "\n",
    "# remove variables to save memory\n",
    "del myData, myMods, mySNRs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Dataset Class and loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RfDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, Y_data):\n",
    "        self.X_data = X_data\n",
    "        self.Y_data = Y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.Y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "batch_size = 1024\n",
    "train_dataset = RfDataset(torch.from_numpy(X_train).float(), torch.from_numpy(Y_train))\n",
    "test_dataset = RfDataset(torch.from_numpy(X_test).float(), torch.from_numpy(Y_test))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,  shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Simple CNN  Model \n",
    "Here we construct a model with 4 convolutiona layers, followed by 3 fc layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,p):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(2, 32, kernel_size=(5,5), stride=1, padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=(5,5), stride=1, padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=(5,5), stride=1, padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 16, kernel_size=(5,5), stride=2,  padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear((16*8*8), 256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Linear(128, 22),\n",
    "            nn.Softmax(dim=1)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        return x\n",
    "    \n",
    "# model summary\n",
    "model = CNN(0.5).to(device)\n",
    "summary (model, (2, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets verify that our model is working. \n",
    "Because the weight are unitialize, all the probabilites will be close to a random guess of 0.045 (1/22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=  torch.from_numpy(X_test[0:1])\n",
    "print(np.size(X_test[0]))\n",
    "inputs = inputs.to(device)\n",
    "predict = model.eval()(inputs)\n",
    "print(np.size(predict))\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cMSL0_bAymJq"
   },
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Training and Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, criterion, optimizer, epoch):\n",
    "    '''\n",
    "    train the model\n",
    "    '''\n",
    "    model.train()\n",
    "    counter = 0\n",
    "    epoch_loss = 0\n",
    " \n",
    "    print(\"\\nEpoch \"+str(epoch), end=\" \")\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, torch.max(target, 1)[1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        counter += 1\n",
    "        if (counter%20 == 1):\n",
    "             print(end=\".\")\n",
    "    epoch_loss += output.shape[0] * loss.item()\n",
    "    return epoch_loss\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    '''\n",
    "    test the model\n",
    "    '''\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            target = target.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    acc = 100. * correct / len(test_loader.dataset)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EQ7cwvmzymJw",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!mkdir -p checkpoints\n",
    "nb_epoch = 200 # number of epochs to train on\n",
    "learnrate = 0.0002\n",
    "optimizer = optim.Adam(model.parameters(), lr=learnrate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "best_acc = 0\n",
    "stop_count = 0\n",
    "# training with test after each epoch\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    loss= train(model, device, train_loader, criterion, optimizer, epoch)\n",
    "    print(\"\\nTraining Loss: \", loss/len(train_loader))\n",
    "    new_acc = test(model, device, test_loader)\n",
    "    print(\"Test Set Accuracy:\",format(new_acc), \"%\")\n",
    "\n",
    "    if(new_acc <= best_acc):\n",
    "        stop_count += 1\n",
    "    else:\n",
    "        stop_count = 0\n",
    "        best_acc = new_acc\n",
    "        # save checkpoint\n",
    "        torch.save(model.state_dict(),\"/workspace/checkpoints/model.pth\")\n",
    "    if(stop_count == 5):\n",
    "        print(\"No improvment in accuracy, early stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GzDFfRgo9uC7"
   },
   "source": [
    "## Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LGm7zfUjymJx",
    "outputId": "3d306543-1b13-4af8-ef3b-6e1e536e972d"
   },
   "outputs": [],
   "source": [
    "#Reload model weights in case it was closed. \n",
    "model.load_state_dict(torch.load(\"/workspace/checkpoints/model.pth\"))\n",
    "score = test(model, device, test_loader)\n",
    "print(\"Model Accuracy:\",score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Top1 accuracy should be close to 54%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XyDZgJ1oA3NG"
   },
   "source": [
    "### Generate Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6rz_n1bA5_1"
   },
   "outputs": [],
   "source": [
    "batchsize = 1024\n",
    "total_batches = int(np.shape(X_test)[0]/batchsize) \n",
    "y_pred = []\n",
    "y_actual = []\n",
    "\n",
    "for i in (range(0, total_batches)):\n",
    "   x_batch = X_test[i*batchsize:i*batchsize+batchsize]\n",
    "   inputs =  torch.from_numpy(x_batch)\n",
    "   inputs = inputs.to(device)\n",
    "   Y_pred = model.eval()(inputs)\n",
    "   Y_pred_cpu = Y_pred.cpu().detach().numpy()\n",
    "   y_pred[i*batchsize:i*batchsize+batchsize] = np.argmax(Y_pred_cpu, axis = 1)\n",
    "   y_actual[i*batchsize:i*batchsize+batchsize] = np.argmax(Y_test[i*batchsize:i*batchsize+batchsize], axis = 1)\n",
    "classificationreport_fp = classification_report(y_actual,y_pred, target_names=mods)\n",
    "print(classificationreport_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision Measures the  Accuracy of the positive predictions.\n",
    "Precision = TP/(TP + FP)\n",
    "\n",
    "Recall Measures the fraction of positives that were correctly identified.\n",
    "Recall = TP/(TP+FN)\n",
    "\n",
    "The F1 score is measure of a weighted harmonic mean of precision and recall. \n",
    "\n",
    "Support is the number of values for each class.\n",
    "\n",
    "Looking at the f1- scores for the different classes, we can see that the model is more accuracte with some classses than others.\n",
    "For example, the model is not able to correctly identify the higher order PSK and QAM modulations as other classes.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy vs. SNR\n",
    "Now lets see how the model accuracy is effcted by SNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load model in case it was closed\n",
    "model = CNN(0).to(device)\n",
    "model.load_state_dict(torch.load('/workspace/checkpoints/model.pth'))\n",
    "model.eval() \n",
    "\n",
    "batchsize = 1024\n",
    "progress = ProgressBar()\n",
    "snrlist = np.unique(Z_test)\n",
    "acc_snr_arr = []\n",
    "\n",
    "# interate over SNRs\n",
    "for snr in progress(snrlist):\n",
    "    acc_arr = []\n",
    "    i_SNR = np.where(Z_test==snr)\n",
    "    X_SNR = X_test[i_SNR[0],:,:]\n",
    "    Y_SNR = Y_test[i_SNR[0],:]\n",
    "    X_SNR_len = np.shape(X_SNR)[0]\n",
    "    total_batches = int(X_SNR_len/batchsize)\n",
    "    \n",
    "    for i in (range(0, total_batches)):\n",
    "        x_batch, y_batch = X_SNR[i*batchsize:i*batchsize+batchsize], Y_SNR[i*batchsize:i*batchsize+batchsize]\n",
    "        \n",
    "        # model prediction\n",
    "        inputs=  torch.from_numpy(x_batch)\n",
    "        inputs = inputs.to(device)\n",
    "        pred = model(inputs)\n",
    "        pred = pred.cpu().detach().numpy()\n",
    "        \n",
    "        #Pediction values are onehote, corresponding to indices representing different modulation types\n",
    "        pred_ind = np.argmax(pred, axis=1)\n",
    "        expected_ind = np.argmax(y_batch, axis=1)\n",
    "        matches  = sum(np.equal(pred_ind, expected_ind))\n",
    "        acc      = matches/batchsize\n",
    "        acc_arr.append(acc)\n",
    "\n",
    "    # Average the per-batch accuracy values\n",
    "    accuracy = np.mean(acc_arr)\n",
    "    acc_snr_arr.append(accuracy)\n",
    "    print(\"SNR: \", snr, \"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(1,1))\n",
    "plt.show()\n",
    "fig= plt.figure(figsize=(10,8))\n",
    "plt.plot(snrlist, acc_snr_arr, 'bo-', label='accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('SNR')\n",
    "plt.title(\"Accuracy vs, SNR for Floating Point Model\")\n",
    "plt.legend()\n",
    "plt.axis([-22, 32, 0, 1.0])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are you can see accurccy SNRs below -10db the Top1 accuracy is no better than a random guess (1/24), and once SNR is above 10db the Top1 accuracy is over 80%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vitis AI\n",
    "The Vitis-AI tools will be used the Quantize and Compile the model for accleration on the DPU. <br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize Model to INT8\n",
    "The Vitis-AI Quantizer uses a  small set of unlabeled samples to analyze the distribution of the activations. We will use 1000 input samples from the test set, and enable Fast Fine Tuning <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(device, float_model, quant_mode, batchsize, fast_finetune, deploy, output_dir):\n",
    "  # load trained model\n",
    "  model = CNN(0).to(device)\n",
    "  model.load_state_dict(torch.load(float_model))\n",
    "\n",
    "  # force to merge BN with CONV for better quantization accuracy\n",
    "  optimize = 1\n",
    "  subset_len = 1000\n",
    "\n",
    "  # override batchsize if in test mode\n",
    "  if (quant_mode=='test' and deploy):\n",
    "      if(batchsize != 1):\n",
    "        print(\"Forcing batch size to 1\")\n",
    "        batchsize = 1\n",
    "  \n",
    "  input = torch.randn([batchsize, 2, 32, 32])\n",
    "  quantizer = torch_quantizer(quant_mode, model, input, bitwidth=8, output_dir=output_dir) \n",
    "  quantized_model = quantizer.quant_model\n",
    "\n",
    "  calib_dataset = RfDataset(torch.from_numpy(X_test[0:subset_len]), torch.from_numpy(Y_test[0:subset_len]))\n",
    "  calib_loader = torch.utils.data.DataLoader(calib_dataset, batch_size=batchsize,  shuffle=False)\n",
    "    \n",
    "  if fast_finetune == True:  \n",
    "    if quant_mode == 'calib':\n",
    "      test(quantized_model, device, calib_loader)  \n",
    "      quantizer.fast_finetune(test, (quantized_model, device, calib_loader))     \n",
    "    elif quant_mode == 'test':   \n",
    "      quantizer.load_ft_param()\n",
    "   \n",
    "  # export config\n",
    "  if quant_mode == 'calib':\n",
    "    test(quantized_model, device, calib_loader)\n",
    "    quantizer.export_quant_config()\n",
    "  # handle quantization result\n",
    "  elif quant_mode == 'test':\n",
    "    if(deploy): \n",
    "         quantizer.export_xmodel(deploy_check=False, output_dir=output_dir)\n",
    "    else:\n",
    "      acc = test(model, device, calib_loader)\n",
    "      print(\"Calibration Data Set Accuracy for Floating Point model: \",format(acc))\n",
    "      acc = test(quantized_model, device, calib_loader)\n",
    "      print(\"Calibration Data Set Accuracy for Quantized model: \",format(acc))\n",
    "     \n",
    "  return quantized_model\n",
    "\n",
    "FastTune = True\n",
    "DeployMode = False \n",
    "# generate quantized model\n",
    "quantize(device, '/workspace/checkpoints/model.pth', 'calib', 10, FastTune, DeployMode, '/workspace/quant_model')\n",
    "         \n",
    "# evalute quantized model\n",
    "quantize(device, '/workspace/checkpoints/model.pth', 'test', 10, FastTune, DeployMode, '/workspace/quant_model')\n",
    "\n",
    "DeployMode = True\n",
    "# generate xmodel for compilation\n",
    "quantized_model = quantize(device, '/workspace/checkpoints/model.pth', 'test', 1, FastTune,  DeployMode, '/workspace/quant_model')\n",
    "\n",
    "!ls -l /workspace/quant_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalute  Model INT8 Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score = test(quantized_model, device, test_loader)\n",
    "print(\"Test Set Accuracy of Quantized Model:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Overall Top-1 score has gone down by about 1.5% due to quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report for INT8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batchsize = 1024\n",
    "total_batches = int(np.shape(X_test)[0]/batchsize) \n",
    "y_pred = []\n",
    "y_actual = []\n",
    "\n",
    "for i in (range(0, total_batches)):\n",
    "   x_batch = X_test[i*batchsize:i*batchsize+batchsize]\n",
    "   inputs =  torch.from_numpy(x_batch)\n",
    "   inputs = inputs.to(device)\n",
    "   Y_pred = quantized_model.eval()(inputs)\n",
    "   Y_pred_cpu = Y_pred.cpu().detach().numpy()\n",
    "   y_pred[i*batchsize:i*batchsize+batchsize] = np.argmax(Y_pred_cpu, axis = 1)\n",
    "   y_actual[i*batchsize:i*batchsize+batchsize] = np.argmax(Y_test[i*batchsize:i*batchsize+batchsize], axis = 1)\n",
    "classificationreport_fp = classification_report(y_actual,y_pred, target_names=mods)\n",
    "print(classificationreport_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy vs SNR for INT8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batchsize = 1024\n",
    "progress = ProgressBar()\n",
    "snrlist = np.unique(Z_test)\n",
    "acc_snr_arr = []\n",
    "\n",
    "# interate over SNRs\n",
    "for snr in progress(snrlist):\n",
    "    acc_arr = []\n",
    "    i_SNR = np.where(Z_test==snr)\n",
    "    X_SNR = X_test[i_SNR[0],:,:]\n",
    "    Y_SNR = Y_test[i_SNR[0],:]\n",
    "    X_SNR_len = np.shape(X_SNR)[0]\n",
    "    total_batches = int(X_SNR_len/batchsize)\n",
    "    \n",
    "    for i in (range(0, total_batches)):\n",
    "        x_batch, y_batch = X_SNR[i*batchsize:i*batchsize+batchsize], Y_SNR[i*batchsize:i*batchsize+batchsize]\n",
    "        \n",
    "        # model prediction\n",
    "        inputs=  torch.from_numpy(x_batch)\n",
    "        inputs = inputs.to(device)\n",
    "        pred = quantized_model(inputs)\n",
    "        pred = pred.cpu().detach().numpy()\n",
    "        \n",
    "        #Pediction values are onehote, corresponding to indices representing different modulation types\n",
    "        pred_ind = np.argmax(pred, axis=1)\n",
    "        expected_ind = np.argmax(y_batch, axis=1)\n",
    "        matches  = sum(np.equal(pred_ind, expected_ind))\n",
    "        acc      = matches/batchsize\n",
    "        acc_arr.append(acc)\n",
    "\n",
    "    # Average the per-batch accuracy values\n",
    "    accuracy = np.mean(acc_arr)\n",
    "    acc_snr_arr.append(accuracy)\n",
    "    print(\"SNR: \", snr, \"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(1,1))\n",
    "plt.show()\n",
    "fig= plt.figure(figsize=(10,8))\n",
    "plt.plot(snrlist, acc_snr_arr, 'bo-', label='accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('SNR')\n",
    "plt.title(\"Accuracy vs, SNR for INT8 Model\")\n",
    "plt.legend()\n",
    "plt.axis([-22, 32, 0, 1.0])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Accuracy vs SNR looks very similar to the floating point model, expect the accuracy is down by about 2% for higher SNRs from the floating point model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model for DPU\n",
    "The Vitis-AI compiler reads in the quantized model and generates an xmodel file which the instruction set for the Xilinx Deep Learning Processor (DPU). The arhictecture option (-a) is used to specify a json file which indicates which hw target the DPU is being compiled for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select HW Target\n",
    "#For ZCU104\n",
    "#!vai_c_xir -x /workspace/quant_model/CNN_int.xmodel -a /opt/vitis_ai/compiler/arch/DPUCZDX8G/ZCU104/arch.json -o vai_c_output -n rfClassification --options \"{'cpu_arch':'arm64', 'mode':'normal', 'save_kernel':''}\"\n",
    "\n",
    "#For ZCU102 \n",
    "#!vai_c_xir -x /workspace/quant_model/CNN_int.xmodel -a /opt/vitis_ai/compiler/arch/DPUCZDX8G/ZCU102/arch.json -o vai_c_output -n rfClassification --options \"{'cpu_arch':'arm64', 'mode':'normal', 'save_kernel':''}\"\n",
    "\n",
    "#For Alveo U50\n",
    "#!vai_c_xir -x /workspace/quant_model/CNN_int.xmodel -a /opt/vitis_ai/compiler/arch/DPUCAHX8H/U50/arch.json -o vai_c_output -n rfClassification --options \"{'cpu_arch':'arm64', 'mode':'normal', 'save_kernel':''}\"\n",
    "\n",
    "#For Versal VCK190\n",
    "!vai_c_xir -x /workspace/quant_model/CNN_int.xmodel -a /opt/vitis_ai/compiler/arch/DPUCVDX8G/VCK190/arch.json -o vai_c_output -n rfClassification --options \"{'cpu_arch':'arm64', 'mode':'normal', 'save_kernel':''}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Graph Visualization with xir tool.\n",
    "You will see a compiler message about the number of  subgraphs:\n",
    "Total device subgraph number 3, DPU subgraph number 1 <br>\n",
    "This means that are 3 subgraphs created, 1 for the input layer, 1 for for everything up the softmax layer (which runs on the DPU), and one for the softmax. <br>\n",
    "\n",
    "The softmax layer can  optionally be acclerated in programmable logic, however in this tutorial we will implement the softmax layer on the CPU.\n",
    "\n",
    "You can use the the xir command generate a .png file to visulize the graph layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls  vai_c_output/rfClassification.xmodel\n",
    "!xir png vai_c_output/rfClassification.xmodel xmodel.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out  samples  of Test Data to be used later for HW testing\n",
    "The python function we will run in the target board will read in these numpy files containing the RF data, class, and SNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/workspace/rf_input.npy', np.transpose(X_test[0:1000], (0,2,3,1)))\n",
    "np.save('/workspace/rf_classes.npy', Y_test[0:1000])\n",
    "np.save('/workspace/rf_snrs.npy', Z_test[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfIn=np.load('/workspace/rf_input_works.npy')\n",
    "rfClasses=np.load('/workspace/rf_classes_works.npy')\n",
    "rfSNRs=np.load('/workspace/rf_snrs_works.npy')\n",
    "\n",
    "print(np.shape(rfIn[0]))\n",
    "print(rfIn[0])\n",
    "print(rfClasses[0])\n",
    "print(rfSNRs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that a dpu xmodel file has been created you are ready to run on target board. You will need to copy the above 3 files, and the xmodel file from the compiler to your target board.\n",
    "\n",
    "You can close this notebook by entering CtrlC at the console, close the docker container by entering CtrlD, and the proceed with the Tutorial readme instructions."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "QEwdbt6MBcjS",
    "46uELugqymJa"
   ],
   "name": "Import 2018 RadioML.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
