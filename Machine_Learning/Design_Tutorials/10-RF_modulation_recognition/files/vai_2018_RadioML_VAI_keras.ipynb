{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Copyright 2020 Xilinx Inc.\n",
    "# \n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "# \n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# \n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UQW00mw3ymJX",
    "outputId": "03391fb0-0e63-4fd0-dc62-cb0da60055e7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version is  2.3.0\n",
      "Keras version      :  2.4.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow import Tensor\n",
    "print(\"Tensorflow version is \", tf.__version__)\n",
    "print('Keras version      : ',keras.__version__)\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import random\n",
    "import time\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Conv2DTranspose, Concatenate, BatchNormalization, UpSampling2D\n",
    "from tensorflow.keras.layers import  Dropout, Activation, GlobalAveragePooling1D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD, Adadelta\n",
    "from tensorflow.keras.layers import Reshape, Dense, Flatten, Add\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, History\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from random import shuffle\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from progressbar import ProgressBar\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QEwdbt6MBcjS"
   },
   "source": [
    "## Download the 2018.01 Dataset from Deepsig\n",
    "Deepsig has released multiple RF data sets, we are using the 2018 dataset.\n",
    "\n",
    "This data set contains RF data with 24 different modulations at various SNR. Each of the 2555904 data inputs is 1024 samples long of complex (I Q) data.\n",
    "\n",
    "You need to register  with Deepsig in order to download the dataset, go to https://www.deepsig.io/datasets, select the link for Dataset Download: 2018.01.OSC.0001_1024x2M.h5.tar.gz, register, dowlnload the file, and copy to the same directory containing this Jupyter notebook \n",
    "\n",
    "Note that the modulatiom class order in classes.tx is incorrect, and you should use the modulation class order as in this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rCXtKzI3BiJ-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " !pwd\n",
    " !ls\n",
    " !tar -xvzf 2018.01.OSC.0001_1024x2M.h5.tar.gz\n",
    " !ls\n",
    " !rm 2018.01.OSC.0001_1024x2M.h5.tar.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "46uELugqymJa"
   },
   "source": [
    "## 2018 Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in RF Data\n",
    "3 Arrays will be created. <br>\n",
    "myData holds the 1024 I and Q time values for each input sample. <br>\n",
    "myMods holds the one hot encoded RF class for each sample.<br>\n",
    "mySNRs holds the SNR value for each sample.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Adeih-_lymJa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Note this is needed to aviod a tensorFlow memory issue\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "data_file = '/workspace/files/2018.01/GOLD_XYZ_OSC.0001_1024.hdf5'\n",
    "file_handle = h5.File(data_file,'r+')\n",
    "\n",
    "myData = file_handle['X'][:]  #1024x2 samples \n",
    "myMods = file_handle['Y'][:]  #mods \n",
    "mySNRs = file_handle['Z'][:]  #snrs  \n",
    "\n",
    "print(np.shape(myData))\n",
    "print(np.shape(myMods))\n",
    "print(np.shape(mySNRs))\n",
    "file_handle.close()\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jBYK1dSWAKyA"
   },
   "source": [
    "### List the SNRs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "n6tCNR5ky6TN",
    "outputId": "7ae528cf-72d5-4bb2-a795-8aa358a863b7"
   },
   "outputs": [],
   "source": [
    "snrs = list(np.unique(mySNRs.T[0]))  \n",
    "print(snrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Modulaton classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods = [\n",
    "    'OOK',      '4ASK',      '8ASK',      'BPSK',   'QPSK',    '8PSK',\n",
    "    '16PSK',    '32PSK',     '16APSK',    '32APSK', '64APSK',  '128APSK',\n",
    "    '16QAM',    '32QAM',     '64QAM',     '128QAM', '256QAM',  \n",
    "    'AM-SSB-WC','AM-SSB-SC', 'AM-DSB-WC', 'AM-DSB-SC', 'FM', 'GMSK','OQPSK']\n",
    "\n",
    "num_classes = np.shape(mods)[0]\n",
    "print(\"The number of classes is \", num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine RF input samples\n",
    "The samples in data set are ordered by class, let's print out one example from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn off warning about more than 10 figures plotted\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "def my_range(start, end, step):\n",
    "    while start <= end:\n",
    "        yield start\n",
    "        start += step\n",
    "\n",
    "size = np.size(myData, axis = 0)\n",
    "step = size//24\n",
    "\n",
    "for x in my_range(100000, (size-1), step):\n",
    "  plt.figure()\n",
    "  plt.suptitle( mods[np.argmax(myMods[x])])\n",
    "  plt.plot(myData[x,:,0])\n",
    "  plt.plot(myData[x,:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Input Data Range\n",
    "The input datat is close to being centered around 0, and since the standard deviation is around 1.57, most of the data lies between -6 an +6 with some outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Max value of the data set = \", np.max(myData))\n",
    "print (\"Min value of the data set = \", np.min(myData))\n",
    "print (\"Mean value of the data set = \", np.mean(myData))\n",
    "print (\"Standard Deviation of the data set \", np.std(myData) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets examine where the outlyers are comming from. We will see below that all data is between -5 an 5 expect for AM-SSB-WC and the AM-SSB-SC modulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len = (myData.shape[0])\n",
    "limit = 5\n",
    "Max = np.zeros(len)\n",
    "Min = np.zeros(len)\n",
    "for i in range(0,len):\n",
    "  Max[i] = (np.max(myData[i,:,0]))\n",
    "  Min[i] = (np.min(myData[i,:,0]))\n",
    "  if(Max[i] > limit or Min[i] < -limit):\n",
    "   print (\"index =\", i, mods[np.argmax(myMods[i])])\n",
    "plt.figure()\n",
    "plt.plot(Max)\n",
    "plt.plot(Min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove AM-SSB-WC and AM-SSB_SC from the data set\n",
    "If we leave the AM-SSB-WC and AM-SSB-SC modulations in the data set we will see lower accuracy after quantizing the model to INT8. This is becuase we can more accurately quantize the floating point input data if it is over a smaller range with fewer outlyers as in seen in the other modulations \n",
    "\n",
    "In the next step we will remove these two modulations from the data set. If you want to leave these modulations in, you can skip the next step. Leaving these in will cause an additonal 5% accuracy drop after quantizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skip this entire panel if you want to leave AM-SSB-WC and AM-SSB-SC modulations in the data set\n",
    "myData = np.concatenate((myData[0:1810432], myData[2023424:2555904]),axis=0)\n",
    "mySNRs = np.concatenate((mySNRs[0:1810432], mySNRs[2023424:2555904]),axis=0)\n",
    "myMods = np.concatenate((myMods[0:1810432], myMods[2023424:2555904]),axis=0)\n",
    "\n",
    "#re-onehot encode myMods to 22 from 24\n",
    "length = (np.size(myMods, axis=0))\n",
    "temp = np.concatenate((myMods[:,0:17],myMods[:,19:24]), axis=1)\n",
    "myMods = temp\n",
    "\n",
    "mods = [\n",
    "    'OOK',      '4ASK',      '8ASK',      'BPSK',   'QPSK',    '8PSK',\n",
    "    '16PSK',    '32PSK',     '16APSK',    '32APSK', '64APSK',  '128APSK',\n",
    "    '16QAM',    '32QAM',     '64QAM',     '128QAM', '256QAM',  \n",
    "    'AM-DSB-WC', 'AM-DSB-SC', 'FM', 'GMSK','OQPSK']\n",
    "\n",
    "num_classes = np.shape(mods)[0]\n",
    "print(\"The number of classes is \", num_classes)\n",
    "\n",
    "\n",
    "print(np.shape(myData))\n",
    "print(np.shape(mySNRs))\n",
    "print(np.shape(myMods))\n",
    "\n",
    "print (\"Max value of the data set = \", np.max(myData))\n",
    "print (\"Min value of the data set = \", np.min(myData))\n",
    "print (\"Mean value of the data set = \", np.mean(myData))\n",
    "print (\"Standard Deviation of the data set \", np.std(myData) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets look at how the SNRs are distributed across the data set\n",
    "As you can see each SNR appears an equal number of times across the data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.suptitle(\"SNR Distribution\")\n",
    "plt.hist(mySNRs, bins = [-20, -18, -16, -14, -12, -10, -8, -6, -4, -2, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape RF data to 2D Matrix\n",
    "We will reshape both the I and Q data from a 1024 long vector to 2D 1024x1 matrix to be conpatabile with 2D convolution commands supported by the DPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = myData.reshape(myData.shape[0], 1024, 1, 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slpit Data into Trainnig and Validation set\n",
    "We will use 80% of the data for the Training set and 20% for the Test set. \n",
    "The random_state input to the the train_test_split function is set to 0, which means the 80/20 split will be done in a repeatable manner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "En0je_7oymJg"
   },
   "outputs": [],
   "source": [
    "X_train ,X_test ,Y_train ,Y_test, Z_train, Z_test =train_test_split(myData, myMods, mySNRs, test_size=0.2, random_state=0)\n",
    "print (np.shape(X_test))\n",
    "print (np.shape(Y_test))\n",
    "print (np.shape(Z_test))\n",
    "print (np.shape(X_train))\n",
    "print (np.shape(Y_train))\n",
    "print (np.shape(Z_train))\n",
    "del myData, myMods, mySNRs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Simple Resnet  Model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This resnet model was inspired by the model disussed in the following paper <br>\n",
    "Over-the-Air Deep Learning Based Radio Signal Classification, <br>\n",
    "IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, VOL. 12, NO. 1, <br>\n",
    "FEBRUARY 2018 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shp = list(X_train.shape[1:])\n",
    "print(\"Dataset Shape={0} CNN Model Input layer={1}\".format(X_train.shape, input_shp))\n",
    "classes = mods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we construct a resnet block which will be used multiple times in our model. In order to be compatabile with the Vitis-AI compilation tools we need to use a square kernel size (2x2) for the MaxPooling layer. Since the data is rectangular 1024x1, 512x1, ... we have enabled padding so the a square kernel size can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(input_data, filters, conv_size):\n",
    "  x = Conv2D(filters, 1, activation=None, padding='same')(input_data)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = Conv2D(filters, conv_size, activation=None, padding='same')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = Conv2D(filters, conv_size, activation=None, padding='same')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Add()([x, input_data])\n",
    "  x = Activation('relu')(x)\n",
    "    \n",
    "  y = Conv2D(filters, conv_size, activation=None, padding='same')(x)\n",
    "  y = BatchNormalization()(y)\n",
    "  y = Activation('relu')(y)\n",
    "  y = Conv2D(filters, conv_size, activation=None, padding='same')(y)\n",
    "  y = BatchNormalization()(y)    \n",
    "  y = Add()([y, x])\n",
    "  y = Activation('relu')(y)\n",
    "  \n",
    "  z = MaxPooling2D(2, strides = (2,1), padding = 'same') (y)\n",
    "  return z\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we construct a model with 4 resnet_blocks.\n",
    "Note the 8x8 reshape layer before the GlobalAveragePooling2D layer. This is needed to reshape the 32x1 data shape to 8x8 to be compatabile with the Vitis-AI compilation tools, as the Xilinx DPU only supports square data shapes for this layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using 6 blocks will give small accuracy impprovment with 5% decrease in performance\n",
    "#num_resnet_blocks = 6\n",
    "\n",
    "num_resnet_blocks = 4\n",
    "num_filters = 32\n",
    "kernel_size = 5,1\n",
    "\n",
    "rf_input = Input(shape=input_shp, name = 'rf_input')\n",
    "\n",
    "x = Conv2D(num_filters, (kernel_size), activation=None, padding='same')(rf_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "for i in range(num_resnet_blocks):\n",
    "    x = resnet_block(x, num_filters, (kernel_size))\n",
    "\n",
    "x = Conv2D(num_filters, (kernel_size), activation=None, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# use if number of resnet blocks = 6\n",
    "#x = Reshape((4,4,num_filters), input_shape = (16,1,num_filters)) (x)\n",
    "\n",
    "# use if number of resent blocks = 4\n",
    "x = Reshape((8,8,num_filters), input_shape = (32,1,num_filters)) (x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "dense_1 = Dense(256, activation='relu')(x)\n",
    "dropout_1 = Dropout(0.5)(dense_1)\n",
    "dense_2 = Dense(128, activation='relu')(dropout_1)\n",
    "dropout_2 = Dropout(0.5)(dense_2)\n",
    "dense_3 = Dense(num_classes)(dropout_2)          \n",
    "softmax = Activation('softmax', name = 'softmax')(dense_3)\n",
    "\n",
    "optimizer= Adam(learning_rate=0.00050)\n",
    "model = keras.Model(rf_input, softmax)\n",
    "model.compile(loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets verify that our model is working. Because the weight are unitialize, all the probabilites will be close to a random guess of 0.045 (1/22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X_test[0:1])\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cMSL0_bAymJq"
   },
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up batch and epoch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3E-wFME2ymJr"
   },
   "outputs": [],
   "source": [
    "nb_epoch = 100     # number of epochs to train on\n",
    "batch_size = 1024  # training batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stoping callback \n",
    "Will end training after 5 epochs with no accuracy improvement on test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ta0SARPrymJu"
   },
   "outputs": [],
   "source": [
    "### Callback\n",
    "checkpoint_dir = 'resnet_checkpoints'\n",
    "os.mkdir(checkpoint_dir)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath =checkpoint_dir + '/best_checkpoint.h5', \n",
    "                                                 verbose = 1,\n",
    "                                                 save_best_only=True, \n",
    "                                                 save_weights_only=False,\n",
    "                                                 mode='auto')\n",
    "earlystopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        patience = 5,\n",
    "        mode='auto',\n",
    "        verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EQ7cwvmzymJw",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train,\n",
    "    Y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=nb_epoch,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    callbacks = [ cp_callback,earlystopping_callback]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Completed\n",
    "Reload the best weights once training is fininsed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ItplNjS8LIG"
   },
   "outputs": [],
   "source": [
    "best_checkpoint = checkpoint_dir + '/best_checkpoint.h5'\n",
    "model.load_weights(best_checkpoint)\n",
    "!mkdir -p fp_model\n",
    "model.save ('fp_model/resnet_fp_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GzDFfRgo9uC7"
   },
   "source": [
    "## Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LGm7zfUjymJx",
    "outputId": "3d306543-1b13-4af8-ef3b-6e1e536e972d"
   },
   "outputs": [],
   "source": [
    "# Show simple version of performance\n",
    "score = model.evaluate(X_test, Y_test,  verbose=0, batch_size=batch_size)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Top1 accuracy should be 62%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gox9CWdACnLu"
   },
   "source": [
    "\n",
    "### Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f_OFiHDV-GoJ"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues, labels=[]):\n",
    "    plt.figure(figsize = (15,10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    label_len = np.shape(labels)[0]\n",
    "    tick_marks = np.arange(label_len)\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    plt.tight_layout()    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8XRaiXXT-GrO"
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "test_Y_hat = model.predict(X_test, batch_size=batch_size)\n",
    "conf = np.zeros([num_classes,num_classes])\n",
    "confnorm = np.zeros([num_classes,num_classes])\n",
    "for i in range(0,X_test.shape[0]):\n",
    "    j = list(Y_test[i,:]).index(1)\n",
    "    k = int(np.argmax(test_Y_hat[i,:]))\n",
    "    conf[j,k] = conf[j,k] + 1\n",
    "for i in range(0,num_classes):\n",
    "    confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "colab_type": "code",
    "id": "XqFSoOf0DVH4",
    "outputId": "15e76181-bd33-46cb-f707-474a03d7afa7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confnorm, labels=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XyDZgJ1oA3NG"
   },
   "source": [
    "### Generate Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6rz_n1bA5_1"
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test,batch_size=batch_size)\n",
    "y_pred = np.argmax(Y_pred, axis = 1)\n",
    "y_actual = np.argmax(Y_test, axis = 1)\n",
    "classificationreport_fp = classification_report(y_actual,y_pred, target_names=mods)\n",
    "print(classificationreport_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision Measures the  Accuracy of the positive predictions.\n",
    "Precision = TP/(TP + FP)\n",
    "\n",
    "Recall Measures the fraction of positives that were correctly identified.\n",
    "Recall = TP/(TP+FN)\n",
    "\n",
    "The F1 score is measure of a weighted harmonic mean of precision and recall. \n",
    "\n",
    "Support is the number of values for each class.\n",
    "\n",
    "Looking at the f1- scores for the different classes, we can see that the model is more accuracte with some classses than others.\n",
    "For example, the model is not able to correctly inentify the hiher order PSK and QAM modulations as other classes.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy vs. SNR\n",
    "Now lets see how the model accuracy is effcted by SNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batchsize = 1024\n",
    "progress = ProgressBar()\n",
    "snrlist = np.unique(Z_test)\n",
    "acc_snr_arr = []\n",
    "\n",
    "# interate over SNRs\n",
    "for snr in progress(snrlist):\n",
    "    acc_arr = []\n",
    "    i_SNR = np.where(Z_test==snr)\n",
    "    X_SNR = X_test[i_SNR[0],:,:]\n",
    "    Y_SNR = Y_test[i_SNR[0],:]\n",
    "    X_SNR_len = np.shape(X_SNR)[0]\n",
    "    total_batches = int(X_SNR_len/batchsize)\n",
    "    \n",
    "    for i in (range(0, total_batches)):\n",
    "        x_batch, y_batch = X_SNR[i*batchsize:i*batchsize+batchsize], Y_SNR[i*batchsize:i*batchsize+batchsize]\n",
    "        \n",
    "        # model prediction\n",
    "        pred = model.predict(x_batch)\n",
    "        \n",
    "        #Pediction values are onehote, corresponding to indices representing different modulation types\n",
    "        pred_ind = np.argmax(pred, axis=1)\n",
    "        expected_ind = np.argmax(y_batch, axis=1)\n",
    "        matches  = sum(np.equal(pred_ind, expected_ind))\n",
    "        acc      = matches/batchsize\n",
    "        acc_arr.append(acc)\n",
    "\n",
    "    # Average the per-batch accuracy values\n",
    "    accuracy = np.mean(acc_arr)\n",
    "    acc_snr_arr.append(accuracy)\n",
    "    print(\"SNR: \", snr, \"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(1,1))\n",
    "plt.show()\n",
    "fig= plt.figure(figsize=(10,8))\n",
    "plt.plot(snrlist, acc_snr_arr, 'bo-', label='accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('SNR')\n",
    "plt.title(\"Accuracy vs, SNR for Floating Point Model\")\n",
    "plt.legend()\n",
    "plt.axis([-22, 32, 0, 1.0])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are you can see accurccy SNRs below -10db the Top1 accuracy is no better than a random guess (1/24), and once SNR is above 10db the Top1 accuracy is over 98%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vitis AI\n",
    "The Vitis-AI tools will be used the Quantize and Compile the model for accleration on the DPU. <br>\n",
    "Vitis-AI 1.3 now natively supports keras in TensorFlow2, and we can directly read in the .h5 model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize Model to INT8\n",
    "The Vitis-AI Quantizer uses a  small set of unlabeled samples to analyze the distribution of the activations. We will use 1000 input samples from the test set. <br>\n",
    "\n",
    "The quantized.h5 model that is produced will be used as input to the Vitis-AI Quantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# reload the model in case it was closed\n",
    "!ls -l fp_model/\n",
    "model = tf.keras.models.load_model('fp_model/resnet_fp_model.h5')\n",
    " \n",
    "from tensorflow_model_optimization.quantization.keras import vitis_quantize\n",
    "quantizer = vitis_quantize.VitisQuantizer(model)\n",
    "quantized_model = quantizer.quantize_model(calib_dataset = X_test[1:1000])\n",
    "\n",
    "# Save the model\n",
    "!mkdir -p quantize_results\n",
    "quantized_model.save('quantize_results/quantized_model.h5')\n",
    "!ls -l quantize_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Compile Model for Evaluation\n",
    "We can now load and recompile the INT8 model and run evaluations to compare with the floating point model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalute  Model INT8 Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load quantized model\n",
    "from tensorflow_model_optimization.quantization.keras import vitis_quantize\n",
    "with vitis_quantize.quantize_scope():\n",
    "  q_model = tf.keras.models.load_model('quantize_results/quantized_model.h5')\n",
    "\n",
    "q_model.compile(loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "score = q_model.evaluate(X_test, Y_test,  verbose=0, batch_size=1024)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Overall Top-1 score has gone down by about 3% due to quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report for INT8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "Y_pred = q_model.predict(X_test,batch_size=batch_size)\n",
    "y_pred = np.argmax(Y_pred, axis = 1)\n",
    "y_actual = np.argmax(Y_test, axis = 1)\n",
    "classificationreport_int8 = classification_report(y_actual,y_pred, target_names=mods)\n",
    "print(classificationreport_int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy vs SNR for INT8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batchsize = 128\n",
    "progress = ProgressBar()\n",
    "snrlist = np.unique(Z_test)\n",
    "acc_snr_arr = []\n",
    "\n",
    "# interate over SNRs\n",
    "for snr in progress(snrlist):\n",
    "    acc_arr = []\n",
    "    i_SNR = np.where(Z_test==snr)\n",
    "    X_SNR = X_test[i_SNR[0],:,:]\n",
    "    Y_SNR = Y_test[i_SNR[0],:]\n",
    "    X_SNR_len = np.shape(X_SNR)[0]\n",
    "    total_batches = int(X_SNR_len/batchsize)\n",
    "    \n",
    "    for i in (range(0, total_batches)):\n",
    "        x_batch, y_batch = X_SNR[i*batchsize:i*batchsize+batchsize], Y_SNR[i*batchsize:i*batchsize+batchsize]\n",
    "        \n",
    "        # model prediction\n",
    "        pred = q_model.predict(x_batch)\n",
    "        \n",
    "        #Pediction values are 0-24, corresponding to indices representing different modulation types\n",
    "        pred_ind = np.argmax(pred, axis=1)\n",
    "        expected_ind = np.argmax(y_batch, axis=1)\n",
    "        matches  = sum(np.equal(pred_ind, expected_ind))\n",
    "        acc      = matches/batchsize\n",
    "        acc_arr.append(acc)\n",
    "\n",
    "    # Average the per-batch accuracy values\n",
    "    accuracy = np.mean(acc_arr)\n",
    "    acc_snr_arr.append(accuracy)\n",
    "    print(\"SNR: \", snr, \"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(1,1))\n",
    "plt.show()\n",
    "fig= plt.figure(figsize=(10,8))\n",
    "plt.plot(snrlist, acc_snr_arr, 'bo-', label='accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('SNR')\n",
    "plt.title(\"Accuracy vs, SNR for INT8 Model\")\n",
    "plt.legend()\n",
    "plt.axis([-22, 32, 0, 1.0])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Accuracy vs SNR looks very similar to the floating point model, expect the accuracy is down by about 5% for higher SNRs from the floating point model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Step Quantizer Fine Tuning\n",
    "The Vitis-AI quantizer supports fine tuning, which can be used to recover some of the accuracy lost when quantizing. \n",
    "Fine tuning does use the entire training data set, and this step will take a long time to run. If you want to skip this step you can move on to compiling the model for the DPU.\n",
    "\n",
    "\n",
    "Quantize finetuning is similar to float model finetuning. The difference is that quantize finetuning uses the APIs of the vai_q_tensorflow2 to rewrite the float graph to a quantized model before the training starts. \n",
    "\n",
    "When quantize fine tuning it is often beneifical to use a smaller learning rate. For the orginal floating point training we used a learning rate of 0.0005 For Fine tuning we will use a learning rate of 0.0001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the orginal floating point model\n",
    "model = tf.keras.models.load_model('fp_model/resnet_fp_model.h5')\n",
    " \n",
    "# *Call the vai_q_tensorflow2 api to create the quantize training model\n",
    "from tensorflow_model_optimization.quantization.keras import vitis_quantize\n",
    "quantizer = vitis_quantize.VitisQuantizer(model)\n",
    "model = quantizer.get_qat_model()\n",
    "\n",
    "model.compile(\n",
    "#use new learning rate\n",
    "optimizer= Adam(learning_rate=0.0001),\n",
    "loss= 'categorical_crossentropy',\n",
    "metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())\n",
    "    \n",
    "history = model.fit(X_train,Y_train,\n",
    "  epochs = 5,                \n",
    "  callbacks = [\n",
    "  keras.callbacks.ModelCheckpoint(\n",
    "  filepath='quantize_results/fine_tuned_model.h5',\n",
    "  save_best_only=True,\n",
    "  #monitor='categorical_crossentropy',\n",
    "  monitor= 'accuracy',\n",
    "  mode = 'auto',\n",
    "  verbose=1)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalute Model INT8 Performance after Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load quantized model\n",
    "from tensorflow_model_optimization.quantization.keras import vitis_quantize\n",
    "with vitis_quantize.quantize_scope():\n",
    "  ft_model = tf.keras.models.load_model('quantize_results/fine_tuned_model.h5')\n",
    "\n",
    "ft_model.compile(loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "score = ft_model.evaluate(X_test, Y_test,  verbose=0, batch_size=1024)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fine tuning the accuarcy has improved, you should that the accuarcy has improved to around 60.5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy vs SNR for INT8 Model after Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 128\n",
    "progress = ProgressBar()\n",
    "snrlist = np.unique(Z_test)\n",
    "acc_snr_arr = []\n",
    "\n",
    "# interate over SNRs\n",
    "for snr in progress(snrlist):\n",
    "    acc_arr = []\n",
    "    i_SNR = np.where(Z_test==snr)\n",
    "    X_SNR = X_test[i_SNR[0],:,:]\n",
    "    Y_SNR = Y_test[i_SNR[0],:]\n",
    "    X_SNR_len = np.shape(X_SNR)[0]\n",
    "    total_batches = int(X_SNR_len/batchsize)\n",
    "    \n",
    "    for i in (range(0, total_batches)):\n",
    "        x_batch, y_batch = X_SNR[i*batchsize:i*batchsize+batchsize], Y_SNR[i*batchsize:i*batchsize+batchsize]\n",
    "        \n",
    "        # model prediction\n",
    "        pred = ft_model.predict(x_batch)\n",
    "        \n",
    "        #Pediction values are 0-24, corresponding to indices representing different modulation types\n",
    "        pred_ind = np.argmax(pred, axis=1)\n",
    "        expected_ind = np.argmax(y_batch, axis=1)\n",
    "        matches  = sum(np.equal(pred_ind, expected_ind))\n",
    "        acc      = matches/batchsize\n",
    "        acc_arr.append(acc)\n",
    "\n",
    "    # Average the per-batch accuracy values\n",
    "    accuracy = np.mean(acc_arr)\n",
    "    acc_snr_arr.append(accuracy)\n",
    "    print(\"SNR: \", snr, \"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(1,1))\n",
    "plt.show()\n",
    "fig= plt.figure(figsize=(10,8))\n",
    "plt.plot(snrlist, acc_snr_arr, 'bo-', label='accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('SNR')\n",
    "plt.title(\"Accuracy vs, SNR for Fine Tuned INT8 Model\")\n",
    "plt.legend()\n",
    "plt.axis([-22, 32, 0, 1.0])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model for DPU\n",
    "The Vitis-AI compiler reads in the quantized model and generates an xmodel file which the instruction set for the Xilinx Deep Learning Processor (DPU). The arhictecture option (-a) is used to specify a json file which indicates which hw target the DPU is being compiled for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "* VITIS_AI Compilation - Xilinx Inc.\n",
      "**************************************************\n",
      "[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['/workspace/files/quantize_results/quantized_model.h5'], model_type='tensorflow2', named_inputs_shape=None, out_filename='/tmp/rfClassification_org.xmodel', proto=None)\n",
      "[INFO] tensorflow2 model: /workspace/files/quantize_results/quantized_model.h5\n",
      "[INFO] keras version: 2.4.0\n",
      "[INFO] Tensorflow Keras model type: functional\n",
      "[INFO] parse raw model     :100%|█| 66/66 [00:00<00:00, 14987.77it/s]           \n",
      "[INFO] infer shape (NHWC)  :100%|█| 110/110 [00:00<00:00, 8335.56it/s]          \n",
      "[INFO] perform level-0 opt :100%|█| 2/2 [00:00<00:00, 45.92it/s]                \n",
      "[INFO] perform level-1 opt :100%|█| 2/2 [00:00<00:00, 181.73it/s]               \n",
      "[INFO] infer shape (NHWC)  :100%|█| 112/112 [00:00<00:00, 11312.75it/s]         \n",
      "[INFO] generate xmodel     :100%|█| 112/112 [00:00<00:00, 4854.77it/s]          \n",
      "[INFO] dump xmodel: /tmp/rfClassification_org.xmodel\n",
      "[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2\n",
      "[UNILOG][INFO] Compile mode: dpu\n",
      "[UNILOG][INFO] Debug mode: function\n",
      "[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2\n",
      "[UNILOG][INFO] Graph name: model, with op num: 206\n",
      "[UNILOG][INFO] Begin to compile...\n",
      "[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "[UNILOG][INFO] Compile done.\n",
      "[UNILOG][INFO] The meta json is saved to \"/workspace/files/vai_c_output/meta.json\"\n",
      "[UNILOG][INFO] The compiled xmodel is saved to \"/workspace/files/vai_c_output/rfClassification.xmodel\"\n",
      "[UNILOG][INFO] The compiled xmodel's md5sum is f9081d17d58914065bfa24e08653a29a, and has been saved to \"/workspace/files/vai_c_output/md5sum.txt\"\n"
     ]
    }
   ],
   "source": [
    "# Select HW Target Choose Either Quantized or Fine Tuned Model\n",
    "#For ZCU104\n",
    "!vai_c_tensorflow2 -m /workspace/files/quantize_results/quantized_model.h5 -a /opt/vitis_ai/compiler/arch/DPUCZDX8G/ZCU104/arch.json -o vai_c_output -n rfClassification\n",
    "#!vai_c_tensorflow2 -m /workspace/files/quantize_results/fine_tuned_model.h5 -a /opt/vitis_ai/compiler/arch/DPUCZDX8G/ZCU104/arch.json -o vai_c_output -n rfClassification\n",
    "\n",
    "#For ZCU102 \n",
    "#!vai_c_tensorflow2 -m /workspace/files/quantize_results/quantized_model.h5 -a /opt/vitis_ai/compiler/arch/DPUCZDX8G/ZCU102/arch.json -o vai_c_output -n rfClassification --options \"{'cpu_arch':'arm64', 'mode':'normal', 'save_kernel':''}\"\n",
    "#!vai_c_tensorflow2 -m /workspace/files/quantize_results/fine_tuned_model.h5 -a /opt/vitis_ai/compiler/arch/DPUCZDX8G/ZCU102/arch.json -o vai_c_output -n rfClassification --options \"{'cpu_arch':'arm64', 'mode':'normal', 'save_kernel':''}\"\n",
    "\n",
    "#For Alveo U50\n",
    "#!vai_c_tensorflow2 -m /workspace/files/quantize_results/quantized_model.h5 -a /opt/vitis_ai/compiler/arch/DPUCAHX8H/U50/arch.json -o vai_c_output -n rfClassification --options \"{'cpu_arch':'arm64', 'mode':'normal', 'save_kernel':''}\"\n",
    "#!vai_c_tensorflow2 -m /workspace/files/quantize_results/fine_tuned_model.h5 -a /opt/vitis_ai/compiler/arch/DPUCAHX8H/U50/arch.json -o vai_c_output -n rfClassification --options \"{'cpu_arch':'arm64', 'mode':'normal', 'save_kernel':''}\"\n",
    "\n",
    "#For Versal VCK190\n",
    "#!vai_c_tensorflow2 -m /workspace/files/quantize_results/quantized_model.h5 -a /opt/vitis_ai/compiler/arch/DPUCVDX8G/VCK190/arch.json -o vai_c_output -n rfClassification --options \"{'cpu_arch':'arm64', 'mode':'normal', 'save_kernel':''}\"\n",
    "#!vai_c_tensorflow2 -m /workspace/files/quantize_results/fine_tuned_model.h5 -a /opt/vitis_ai/compiler/arch/DPUCVDX8G/VCK190/arch.json -o vai_c_output -n rfClassification --options \"{'cpu_arch':'arm64', 'mode':'normal', 'save_kernel':''}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Graph Visualization with xir tool.\n",
    "You will see a compiler message about the number of  subgraphs:\n",
    "Total device subgraph number 3, DPU subgraph number 1 <br>\n",
    "This means that are 3 subgraphs created, 1 for the input layer, 1 for for everything up the softmax layer (which runs on the DPU), and one for the softmax. <br>\n",
    "\n",
    "The softmax layer can  optionally be acclerated in programmable logic, however in this tutorial we will implement the softmax layer on the CPU.\n",
    "\n",
    "You can use the the xir command generate a .png file to visulize the graph layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xir png /workspace/vai_c_output/rfClassification.xmodel xmodel.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out  samples  of Test Data to be used later for HW testing\n",
    "The python function we will run in the target board will read in these numpy files containing the RF data, class, and SNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/workspace/rf_input.npy', X_test[0:1000,:,:])\n",
    "np.save('/workspace/rf_classes.npy', Y_test[0:1000])\n",
    "np.save('/workspace/rf_snrs.npy', Z_test[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that a dpu xmodel file has been created you are ready to run on target board. You will need to copy the above 3 files, and the xmodel file from the compiler to your target board.\n",
    "\n",
    "You can close this notebook by entering CtrlC at the console, close the docker container by entering CtrlD, and the proceed with the Tutorial readme instructions."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "QEwdbt6MBcjS",
    "46uELugqymJa"
   ],
   "name": "Import 2018 RadioML.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
