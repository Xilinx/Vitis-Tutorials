<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
<!-- OneTrust Cookies Consent Notice start for xilinx.github.io -->

<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="03af8d57-0a04-47a6-8f10-322fa00d8fc7" ></script>
<script type="text/javascript">
function OptanonWrapper() { }
</script>
<!-- OneTrust Cookies Consent Notice end for xilinx.github.io -->
  <title>6. Using Out-of-Order Queues and Multiple Compute Units &mdash; Vitis™ Tutorials 2022.1 documentation</title>
      <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
            <a href="../../../../README.html" class="icon icon-home"> Vitis™ Tutorials
            <img src="../../../../_static/xilinx-header-logo.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                2022.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">日本語版</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/Vitis-Tutorials/master/docs-jp/README.html">Master</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting Started Pathway</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Getting_Started/Vitis/README.html">Vitis Flow 101 Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Getting_Started/Vitis_HLS/README.html">Vitis HLS Analysis and Optimization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Hardware Accelerators</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../02-bloom/README.html">Optimizing Accelerated FPGA Applications: Bloom Filter Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="README.html">Optimizing Accelerated FPGA Applications: Convolution Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../03-rtl_stream_kernel_integration/README.html">Mixed Kernels Design Tutorial with AXI Stream and Vitis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Feature_Tutorials/01-rtl_kernel_workflow/README.html">Getting Started with RTL Kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Feature_Tutorials/02-mixing-c-rtl-kernels/README.html">Mixing C++ and RTL Kernels</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Runtime and System Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/Design_Tutorials/01-host-code-opt/README.html">Host Code Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/Design_Tutorials/02-ivas-ml/README.html">IVAS ZCU104 ML Acceleration Reference Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/Feature_Tutorials/01-mult-ddr-banks/README.html">Using Multiple DDR Banks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/Feature_Tutorials/02-using-multiple-cu/README.html">Using Multiple Compute Units</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/Feature_Tutorials/03-controlling-vivado-implementation/README.html">Controlling Vivado Implementation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Vitis Platform Creation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Vitis_Platform_Creation/Introduction/01-Overview/README.html">Platform Creation Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Vitis_Platform_Creation/Introduction/02-Edge-AI-ZCU104/README.html">Vitis Custom Embedded Platform Creation Example on ZCU104</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Versions</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/Vitis-Tutorials/">Main</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: black" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../README.html">Vitis™ Tutorials</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../README.html" class="icon icon-home"></a> &raquo;</li>
      <li>6. Using Out-of-Order Queues and Multiple Compute Units</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../_sources/docs/Hardware_Accelerators/Design_Tutorials/01-convolution-tutorial/multi-CU.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <table class="sphinxhide">
 <tr>
   <td align="center"><img src="https://www.xilinx.com/content/dam/xilinx/imgs/press/media-kits/corporate/xilinx-logo.png" width="30%"/><h1>2020.1 Vitis™ Application Acceleration Development Flow Tutorials</h1>
   <a href="https://github.com/Xilinx/Vitis-Tutorials/branches/all">See 2019.2 Vitis Application Acceleration Development Flow Tutorials</a>
   </td>
 </tr>
 <tr>
 <td>
 </td>
 </tr>
</table><div class="section" id="using-out-of-order-queues-and-multiple-compute-units">
<h1>6. Using Out-of-Order Queues and Multiple Compute Units<a class="headerlink" href="#using-out-of-order-queues-and-multiple-compute-units" title="Permalink to this heading">¶</a></h1>
<p>In the previous labs, you concentrated on extracting parallelism within a kernel using techniques such as pipelining and dataflow. One of the very powerful features of FPGAs is that you can create multiple compute units (CUs), which are identical copies of your kernel, allowing more processing to happen in parallel. These CUs can be used to process multiple images at the same time, or divide one image into smaller regions, so that you can process each frame faster. In this tutorial, you are going to take the latter approach to speed up computation of each individual frame.</p>
<p>To take advantage of acceleration potential offered by the multiple CUs, the host application needs to be able to issue and manage multiple concurrent requests to the CUs. For maximum performance, it is important to ensure that the application keeps all the CUs busy. Any delay in transferring data or starting a CU will reduce the overall performance.</p>
<p>In this lab, you will first implement changes in the host code to handle multiple CUs, then make updates to the kernel to handle subregions of a frame.</p>
<div class="section" id="executing-queued-operations-out-of-order">
<h2>Executing Queued Operations Out-of-Order<a class="headerlink" href="#executing-queued-operations-out-of-order" title="Permalink to this heading">¶</a></h2>
<p>The host application uses OpenCL™ APIs to communicate with kernels on an FPGA. Those commands are executed through a command queue object. By default, the command queue is handled in order; however, you can change this behavior to execute your operations in any order by passing a special flag to the command queue. This type of queue will execute whatever operation is ready to execute as soon as the resources are available.</p>
<p>Out-of-order queues allow you to launch multiple operations at the same time, including memory transfers and kernel calls. You can add dependencies on tasks using OpenCL API events and wait lists. Events are objects that are associated with a particular task. It is usually passed into a call as the last argument. If an operation depends on another task, you can pass the event into a wait list. The operation will need to wait for all events in the wait list to finish before executing.</p>
<blockquote>
<div><p><strong>TIP:</strong> The completed host code source file is provided under the <code class="docutils literal notranslate"><span class="pre">reference-files/multicu</span></code> folder. You can use it as a reference if needed.</p>
</div></blockquote>
<p>To take advantage of the out-of-order queues and events, modify the host program.</p>
<ol>
<li><p>Open the <code class="docutils literal notranslate"><span class="pre">convolve.cpp</span></code> file from <code class="docutils literal notranslate"><span class="pre">src/multicu</span></code> and modify the following line.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="n">cl</span><span class="p">::</span><span class="n">CommandQueue</span> <span class="n">q</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">cl</span><span class="p">::</span><span class="n">QueueProperties</span><span class="p">::</span><span class="n">Profiling</span><span class="p">);</span>
</pre></div>
</div>
<p>to:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="n">cl</span><span class="p">::</span><span class="n">CommandQueue</span> <span class="n">q</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">cl</span><span class="p">::</span><span class="n">QueueProperties</span><span class="p">::</span><span class="n">Profiling</span> <span class="o">|</span> <span class="n">cl</span><span class="p">::</span><span class="n">QueueProperties</span><span class="p">::</span><span class="n">OutOfOrder</span><span class="p">);</span>
</pre></div>
</div>
<p>Passing <code class="docutils literal notranslate"><span class="pre">cl::QueueProperties::OutOfOrder</span></code> enum to the <code class="docutils literal notranslate"><span class="pre">CommandQueue</span></code> constructor tells the runtime that the operations on this queue can be executed out-of-order.</p>
</li>
<li><p>With an out-of-order queue, you must now enforce ordering between the read, enqueueTask, and write calls to make sure that you do not read the buffer before the copy operation has completed. You will create a <code class="docutils literal notranslate"><span class="pre">cl::Event</span></code> object and pass it as the last argument of the <code class="docutils literal notranslate"><span class="pre">enqueueWriteBuffer</span></code> function. Change line 95 from:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="n">q</span><span class="o">.</span><span class="n">enqueueWriteBuffer</span><span class="p">(</span><span class="n">buffer_input</span><span class="p">,</span> <span class="n">CL_FALSE</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">frame_bytes</span><span class="p">,</span> <span class="n">inFrame</span><span class="o">.</span><span class="n">data</span><span class="p">());</span>
</pre></div>
</div>
<p>to:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="n">cl</span><span class="p">::</span><span class="n">Event</span> <span class="n">write_event</span><span class="p">;</span>
 <span class="n">q</span><span class="o">.</span><span class="n">enqueueWriteBuffer</span><span class="p">(</span><span class="n">buffer_input</span><span class="p">,</span> <span class="n">CL_FALSE</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">frame_bytes</span><span class="p">,</span> <span class="n">inFrame</span><span class="o">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">nullptr</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">write_event</span><span class="p">);</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">write_event</span></code> object will be used to enforce this operation’s dependency on the next task.</p>
</li>
<li><p>You need to pass the <code class="docutils literal notranslate"><span class="pre">write_event</span></code> to the <code class="docutils literal notranslate"><span class="pre">enqueueTask</span></code> call. You must also create an event object for the task to pass to the read operation. The <code class="docutils literal notranslate"><span class="pre">write_event</span></code> object from the previous call must be passed into this call through a pointer to a vector. Modify the <code class="docutils literal notranslate"><span class="pre">enqueueTask</span></code> call in line 96 as follows.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="n">vector</span><span class="o">&lt;</span><span class="n">cl</span><span class="p">::</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">iteration_events</span><span class="p">{</span><span class="n">write_event</span><span class="p">};</span>
 <span class="n">cl</span><span class="p">::</span><span class="n">Event</span> <span class="n">task_event</span><span class="p">;</span>
 <span class="n">q</span><span class="o">.</span><span class="n">enqueueTask</span><span class="p">(</span><span class="n">convolve_kernel</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">iteration_events</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">task_event</span><span class="p">);</span>
</pre></div>
</div>
</li>
<li><p>The read call needs to be executed after the <code class="docutils literal notranslate"><span class="pre">convolve_kernel</span></code> has finished executing. Just like in the previous operations, you can also send the event as the last argument of this function. Modify the <code class="docutils literal notranslate"><span class="pre">enqueueReadBuffer</span></code> call in line 97 as follows.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="n">iteration_events</span><span class="o">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">task_event</span><span class="p">);</span>
 <span class="n">cl</span><span class="p">::</span><span class="n">Event</span> <span class="n">read_event</span><span class="p">;</span>
 <span class="n">q</span><span class="o">.</span><span class="n">enqueueReadBuffer</span><span class="p">(</span><span class="n">buffer_output</span><span class="p">,</span> <span class="n">CL_FALSE</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">frame_bytes</span><span class="p">,</span> <span class="n">outFrame</span><span class="o">.</span><span class="n">data</span><span class="p">(),</span> <span class="o">&amp;</span><span class="n">iteration_events</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">read_event</span><span class="p">);</span>
 <span class="n">iteration_events</span><span class="o">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">read_event</span><span class="p">);</span>
</pre></div>
</div>
<p>Here you added the <code class="docutils literal notranslate"><span class="pre">task_event</span></code> object to the end of the <code class="docutils literal notranslate"><span class="pre">iteration_events</span></code> vector. Then, you pass <code class="docutils literal notranslate"><span class="pre">iteration_events</span></code> in as the second to the last argument to the <code class="docutils literal notranslate"><span class="pre">enqueueReadBuffer</span></code> call. You could also have created a new vector because the <code class="docutils literal notranslate"><span class="pre">enqueueTask</span></code> call depends on the previous call.</p>
</li>
<li><p>You need to make sure that <code class="docutils literal notranslate"><span class="pre">ffmpeg</span></code> does not write to the output stream before you transfer the data back to the host. You can block the thread from continuing by calling the wait call on the <code class="docutils literal notranslate"><span class="pre">read_event</span></code> object. Add this line after the <code class="docutils literal notranslate"><span class="pre">push_back</span></code> function call on the <code class="docutils literal notranslate"><span class="pre">iteration_events</span></code> object.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="n">read_event</span><span class="o">.</span><span class="n">wait</span><span class="p">();</span>
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="using-multiple-compute-units">
<h2>Using Multiple Compute Units<a class="headerlink" href="#using-multiple-compute-units" title="Permalink to this heading">¶</a></h2>
<p>In previous labs, only one CU is used for the kernel. In this section, you will modify the design to use multiple CUs, and each CU will process a smaller region of the image. To achieve that, you are going to make further modifications based on the output from the previous step.</p>
<blockquote>
<div><p><strong>TIP:</strong> The completed kernel source file is provided under the <code class="docutils literal notranslate"><span class="pre">reference-files/multicu</span></code> folder. You can use it as a reference if needed.</p>
</div></blockquote>
<p>Here you are going to modify the kernel code. Open the <code class="docutils literal notranslate"><span class="pre">convolve_fpga.cpp</span></code> file from <code class="docutils literal notranslate"><span class="pre">src/multicu</span></code>, and make following modifications:</p>
<ol>
<li><p>Modify the signature of the <code class="docutils literal notranslate"><span class="pre">convolve_fpga</span></code> kernel to accept the offset and number of lines each kernel will process (line 106).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>        <span class="n">void</span> <span class="n">convolve_fpga</span><span class="p">(</span><span class="n">const</span> <span class="n">RGBPixel</span><span class="o">*</span> <span class="n">inFrame</span><span class="p">,</span> <span class="n">RGBPixel</span><span class="o">*</span> <span class="n">outFrame</span><span class="p">,</span> <span class="n">const</span> <span class="nb">float</span><span class="o">*</span> <span class="n">coefficient</span><span class="p">,</span> <span class="nb">int</span> <span class="n">coefficient_size</span><span class="p">,</span> <span class="nb">int</span> <span class="n">img_width</span><span class="p">,</span> <span class="nb">int</span> <span class="n">img_height</span><span class="p">,</span> <span class="nb">int</span> <span class="n">line_offset</span><span class="p">,</span> <span class="nb">int</span> <span class="n">num_lines</span><span class="p">)</span> <span class="p">{</span>
            <span class="o">...</span>
</pre></div>
</div>
<p>Depending on the image size and the number of CUs, you will divide the work evenly, and the offset will be used to determine the starting location of the kernel. The <code class="docutils literal notranslate"><span class="pre">line_offset</span></code> parameter is the first line that the CU will process. The <code class="docutils literal notranslate"><span class="pre">num_lines</span></code> argument will hold the number of lines processed by each CU.</p>
<blockquote>
<div><p><strong>TIP</strong>: Ensure the declaration of the <code class="docutils literal notranslate"><span class="pre">convolve_fpga</span></code> function in <code class="docutils literal notranslate"><span class="pre">kernels.h</span></code> matches with the <code class="docutils literal notranslate"><span class="pre">convolve_fpga.cpp</span></code> file.</p>
</div></blockquote>
</li>
<li><p>Modify the main kernel, so that you can calculate the padding and offsets for each of the CUs to process (line 123).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>     <span class="nb">int</span> <span class="n">half</span> <span class="o">=</span> <span class="n">COEFFICIENT_SIZE</span> <span class="o">/</span> <span class="mi">2</span><span class="p">;</span>

     <span class="n">hls</span><span class="p">::</span><span class="n">stream</span><span class="o">&lt;</span><span class="n">RGBPixel</span><span class="o">&gt;</span> <span class="n">read_stream</span><span class="p">(</span><span class="s2">&quot;read&quot;</span><span class="p">);</span>
     <span class="n">hls</span><span class="p">::</span><span class="n">stream</span><span class="o">&lt;</span><span class="n">RGBPixel</span><span class="o">&gt;</span> <span class="n">write_stream</span><span class="p">(</span><span class="s2">&quot;write&quot;</span><span class="p">);</span>

     <span class="nb">int</span> <span class="n">elements</span> <span class="o">=</span> <span class="n">img_width</span> <span class="o">*</span> <span class="n">num_lines</span><span class="p">;</span>
     <span class="nb">int</span> <span class="n">offset</span> <span class="o">=</span> <span class="n">std</span><span class="p">::</span><span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">line_offset</span> <span class="o">-</span> <span class="n">half</span><span class="p">)</span> <span class="o">*</span> <span class="n">img_width</span><span class="p">;</span>
     <span class="nb">int</span> <span class="n">top_padding</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
     <span class="nb">int</span> <span class="n">bottom_padding</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
     <span class="nb">int</span> <span class="n">padding</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
     <span class="k">if</span><span class="p">(</span><span class="n">line_offset</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
         <span class="n">top_padding</span> <span class="o">=</span> <span class="n">half</span> <span class="o">*</span> <span class="n">img_width</span><span class="p">;</span>
     <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
         <span class="n">padding</span> <span class="o">=</span> <span class="n">img_width</span> <span class="o">*</span>  <span class="n">half</span><span class="p">;</span>
     <span class="p">}</span>
     <span class="k">if</span><span class="p">(</span><span class="n">line_offset</span> <span class="o">+</span> <span class="n">num_lines</span> <span class="o">&lt;</span> <span class="n">img_height</span><span class="p">)</span> <span class="p">{</span>
         <span class="n">padding</span> <span class="o">+=</span> <span class="n">img_width</span> <span class="o">*</span> <span class="n">half</span> <span class="o">+</span> <span class="n">COEFFICIENT_SIZE</span><span class="p">;</span>
     <span class="p">}</span><span class="k">else</span> <span class="p">{</span>
         <span class="n">bottom_padding</span> <span class="o">=</span> <span class="n">img_width</span> <span class="o">*</span> <span class="p">(</span><span class="n">half</span><span class="p">)</span> <span class="o">+</span> <span class="n">COEFFICIENT_SIZE</span><span class="p">;</span>
     <span class="p">}</span>

     <span class="c1">#pragma HLS dataflow</span>
     <span class="n">read_dataflow</span><span class="p">(</span><span class="n">read_stream</span><span class="p">,</span> <span class="n">inFrame</span> <span class="o">+</span> <span class="n">offset</span><span class="p">,</span> <span class="n">img_width</span><span class="p">,</span> <span class="n">elements</span> <span class="o">+</span> <span class="n">padding</span><span class="p">,</span> <span class="n">half</span><span class="p">,</span> <span class="n">top_padding</span><span class="p">,</span> <span class="n">bottom_padding</span><span class="p">);</span>
     <span class="n">compute_dataflow</span><span class="p">(</span><span class="n">write_stream</span><span class="p">,</span> <span class="n">read_stream</span><span class="p">,</span> <span class="n">coefficient</span><span class="p">,</span> <span class="n">img_width</span><span class="p">,</span> <span class="n">elements</span><span class="p">,</span> <span class="n">half</span><span class="p">);</span>
     <span class="n">write_dataflow</span><span class="p">(</span><span class="n">outFrame</span> <span class="o">+</span> <span class="n">line_offset</span> <span class="o">*</span> <span class="n">img_width</span><span class="p">,</span> <span class="n">write_stream</span><span class="p">,</span> <span class="n">elements</span><span class="p">);</span>
</pre></div>
</div>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">offset</span></code> variable is used to calculate the offsets from the beginning of the image to the first pixel that the CU will read.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">top_padding</span></code> and <code class="docutils literal notranslate"><span class="pre">bottom_padding</span></code> variables will determine the padding of zeros to add to the top and the bottom of the image.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">padding</span></code> variable, on the other hand, is the number of pixels to read including the regions around the convolution window.</p></li>
</ul>
</li>
<li><p>Modify the read_dataflow kernel to send zeros for the padding areas for the top and the bottom of the image (line 20).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>     <span class="n">void</span> <span class="n">read_dataflow</span><span class="p">(</span><span class="n">hls</span><span class="p">::</span><span class="n">stream</span><span class="o">&lt;</span><span class="n">RGBPixel</span><span class="o">&gt;&amp;</span> <span class="n">read_stream</span><span class="p">,</span> <span class="n">const</span> <span class="n">RGBPixel</span> <span class="o">*</span> <span class="ow">in</span><span class="p">,</span> <span class="nb">int</span> <span class="n">img_width</span><span class="p">,</span> <span class="nb">int</span> <span class="n">elements</span><span class="p">,</span> <span class="nb">int</span> <span class="n">half</span><span class="p">,</span> <span class="nb">int</span> <span class="n">top_padding</span><span class="p">,</span> <span class="nb">int</span> <span class="n">bottom_padding</span><span class="p">)</span> <span class="p">{</span>
         <span class="k">while</span><span class="p">(</span><span class="n">top_padding</span><span class="o">--</span><span class="p">)</span> <span class="p">{</span>
             <span class="n">read_stream</span> <span class="o">&lt;&lt;</span> <span class="n">zero</span><span class="p">;</span>
         <span class="p">}</span>
         <span class="nb">int</span> <span class="n">pixel</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
         <span class="k">while</span><span class="p">(</span><span class="n">elements</span><span class="o">--</span><span class="p">)</span> <span class="p">{</span>
             <span class="n">read_stream</span> <span class="o">&lt;&lt;</span> <span class="ow">in</span><span class="p">[</span><span class="n">pixel</span><span class="o">++</span><span class="p">];</span>
         <span class="p">}</span>
         <span class="k">while</span><span class="p">(</span><span class="n">bottom_padding</span><span class="o">--</span><span class="p">)</span> <span class="p">{</span>
             <span class="n">read_stream</span> <span class="o">&lt;&lt;</span> <span class="n">zero</span><span class="p">;</span>
         <span class="p">}</span>
     <span class="p">}</span>
</pre></div>
</div>
</li>
<li><p>Because you are handling the padding logic in the read_dataflow module, you can remove the initialization logic for zeroing out the padded area. Remove the following lines from compute_dataflow (line 45).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>     <span class="k">while</span><span class="p">(</span><span class="n">line_idx</span> <span class="o">&lt;</span> <span class="n">center</span><span class="p">)</span> <span class="p">{</span>
         <span class="k">for</span><span class="p">(</span><span class="nb">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">img_width</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
             <span class="n">window_mem</span><span class="p">[</span><span class="n">line_idx</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">zero</span><span class="p">;</span>
         <span class="p">}</span>
             <span class="n">line_idx</span><span class="o">++</span><span class="p">;</span>
     <span class="p">}</span>
</pre></div>
</div>
</li>
</ol>
<p>You still need to modify a few things on the host code side to launch multiple CUs in parallel.</p>
</div>
<div class="section" id="host-code-updates-to-support-multiple-compute-units">
<h2>Host Code Updates to Support Multiple Compute Units<a class="headerlink" href="#host-code-updates-to-support-multiple-compute-units" title="Permalink to this heading">¶</a></h2>
<p>The following steps need to be performed for supporting CUs.</p>
<ol>
<li><p>Open <code class="docutils literal notranslate"><span class="pre">convolve.cpp</span></code> and add the following lines before the <code class="docutils literal notranslate"><span class="pre">frame_count</span></code> <code class="docutils literal notranslate"><span class="pre">for</span></code> loop.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>     <span class="nb">int</span> <span class="n">compute_units</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>
     <span class="nb">int</span> <span class="n">lines_per_compute_unit</span> <span class="o">=</span> <span class="n">height</span> <span class="o">/</span> <span class="n">compute_units</span><span class="p">;</span>
</pre></div>
</div>
<p>These variables define the number of CUs you will have in your binary. You then divide the lines of the image evenly between the CUs. This code assumes that you can evenly divide the image among the CUs.</p>
</li>
<li><p>Instead of launching one task, launch a task on each of the CUs you created. Modify the following code from:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>     <span class="n">cl</span><span class="p">::</span><span class="n">Event</span> <span class="n">task_event</span><span class="p">;</span>
     <span class="n">q</span><span class="o">.</span><span class="n">enqueueTask</span><span class="p">(</span><span class="n">convolve_kernel</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">iteration_events</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">task_event</span><span class="p">);</span>
</pre></div>
</div>
<p>to:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>     <span class="n">vector</span><span class="o">&lt;</span><span class="n">cl</span><span class="p">::</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">task_events</span><span class="p">;</span>
     <span class="k">for</span><span class="p">(</span><span class="nb">int</span> <span class="n">cu</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">cu</span> <span class="o">&lt;</span> <span class="n">compute_units</span><span class="p">;</span> <span class="n">cu</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
         <span class="n">cl</span><span class="p">::</span><span class="n">Event</span> <span class="n">task_event</span><span class="p">;</span>
         <span class="n">convolve_kernel</span><span class="o">.</span><span class="n">setArg</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">cu</span> <span class="o">*</span> <span class="n">lines_per_compute_unit</span><span class="p">);</span>
         <span class="n">convolve_kernel</span><span class="o">.</span><span class="n">setArg</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="n">lines_per_compute_unit</span><span class="p">);</span>
         <span class="n">q</span><span class="o">.</span><span class="n">enqueueTask</span><span class="p">(</span><span class="n">convolve_kernel</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">iteration_events</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">task_event</span><span class="p">);</span>
         <span class="n">task_events</span><span class="o">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">task_event</span><span class="p">);</span>
     <span class="p">}</span>
     <span class="n">copy</span><span class="p">(</span><span class="n">begin</span><span class="p">(</span><span class="n">task_events</span><span class="p">),</span> <span class="n">end</span><span class="p">(</span><span class="n">task_events</span><span class="p">),</span> <span class="n">std</span><span class="p">::</span><span class="n">back_inserter</span><span class="p">(</span><span class="n">iteration_events</span><span class="p">));</span>
</pre></div>
</div>
<p>This <code class="docutils literal notranslate"><span class="pre">for</span></code> loop will launch one task per CU. You will pass an event object to each of the tasks, and then add it to the <code class="docutils literal notranslate"><span class="pre">task_events</span></code> vector. Notice that you are not adding it to the <code class="docutils literal notranslate"><span class="pre">iteration_events</span></code> until after the end of the loop. This is because you only want the tasks to depend on the <code class="docutils literal notranslate"><span class="pre">enqueueWriteBuffer</span></code> call and not each other.</p>
</li>
</ol>
<p>Now you can compile and run the design, and you should see results similar to the following section.</p>
</div>
<div class="section" id="run-hardware-emulation-for-multiple-compute-units">
<h2>Run Hardware Emulation for Multiple Compute Units<a class="headerlink" href="#run-hardware-emulation-for-multiple-compute-units" title="Permalink to this heading">¶</a></h2>
<ol>
<li><p>Before running emulation, you need to set the CU number to 4. To do that, open the <code class="docutils literal notranslate"><span class="pre">design.cfg</span></code> and modify the <code class="docutils literal notranslate"><span class="pre">nk</span></code> option as follows.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">nk</span><span class="o">=</span><span class="n">convolve_fpga</span><span class="p">:</span><span class="mi">4</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">nk</span></code> option is used to specify the number of kernel instances, or CUs, generated during the linking step of the build process. For this lab, set it to 4.</p>
</li>
<li><p>Go to the <code class="docutils literal notranslate"><span class="pre">makefile</span></code> directory.</p></li>
<li><p>Use the following command to run hardware emulation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">run</span> <span class="n">TARGET</span><span class="o">=</span><span class="n">hw_emu</span> <span class="n">STEP</span><span class="o">=</span><span class="n">multicu</span> <span class="n">SOLUTION</span><span class="o">=</span><span class="mi">1</span> <span class="n">NUM_FRAMES</span><span class="o">=</span><span class="mi">1</span>
</pre></div>
</div>
<p>The following code shows the results of this kernel running on four CUs.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Processed</span> <span class="mf">0.08</span> <span class="n">MB</span> <span class="ow">in</span> <span class="mf">42.810</span><span class="n">s</span> <span class="p">(</span><span class="mf">0.00</span> <span class="n">MBps</span><span class="p">)</span>

<span class="n">INFO</span><span class="p">:</span> <span class="p">[</span><span class="n">Vitis</span><span class="o">-</span><span class="n">EM</span> <span class="mi">22</span><span class="p">]</span> <span class="p">[</span><span class="n">Wall</span> <span class="n">clock</span> <span class="n">time</span><span class="p">:</span> <span class="mi">01</span><span class="p">:</span><span class="mi">34</span><span class="p">,</span> <span class="n">Emulation</span> <span class="n">time</span><span class="p">:</span> <span class="mf">0.102462</span> <span class="n">ms</span><span class="p">]</span> <span class="n">Data</span> <span class="n">transfer</span> <span class="n">between</span> <span class="n">kernel</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="ow">and</span> <span class="k">global</span> <span class="n">memory</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="n">convolve_fpga_1</span><span class="p">:</span><span class="n">m_axi_gmem1</span><span class="o">-</span><span class="n">DDR</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>          <span class="n">RD</span> <span class="o">=</span> <span class="mf">24.012</span> <span class="n">KB</span>              <span class="n">WR</span> <span class="o">=</span> <span class="mf">0.000</span> <span class="n">KB</span>
<span class="n">convolve_fpga_1</span><span class="p">:</span><span class="n">m_axi_gmem2</span><span class="o">-</span><span class="n">DDR</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>          <span class="n">RD</span> <span class="o">=</span> <span class="mf">0.000</span> <span class="n">KB</span>               <span class="n">WR</span> <span class="o">=</span> <span class="mf">20.000</span> <span class="n">KB</span>
<span class="n">convolve_fpga_1</span><span class="p">:</span><span class="n">m_axi_gmem3</span><span class="o">-</span><span class="n">DDR</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>          <span class="n">RD</span> <span class="o">=</span> <span class="mf">0.035</span> <span class="n">KB</span>               <span class="n">WR</span> <span class="o">=</span> <span class="mf">0.000</span> <span class="n">KB</span>
<span class="n">convolve_fpga_2</span><span class="p">:</span><span class="n">m_axi_gmem1</span><span class="o">-</span><span class="n">DDR</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>          <span class="n">RD</span> <span class="o">=</span> <span class="mf">22.012</span> <span class="n">KB</span>              <span class="n">WR</span> <span class="o">=</span> <span class="mf">0.000</span> <span class="n">KB</span>
<span class="n">convolve_fpga_2</span><span class="p">:</span><span class="n">m_axi_gmem2</span><span class="o">-</span><span class="n">DDR</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>          <span class="n">RD</span> <span class="o">=</span> <span class="mf">0.000</span> <span class="n">KB</span>               <span class="n">WR</span> <span class="o">=</span> <span class="mf">20.000</span> <span class="n">KB</span>
<span class="n">convolve_fpga_2</span><span class="p">:</span><span class="n">m_axi_gmem3</span><span class="o">-</span><span class="n">DDR</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>          <span class="n">RD</span> <span class="o">=</span> <span class="mf">0.035</span> <span class="n">KB</span>               <span class="n">WR</span> <span class="o">=</span> <span class="mf">0.000</span> <span class="n">KB</span>
<span class="n">convolve_fpga_3</span><span class="p">:</span><span class="n">m_axi_gmem1</span><span class="o">-</span><span class="n">DDR</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>          <span class="n">RD</span> <span class="o">=</span> <span class="mf">24.012</span> <span class="n">KB</span>              <span class="n">WR</span> <span class="o">=</span> <span class="mf">0.000</span> <span class="n">KB</span>
<span class="n">convolve_fpga_3</span><span class="p">:</span><span class="n">m_axi_gmem2</span><span class="o">-</span><span class="n">DDR</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>          <span class="n">RD</span> <span class="o">=</span> <span class="mf">0.000</span> <span class="n">KB</span>               <span class="n">WR</span> <span class="o">=</span> <span class="mf">20.000</span> <span class="n">KB</span>
<span class="n">convolve_fpga_3</span><span class="p">:</span><span class="n">m_axi_gmem3</span><span class="o">-</span><span class="n">DDR</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>          <span class="n">RD</span> <span class="o">=</span> <span class="mf">0.035</span> <span class="n">KB</span>               <span class="n">WR</span> <span class="o">=</span> <span class="mf">0.000</span> <span class="n">KB</span>
<span class="n">convolve_fpga_4</span><span class="p">:</span><span class="n">m_axi_gmem1</span><span class="o">-</span><span class="n">DDR</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>          <span class="n">RD</span> <span class="o">=</span> <span class="mf">22.000</span> <span class="n">KB</span>              <span class="n">WR</span> <span class="o">=</span> <span class="mf">0.000</span> <span class="n">KB</span>
<span class="n">convolve_fpga_4</span><span class="p">:</span><span class="n">m_axi_gmem2</span><span class="o">-</span><span class="n">DDR</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>          <span class="n">RD</span> <span class="o">=</span> <span class="mf">0.000</span> <span class="n">KB</span>               <span class="n">WR</span> <span class="o">=</span> <span class="mf">20.000</span> <span class="n">KB</span>
<span class="n">convolve_fpga_4</span><span class="p">:</span><span class="n">m_axi_gmem3</span><span class="o">-</span><span class="n">DDR</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>          <span class="n">RD</span> <span class="o">=</span> <span class="mf">0.035</span> <span class="n">KB</span>               <span class="n">WR</span> <span class="o">=</span> <span class="mf">0.000</span> <span class="n">KB</span>
</pre></div>
</div>
<p>You can now perform four times more work in about the same amount of time. You transfer more data from global memory because each CU needs to read the surrounding padding lines.</p>
</li>
</ol>
</div>
<div class="section" id="view-profile-summary-report-for-hardware-emulation">
<h2>View Profile Summary Report for Hardware Emulation<a class="headerlink" href="#view-profile-summary-report-for-hardware-emulation" title="Permalink to this heading">¶</a></h2>
<p>Use the following command to view the Profile Summary report.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">view_run_summary</span> <span class="n">TARGET</span><span class="o">=</span><span class="n">hw_emu</span> <span class="n">STEP</span><span class="o">=</span><span class="n">multicu</span>
</pre></div>
</div>
<p>The kernel execution time for four CUs is around 0.065 ms each.</p>
<p>Here is the updated table.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th align="left">Step</th>
<th align="left">Image Size</th>
<th align="right">Time (HW-EM)(ms)</th>
<th align="right">Reads (KB)</th>
<th align="right">Writes (KB)</th>
<th align="right">Avg. Read (KB)</th>
<th align="right">Avg. Write (KB)</th>
<th align="right">BW (MBps)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">baseline</td>
<td align="left">512x10</td>
<td align="right">3.903</td>
<td align="right">344</td>
<td align="right">20.0</td>
<td align="right">0.004</td>
<td align="right">0.004</td>
<td align="right">5.2</td>
</tr>
<tr>
<td align="left">localbuf</td>
<td align="left">512x10</td>
<td align="right">1.574 (2.48x)</td>
<td align="right">21 (0.12x)</td>
<td align="right">20.0</td>
<td align="right">0.064</td>
<td align="right">0.064</td>
<td align="right">13</td>
</tr>
<tr>
<td align="left">fixed-type data</td>
<td align="left">512x10</td>
<td align="right">0.46 (3.4x)</td>
<td align="right">21</td>
<td align="right">20.0</td>
<td align="right">0.064</td>
<td align="right">0.064</td>
<td align="right">44</td>
</tr>
<tr>
<td align="left">dataflow</td>
<td align="left">512x10</td>
<td align="right">0.059 (7.8x)</td>
<td align="right">21</td>
<td align="right">20.0</td>
<td align="right">0.064</td>
<td align="right">0.064</td>
<td align="right">347</td>
</tr>
<tr>
<td align="left">multi-CU</td>
<td align="left">512x40*</td>
<td align="right">0.06 (0.98x)</td>
<td align="right">92 (4.3x)</td>
<td align="right">80.0 (4x)</td>
<td align="right">0.064</td>
<td align="right">0.064</td>
<td align="right">1365*</td>
</tr>
</tbody>
</table><blockquote>
<div><p><strong>NOTE:</strong></p>
<ul class="simple">
<li><p>The multi-CU version processed four times the amount of data compared to previous versions. Even if the CU execution time does not change for each CU, the four parallel CUs increase the system performance by almost four times.</p></li>
<li><p>This is calculated by 4x data/time. Here the data transfer time is not accounted for, and you assume that the four CUs are executing in parallel. This is not as accurate as the hardware run, but you will use it as a reference for optimizations effectiveness.</p></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="next-steps">
<h2>Next Steps<a class="headerlink" href="#next-steps" title="Permalink to this heading">¶</a></h2>
<p>In this step, you performed host code optimizations by using out-of-order command queue and executing multiple CUs. In the next step, you will be <a class="reference internal" href="qdma.html"><span class="doc">Using QDMA Streaming with Multiple Compute Units</span></a>.</p>
<p></br></p>
<hr/>
<p align="center" class="sphinxhide"><b><a href="/docs/vitis-getting-started/README.md">Return to Getting Started Pathway</a> — <a href="/docs/convolution-tutorial/README.md">Return to Start of Tutorial</a></b></p><p align="center" class="sphinxhide"><sup>Copyright&copy; 2020 Xilinx</sup></p></div>
</div>


           </div>
          </div>
          
                  <style>
                        .footer {
                        position: fixed;
                        left: 0;
                        bottom: 0;
                        width: 100%;
                        }
                  </style>
				  
				  <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019-2022, Xilinx, Inc. Xilinx is now a part of AMD.
      <span class="lastupdated">Last updated on May 16, 2022.
      </span></p>
  </div>



										<div class="aem-Grid aem-Grid--16">
											<div class="aem-GridColumn aem-GridColumn--xxxlarge--none aem-GridColumn--xsmall--16 aem-GridColumn--offset--xsmall--0 aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--xsmall--none aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
												<div class="container-fluid sub-footer">

													                    <div class="row">
                        <div class="col-xs-24">
                          <p><a target="_blank" href="https://www.amd.com/en/corporate/copyright">Terms and Conditions</a> | <a target="_blank" href="https://www.amd.com/en/corporate/privacy">Privacy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/cookies">Cookie Policy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/trademarks">Trademarks</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/statement-human-trafficking-forced-labor.pdf">Statement on Forced Labor</a> | <a target="_blank" href="https://www.amd.com/en/corporate/competition">Fair and Open Competition</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/amd-uk-tax-strategy.pdf">UK Tax Strategy</a> | <a target="_blank" href="https://docs.xilinx.com/v/u/9x6YvZKuWyhJId7y7RQQKA">Inclusive Terminology</a> | <a href="#cookiessettings" class="ot-sdk-show-settings">Cookies Settings</a></p>
                        </div>
                    </div>
												</div>
											</div>
										</div>
										
</br>


  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>