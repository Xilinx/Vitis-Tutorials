<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
<!-- OneTrust Cookies Consent Notice start for xilinx.github.io -->

<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="03af8d57-0a04-47a6-8f10-322fa00d8fc7" ></script>
<script type="text/javascript">
function OptanonWrapper() { }
</script>
<!-- OneTrust Cookies Consent Notice end for xilinx.github.io -->
  <title>Implementing the Kernel &mdash; Vitis™ Tutorials 2020.2 documentation</title>
      <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
            <a href="../../../../index.html" class="icon icon-home"> Vitis™ Tutorials
            <img src="../../../../_static/xilinx-header-logo.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                2020.2
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">日本語版</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/Vitis-Tutorials/master/docs-jp/README.html">Master</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting Started Pathway</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Getting_Started/Vitis/README.html">Vitis Flow 101 Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Getting_Started/Vitis_HLS/README.html">Vitis HLS Analysis and Optimization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Hardware Accelerators</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Introduction/README.html">Introduction to Vitis Hardware Accelerators Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="README.html">Optimizing Accelerated FPGA Applications: Bloom Filter Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01-convolution-tutorial/README.html">Accelerating Video Convolution Filtering Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="../03-rtl_stream_kernel_integration/README.html">Mixed Kernels Design Tutorial with AXI Stream and Vitis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../04-traveling-salesperson/README.html">The Travelling Salesman Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../05-bottom_up_rtl_kernel/README.html">Bottom-up RTL Kernel Flow with Vitis for Acceleration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Feature_Tutorials/01-rtl_kernel_workflow/README.html">Getting Started with RTL Kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Feature_Tutorials/02-mixing-c-rtl-kernels/README.html">Mixing C++ and RTL Kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Feature_Tutorials/03-dataflow_debug_and_optimization/README.html">Vitis HLS Analysis and Optimization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Runtime and System Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/Design_Tutorials/01-host-code-opt/README.html">Host Code Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/Design_Tutorials/02-ivas-ml/README.html">IVAS ZCU104 ML Acceleration Reference Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/Feature_Tutorials/01-mult-ddr-banks/README.html">Using Multiple DDR Banks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/Feature_Tutorials/02-using-multiple-cu/README.html">Using Multiple Compute Units</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/Feature_Tutorials/03-controlling-vivado-implementation/README.html">Controlling Vivado Implementation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/Feature_Tutorials/04-using-hbm/README.html">Using HBM</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Vitis Platform Creation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Vitis_Platform_Creation/Introduction/01-Overview/README.html">Platform Creation Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Vitis_Platform_Creation/Introduction/02-Edge-AI-ZCU104/README.html">Vitis Custom Embedded Platform Creation Example on ZCU104</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Vitis_Platform_Creation/Introduction/03_Edge_VCK190/README.html">Versal Custom Platform Creation Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Versions</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/Vitis-Tutorials/">Main</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: black" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">Vitis™ Tutorials</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Implementing the Kernel</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../_sources/docs/Hardware_Accelerators/Design_Tutorials/02-bloom/4_implement-kernel.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <table class="sphinxhide">
 <tr>
   <td align="center"><img src="https://raw.githubusercontent.com/Xilinx/Image-Collateral/main/xilinx-logo.png" width="30%"/><h1>2020.2 Vitis™ Application Acceleration Development Flow Tutorials</h1>
   <a href="https://github.com/Xilinx/Vitis-Tutorials/tree/2020.1">See 2020.1 Vitis Application Acceleration Development Flow Tutorials</a>
   </td>
 </tr>
 <tr>
 <td>
 </td>
 </tr>
</table><div class="section" id="implementing-the-kernel">
<h1>Implementing the Kernel<a class="headerlink" href="#implementing-the-kernel" title="Permalink to this heading">¶</a></h1>
<p>In this lab, you will create an optimized kernel with 4, 8, and 16 words to be processed in parallel. All 100,000 documents worth 1.4 GB are sent from the host CPU to the kernel using a single buffer from the host CPU.</p>
<div class="section" id="bloom4x-kernel-implementation-using-4-words-in-parallel">
<h2>Bloom4x: Kernel Implementation Using 4 Words in Parallel<a class="headerlink" href="#bloom4x-kernel-implementation-using-4-words-in-parallel" title="Permalink to this heading">¶</a></h2>
<p>Processing 4 words in parallel will require 32-bits*4 = 128-bits in parallel, but you should access the DDR with 512-bits because the data is contiguous. This will require smaller number of memory accesses.</p>
<p>Use the following interface requirements to create kernel:</p>
<ul class="simple">
<li><p>Read multiple words stored in the DDR as a 512-bit DDR access, equivalent of reading 16 words per DDR access.</p></li>
<li><p>Write multiple flags to the DDR as a 512-bit DDR access, equivalent of writing 32 flags per DDR access.</p></li>
<li><p>Compute 4 words to be computed in parallel with each word requiring two <code class="docutils literal notranslate"><span class="pre">MurmurHash2</span></code> functions</p></li>
<li><p>Compute the hash (two <code class="docutils literal notranslate"><span class="pre">MurmurHash2</span></code> functions) functions for 4 words every cycle.</p></li>
</ul>
<p>Refer to <a class="reference external" href="https://www.xilinx.com/cgi-bin/docs/rdoc?v=2020.2%3Bt=vitis+doc%3Bd=methodologyacceleratingapplications.html">Methodology for Accelerating Applications with the Vitis Software</a> in the in the Application Acceleration Development flow of the Vitis Unified Software Platform Documentation (UG1416).</p>
<div class="section" id="macro-architecture-implementation">
<h3>Macro Architecture Implementation<a class="headerlink" href="#macro-architecture-implementation" title="Permalink to this heading">¶</a></h3>
<p>Navigate to the function <code class="docutils literal notranslate"><span class="pre">runOnfpga</span></code> in <code class="docutils literal notranslate"><span class="pre">02-bloom/reference_files/compute_score_fpga_kernel.cpp</span></code>.</p>
<p>The algorithm has been updated to receive 512-bits of words from the DDR with the following arguments:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">input_words</span></code>: 512-bit input data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">output_flags</span></code>: 512-bit output data.</p></li>
<li><p>Additional arguments:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">bloom_filter</span></code>: Pointer of array with Bloom coefficients.</p></li>
<li><p>Total number of words to be computed</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">load_filter</span></code>: Enable or disable of loading coefficients. This only needs to be loaded one time.</p></li>
</ul>
</li>
</ul>
<ol>
<li><p>The first step of the kernel development methodology requires structuring the kernel code into the Load-Compute-Store pattern. This means creating a top-level function, <code class="docutils literal notranslate"><span class="pre">runOnfpga</span></code> with:</p>
<ul class="simple">
<li><p>Added sub-functions in the <code class="docutils literal notranslate"><span class="pre">compute_hash_flags_dataflow</span></code> for Load, Compute and Store.</p></li>
<li><p>Local arrays or <code class="docutils literal notranslate"><span class="pre">hls::stream</span></code> variables to pass data between these functions.</p></li>
</ul>
</li>
<li><p>The source code has the following INTERFACE pragmas for <code class="docutils literal notranslate"><span class="pre">input_words</span></code>, <code class="docutils literal notranslate"><span class="pre">output_flags</span></code> and <code class="docutils literal notranslate"><span class="pre">bloom_filter</span></code>.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma HLS INTERFACE m_axi port=output_flags bundle=maxiport0   offset=slave </span>
<span class="cp">#pragma HLS INTERFACE m_axi port=input_words  bundle=maxiport0   offset=slave </span>
<span class="cp">#pragma HLS INTERFACE m_axi port=bloom_filter bundle=maxiport1   offset=slave </span>
</pre></div>
</div>
<p>where:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">m_axi</span></code>: Interface pragmas are used to characterize the AXI Master ports.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">port</span></code>: Specifies the name of the argument to be mapped to the AXI4 interface.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">offset=slave</span></code>: Indicates that the base address of the pointer is made available through the AXI4-Lite slave interface of the kernel.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bundle</span></code>: Specifies the name of the <code class="docutils literal notranslate"><span class="pre">m_axi</span></code> interface. In this example, the <code class="docutils literal notranslate"><span class="pre">input_words</span></code> and <code class="docutils literal notranslate"><span class="pre">output_flags</span></code> are mapped to a <code class="docutils literal notranslate"><span class="pre">maxiport0</span></code> and <code class="docutils literal notranslate"><span class="pre">bloom_filter</span></code> argument is mapped to <code class="docutils literal notranslate"><span class="pre">maxiport1</span></code>.</p></li>
</ul>
<p>The function <code class="docutils literal notranslate"><span class="pre">runOnfpga</span></code> loads the Bloom filter coefficients and calls the <code class="docutils literal notranslate"><span class="pre">compute_hash_flags_dataflow</span></code> function which has the main functionality of the Load, Compute and Store functions.</p>
<p>Refer to the function <code class="docutils literal notranslate"><span class="pre">compute_hash_flags_dataflow</span></code> in the <code class="docutils literal notranslate"><span class="pre">02-bloom/cpu_src/compute_score_fpga_kernel.cpp</span></code> file. The following block diagram shows how the compute kernel connects to the device DDR memories and how it feeds the compute hash block processing unit.</p>
<p><img alt="../../../../_images/Kernel_block_diagram.PNG" src="../../../../_images/Kernel_block_diagram.PNG" /></p>
<p>The kernel interface to the DDR memories is an AXI interface that is kept at its maximum width of 512 at the input and output. The <code class="docutils literal notranslate"><span class="pre">compute_hash_flags</span></code> function input can have a width different than 512, managed through “PARALLELIZATION”. To deal with these variations on the processing element boundaries, “Resize” blocks are inserted that adapt between the memory interface width and the processing unit interface width. Essentially, blocks named “Buffer” are memory adapters that convert between streams, and the AXI and “Resize” blocks adapt to interface widths as it depends on PARALLELIZATION factor chosen for the given configuration.</p>
</li>
<li><p>The input of the <code class="docutils literal notranslate"><span class="pre">compute_hash_flags_dataflow</span></code> function, <code class="docutils literal notranslate"><span class="pre">input_words</span></code> are read as 512-bit burst reads from the global memory over an AXI interface and <code class="docutils literal notranslate"><span class="pre">data_from_gmem</span></code>, the stream of 512-bit values are created.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hls_stream</span><span class="p">::</span><span class="n">buffer</span><span class="p">(</span><span class="n">data_from_gmem</span><span class="p">,</span> <span class="n">input_words</span><span class="p">,</span> <span class="n">total_size</span><span class="o">/</span><span class="p">(</span><span class="mi">512</span><span class="o">/</span><span class="mi">32</span><span class="p">));</span>
</pre></div>
</div>
</li>
<li><p>The stream of parallel words, <code class="docutils literal notranslate"><span class="pre">word_stream</span></code> (equals PARALLELIZATION words) are created from <code class="docutils literal notranslate"><span class="pre">data_from_gmem</span></code> as <code class="docutils literal notranslate"><span class="pre">compute_hash_flags</span></code> requires 128-bit for 4 words to process in parallel.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hls_stream</span><span class="p">::</span><span class="n">resize</span><span class="p">(</span><span class="n">word_stream</span><span class="p">,</span> <span class="n">data_from_gmem</span><span class="p">,</span> <span class="n">total_size</span><span class="o">/</span><span class="p">(</span><span class="mi">512</span><span class="o">/</span><span class="mi">32</span><span class="p">));</span>
</pre></div>
</div>
</li>
<li><p>The function <code class="docutils literal notranslate"><span class="pre">compute_hash_flags_dataflow</span></code> calls the <code class="docutils literal notranslate"><span class="pre">compute_hash_flags</span></code> function for computing hash of parallel words.</p></li>
<li><p>With <code class="docutils literal notranslate"><span class="pre">PARALLELIZATION=4</span></code>, the output of the <code class="docutils literal notranslate"><span class="pre">compute_hash_flags</span></code>, <code class="docutils literal notranslate"><span class="pre">flag_stream</span></code> is 4*8-bit = 32-bit parallel words, which will be used to create the 512-bit values of stream as <code class="docutils literal notranslate"><span class="pre">data_to_mem</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hls_stream</span><span class="p">::</span><span class="n">resize</span><span class="p">(</span><span class="n">data_to_gmem</span><span class="p">,</span> <span class="n">flag_stream</span><span class="p">,</span> <span class="n">total_size</span><span class="o">/</span><span class="p">(</span><span class="mi">512</span><span class="o">/</span><span class="mi">8</span><span class="p">));</span>
</pre></div>
</div>
</li>
<li><p>The stream of 512-bit values, <code class="docutils literal notranslate"><span class="pre">data_to_mem</span></code> is written as 512-bit values to the global memory over an AXI interface using <code class="docutils literal notranslate"><span class="pre">output_flags</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hls_stream</span><span class="p">::</span><span class="n">buffer</span><span class="p">(</span><span class="n">output_flags</span><span class="p">,</span> <span class="n">data_to_gmem</span><span class="p">,</span> <span class="n">total_size</span><span class="o">/</span><span class="p">(</span><span class="mi">512</span><span class="o">/</span><span class="mi">8</span><span class="p">));</span>
</pre></div>
</div>
</li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">#pragmas</span> <span class="pre">HLS</span> <span class="pre">DATAFLOW</span></code> is added to enable task-level pipelining. This enables DATAFLOW and will instruct the Vitis High-Level Synthesis (HLS) compiler to run all the functions simultaneously, creating a pipeline of concurrently running tasks.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">compute_hash_flags_dataflow</span><span class="p">(</span><span class="w"></span>
<span class="w">      </span><span class="n">ap_uint</span><span class="o">&lt;</span><span class="mi">512</span><span class="o">&gt;*</span><span class="w">   </span><span class="n">output_flags</span><span class="p">,</span><span class="w"></span>
<span class="w">      </span><span class="n">ap_uint</span><span class="o">&lt;</span><span class="mi">512</span><span class="o">&gt;*</span><span class="w">   </span><span class="n">input_words</span><span class="p">,</span><span class="w"></span>
<span class="w">      </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w">    </span><span class="n">bloom_filter</span><span class="p">[</span><span class="n">PARALLELIZATION</span><span class="p">][</span><span class="n">bloom_filter_size</span><span class="p">],</span><span class="w"></span>
<span class="w">      </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w">    </span><span class="n">total_size</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="cp">#pragma HLS DATAFLOW</span>

<span class="w">    </span><span class="n">hls</span><span class="o">::</span><span class="n">stream</span><span class="o">&lt;</span><span class="n">ap_uint</span><span class="o">&lt;</span><span class="mi">512</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&gt;</span><span class="w">    </span><span class="n">data_from_gmem</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">hls</span><span class="o">::</span><span class="n">stream</span><span class="o">&lt;</span><span class="n">parallel_words_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">word_stream</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">hls</span><span class="o">::</span><span class="n">stream</span><span class="o">&lt;</span><span class="n">parallel_flags_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">flag_stream</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">hls</span><span class="o">::</span><span class="n">stream</span><span class="o">&lt;</span><span class="n">ap_uint</span><span class="o">&lt;</span><span class="mi">512</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&gt;</span><span class="w">    </span><span class="n">data_to_gmem</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="p">.</span><span class="w"> </span><span class="p">.</span><span class="w"> </span><span class="p">.</span><span class="w"> </span><span class="p">.</span><span class="w"> </span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="micro-architecture-implementation">
<h3>Micro Architecture Implementation<a class="headerlink" href="#micro-architecture-implementation" title="Permalink to this heading">¶</a></h3>
<p>Now that you have the top-level function, <code class="docutils literal notranslate"><span class="pre">runOnfpga</span></code> updated with the proper datawidths and interface types, you need to identify the loops to optimize to improve latency and throughput.</p>
<ol>
<li><p>The <code class="docutils literal notranslate"><span class="pre">runOnfpga</span></code> function reads the Bloom filter coefficients from the DDR using <code class="docutils literal notranslate"><span class="pre">maxiport1</span></code> and saves the coefficients into the <code class="docutils literal notranslate"><span class="pre">bloom_filter_local</span></code> local array. This only needs to be read one time.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="w">  </span><span class="k">if</span><span class="p">(</span><span class="n">load_filter</span><span class="o">==</span><span class="nb">true</span><span class="p">)</span><span class="w"></span>
<span class="w">  </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="nl">read_bloom_filter</span><span class="p">:</span><span class="w"> </span><span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">index</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">index</span><span class="o">&lt;</span><span class="n">bloom_filter_size</span><span class="p">;</span><span class="w"> </span><span class="n">index</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="cp">#pragma HLS PIPELINE II=1</span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">tmp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bloom_filter</span><span class="p">[</span><span class="n">index</span><span class="p">];</span><span class="w"></span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">j</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">&lt;</span><span class="n">PARALLELISATION</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">bloom_filter_local</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">index</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tmp</span><span class="p">;</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">#pragma</span> <span class="pre">HLS</span> <span class="pre">PIPELINE</span> <span class="pre">II=1</span></code> is added to initiate the burst DDR accesses and read the Bloom filter coefficients every cycle.</p></li>
<li><p>The expected latency is about 16,000 cycles because the <code class="docutils literal notranslate"><span class="pre">bloom_filter_size</span></code> is fixed to 16,000. You should confirm this after you run HLS Synthesis.</p></li>
</ul>
</li>
<li><p>Within the <code class="docutils literal notranslate"><span class="pre">compute_hash_flags</span></code> function, the <code class="docutils literal notranslate"><span class="pre">for</span></code> loop is rearchitected as nested for the loop to compute 4 words in parallel.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">compute_hash_flags</span><span class="w"> </span><span class="p">(</span><span class="w"></span>
<span class="w">    </span><span class="n">hls</span><span class="o">::</span><span class="n">stream</span><span class="o">&lt;</span><span class="n">parallel_flags_t</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">flag_stream</span><span class="p">,</span><span class="w"></span>
<span class="w">    </span><span class="n">hls</span><span class="o">::</span><span class="n">stream</span><span class="o">&lt;</span><span class="n">parallel_words_t</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">word_stream</span><span class="p">,</span><span class="w"></span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w">                   </span><span class="n">bloom_filter_local</span><span class="p">[</span><span class="n">PARALLELISATION</span><span class="p">][</span><span class="n">bloom_filter_size</span><span class="p">],</span><span class="w"></span>
<span class="w">    </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w">                   </span><span class="n">total_size</span><span class="p">)</span><span class="w"></span>
<span class="w">    </span><span class="p">{</span><span class="w"></span>
<span class="w">      </span><span class="nl">compute_flags</span><span class="p">:</span><span class="w"> </span><span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">&lt;</span><span class="n">total_size</span><span class="o">/</span><span class="n">PARALLELISATION</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"></span>
<span class="w">      </span><span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="cp">#pragma HLS LOOP_TRIPCOUNT min=1 max=10000</span>
<span class="w">        </span><span class="n">parallel_words_t</span><span class="w"> </span><span class="n">parallel_entries</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">word_stream</span><span class="p">.</span><span class="n">read</span><span class="p">();</span><span class="w"></span>
<span class="w">        </span><span class="n">parallel_flags_t</span><span class="w"> </span><span class="n">inh_flags</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">j</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">&lt;</span><span class="n">PARALLELISATION</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="w"></span>
<span class="w">        </span><span class="p">{</span><span class="w"></span>
<span class="w">          </span><span class="cp">#pragma HLS UNROLL</span>
<span class="w">          </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">curr_entry</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">parallel_entries</span><span class="p">(</span><span class="mi">31</span><span class="o">+</span><span class="n">j</span><span class="o">*</span><span class="mi">32</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="o">*</span><span class="mi">32</span><span class="p">);</span><span class="w"></span>
<span class="w">          </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">frequency</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">curr_entry</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x00ff</span><span class="p">;</span><span class="w"></span>
<span class="w">          </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">word_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">curr_entry</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">8</span><span class="p">;</span><span class="w"></span>
<span class="w">          </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">hash_pu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">MurmurHash2</span><span class="p">(</span><span class="n">word_id</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span><span class="w"></span>
<span class="w">          </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">hash_lu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">MurmurHash2</span><span class="p">(</span><span class="n">word_id</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">);</span><span class="w"></span>
<span class="w">          </span><span class="kt">bool</span><span class="w"> </span><span class="n">doc_end</span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">word_id</span><span class="o">==</span><span class="n">docTag</span><span class="p">);</span><span class="w"></span>
<span class="w">          </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">hash1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hash_pu</span><span class="o">&amp;</span><span class="n">hash_bloom</span><span class="p">;</span><span class="w"></span>
<span class="w">          </span><span class="kt">bool</span><span class="w"> </span><span class="n">inh1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">doc_end</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="p">(</span><span class="n">bloom_filter_local</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="w"> </span><span class="n">hash1</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">5</span><span class="w"> </span><span class="p">]</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="p">(</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="p">(</span><span class="n">hash1</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x1f</span><span class="p">)));</span><span class="w"></span>
<span class="w">          </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">hash2</span><span class="o">=</span><span class="p">(</span><span class="n">hash_pu</span><span class="o">+</span><span class="n">hash_lu</span><span class="p">)</span><span class="o">&amp;</span><span class="n">hash_bloom</span><span class="p">;</span><span class="w"></span>
<span class="w">          </span><span class="kt">bool</span><span class="w"> </span><span class="n">inh2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">doc_end</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="p">(</span><span class="n">bloom_filter_local</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="w"> </span><span class="n">hash2</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">5</span><span class="w"> </span><span class="p">]</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="p">(</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="p">(</span><span class="n">hash2</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x1f</span><span class="p">)));</span><span class="w"></span>

<span class="w">          </span><span class="n">inh_flags</span><span class="p">(</span><span class="mi">7</span><span class="o">+</span><span class="n">j</span><span class="o">*</span><span class="mi">8</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="o">*</span><span class="mi">8</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">inh1</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">inh2</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="w">        </span><span class="p">}</span><span class="w"></span>

<span class="w">        </span><span class="n">flag_stream</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">inh_flags</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<ul class="simple">
<li><p>Added <code class="docutils literal notranslate"><span class="pre">#pragma</span> <span class="pre">HLS</span> <span class="pre">UNROLL</span></code></p>
<ul>
<li><p>Unrolls internal loop to make four copies of the Hash functionality.</p></li>
</ul>
</li>
<li><p>Vitis HLS will try to pipeline the outer loop with <code class="docutils literal notranslate"><span class="pre">II=1</span></code>. With the inside loop unrolled, you can initiate the outer loop every clock cycle, and compute 4 words in parallel.</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">#pragma</span> <span class="pre">HLS</span> <span class="pre">LOOP_TRIPCOUNT</span></code> min=1 max=3500000`</p>
<ul>
<li><p>Reports the latency of the function after HLS Synthesis.</p></li>
</ul>
</li>
</ul>
</li>
</ol>
</div>
<div class="section" id="build-the-kernel-using-the-vitis-tool-flow">
<h3>Build the Kernel Using the Vitis Tool Flow<a class="headerlink" href="#build-the-kernel-using-the-vitis-tool-flow" title="Permalink to this heading">¶</a></h3>
<p>Now, build the kernel using the Vitis compiler. The Vitis compiler will call the Vitis HLS tool to synthesize the C++ kernel code into an RTL kernel. You will also review the reports to confirm if the kernel meets the latency/throughput requirements for your performance goals.</p>
<ol>
<li><p>Use the following command to build the kernel.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>cd $LAB_WORK_DIR/makefile; make build STEP=single_buffer PF=4 TARGET=hw_emu
</pre></div>
</div>
<p>This command will call the <code class="docutils literal notranslate"><span class="pre">v++</span></code> compiler which then calls the Vitis HLS tool to translate the C++ code into RTL code that can be used to run Hardware Emulation.</p>
<blockquote>
<div><p><strong>NOTE</strong>: For purposes of this tutorial, the number of input words used is only 100 because it will take a longer time to run the Hardware Emulation.</p>
</div></blockquote>
</li>
<li><p>Then, use the following commands to visualize the HLS Synthesis Report in the Vitis analyzer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">vitis_analyzer</span> <span class="o">../</span><span class="n">build</span><span class="o">/</span><span class="n">single_buffer</span><span class="o">/</span><span class="n">kernel_4</span><span class="o">/</span><span class="n">hw_emu</span><span class="o">/</span><span class="n">runOnfpga_hw_emu</span><span class="o">.</span><span class="n">xclbin</span><span class="o">.</span><span class="n">link_summary</span>
</pre></div>
</div>
<p><img alt="../../../../_images/4_Kernel_4_link.PNG" src="../../../../_images/4_Kernel_4_link.PNG" /></p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">compute_hash_flags</span></code> latency reported is 875,011 cycles. This is based on total of 35,000,000 words, computed with 4 words in parallel. This loop has 875,000 iterations and including the <code class="docutils literal notranslate"><span class="pre">MurmurHash2</span></code> latency, the total latency of 875,011 cycles is optimal.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">compute_hash_flags_dataflow</span></code> function has <code class="docutils literal notranslate"><span class="pre">dataflow</span></code> enabled in the Pipeline column. This function is important to review and indicates that the task-level parallelism is enabled and expected to have overlap across the sub-functions in the <code class="docutils literal notranslate"><span class="pre">compute_hash_flags_dataflow</span></code> function.</p></li>
<li><p>The latency reported for <code class="docutils literal notranslate"><span class="pre">read_bloom_filter</span></code> function is 16,385 for reading the Bloom filter coefficients from the DDR using the <code class="docutils literal notranslate"><span class="pre">bloom_filter</span> <span class="pre">maxi</span></code> port. This loop is iterated over 16,000 cycles reading 32-bits data of from the Bloom filter coefficients.</p></li>
</ul>
</li>
<li><p>The HLS reports confirm that the latency of the function meets your target. You still need to ensure the functionality is correct when communicating with the host. In the next section, you will walk through the initial host code and run the software and hardware emulation.</p></li>
</ol>
</div>
<div class="section" id="review-the-initial-host-code">
<h3>Review the Initial Host Code<a class="headerlink" href="#review-the-initial-host-code" title="Permalink to this heading">¶</a></h3>
<p>The initial version of the accelerated application code structure follows the structure of the original software version. The entire input buffer is transferred from the host to the FPGA in a single transaction. Then, the FPGA accelerator performs the computation. Finally, the results are read back from the FPGA to the host before being post-processed.</p>
<p>The following figure shows the sequential process of the host writing data on the device, compute by the accelerator on the FPGA, and read flags back to host, implemented in this first step. The Profile score is calculated sequentially on CPU after all the flags are received by the host.</p>
<p><img alt="../../../../_images/overlap_single_buffer.PNG" src="../../../../_images/overlap_single_buffer.PNG" /></p>
<p>The FPGA accelerator computes the hash values and flags for the provided input words.</p>
<p>The functionality of the different inputs passed to the accelerator kernel is as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">input_doc_words</span></code>: Input array that contains the 32-bit words for all the documents.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bloom_filter</span></code>: Bloom filter array that contains the inserted search array hash values.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">total_size</span></code>: Unsigned <code class="docutils literal notranslate"><span class="pre">int</span></code> that represents the total size processed by the FPGA when called.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">load_weights</span></code>: Boolean that allows the <code class="docutils literal notranslate"><span class="pre">bloom_filter</span></code> array to load only once to the FPGA in the case of multiple kernel invocations.</p></li>
</ul>
<p>The output of the accelerator is as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">output_inh_flags</span></code>: Output array of 8-bit outputs where each bit in the 8-bit output indicates whether a word is present in the Bloom filter, that is then used for computing score in the CPU.</p></li>
</ul>
</div>
<div class="section" id="run-software-emulation-hardware-emulation-and-hw">
<h3>Run Software Emulation, Hardware Emulation and Hw<a class="headerlink" href="#run-software-emulation-hardware-emulation-and-hw" title="Permalink to this heading">¶</a></h3>
<ol>
<li><p>To ensure the application passes Software Emulation with your changes, run the following command.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>cd $LAB_WORK_DIR/makefile; make run STEP=single_buffer TARGET=sw_emu 
</pre></div>
</div>
<p>Make sure that the Software Emulation is passing.</p>
</li>
<li><p>Next, to verify the functionality is intact, use the following command to run Hardware Emulation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>cd $LAB_WORK_DIR/makefile; make run STEP=single_buffer TARGET=hw_emu 
</pre></div>
</div>
<ul class="simple">
<li><p>The commands show that the SIMULATION is PASSED. This ensures that the generated hardware is functionally correct. However, you have not run the hardware on the FPGA. .</p></li>
</ul>
<blockquote>
<div><p><strong>NOTE</strong>: This tutorial is provided with <code class="docutils literal notranslate"><span class="pre">xclbin</span></code> files in the <code class="docutils literal notranslate"><span class="pre">$LAB_WORK_DIR/xclbin_save</span></code> directory. The <code class="docutils literal notranslate"><span class="pre">SOLUTION=1</span></code> option can be added to the make target for using these <code class="docutils literal notranslate"><span class="pre">xclbin</span></code> files for <code class="docutils literal notranslate"><span class="pre">hw</span></code> runs. These <code class="docutils literal notranslate"><span class="pre">xclbin</span></code> files were generated for Alveo U200 cards only. You must generate new <code class="docutils literal notranslate"><span class="pre">xclbin</span></code> files for every platform used in this tutorial.</p>
</div></blockquote>
</li>
<li><p>Run the following steps to execute the application on hardware.</p>
<p>You are using 100,000 documents compute on the hardware.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>cd $LAB_WORK_DIR/makefile; make run STEP=single_buffer ITER=1 PF=4 TARGET=hw
</pre></div>
</div>
<ul>
<li><p>If you are using an <code class="docutils literal notranslate"><span class="pre">xclbin</span></code> provided as part of solution in this tutorial, then use the following command.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>cd $LAB_WORK_DIR/makefile; make run STEP=single_buffer ITER=1 PF=4 TARGET=hw SOLUTION=1
</pre></div>
</div>
</li>
<li><p>To use four words in parallel, <code class="docutils literal notranslate"><span class="pre">PF=4</span></code> will set the PARALLELIZATION macro to 4 in <code class="docutils literal notranslate"><span class="pre">$LAB_WORK_DIR/reference_files/compute_score_fpga_kernel.cpp</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ITER=1</span></code> indicates buffer sent using single iteration (using a single buffer).</p></li>
</ul>
<p>The following output displays.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Loading</span> <span class="n">runOnfpga_hw</span><span class="o">.</span><span class="n">xclbin</span>
<span class="n">Processing</span> <span class="mf">1398.903</span> <span class="n">MBytes</span> <span class="n">of</span> <span class="n">data</span>
  <span class="n">Running</span> <span class="k">with</span> <span class="n">a</span> <span class="n">single</span> <span class="n">buffer</span> <span class="n">of</span> <span class="mf">1398.903</span> <span class="n">MBytes</span> <span class="k">for</span> <span class="n">FPGA</span> <span class="n">processing</span>
<span class="o">--------------------------------------------------------------------</span>
<span class="n">Executed</span> <span class="n">FPGA</span> <span class="n">accelerated</span> <span class="n">version</span>  <span class="o">|</span>   <span class="mf">838.5898</span> <span class="n">ms</span>   <span class="p">(</span> <span class="n">FPGA</span> <span class="mf">447.964</span> <span class="n">ms</span> <span class="p">)</span>
<span class="n">Executed</span> <span class="n">Software</span><span class="o">-</span><span class="n">Only</span> <span class="n">version</span>     <span class="o">|</span>   <span class="mf">3187.0354</span> <span class="n">ms</span>
<span class="o">--------------------------------------------------------------------</span>
<span class="n">Verification</span><span class="p">:</span> <span class="n">PASS</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Total FPGA time is 447 ms. This includes the host to DDR transfer, Total Compute on FPGA and DDR to host transfer.</p></li>
<li><p>Total time of computing 100,000 documents is about 838 ms.</p></li>
</ul>
</li>
</ol>
<p>At this point, review the Profile reports and Timeline Trace to extract information, such as how much time it takes to transfer the data between host and kernel and how much time it takes to compute on the FPGA.</p>
</div>
<div class="section" id="visualize-the-resources-utilized">
<h3>Visualize the Resources Utilized<a class="headerlink" href="#visualize-the-resources-utilized" title="Permalink to this heading">¶</a></h3>
<p>Use the Vitis analyzer to visualize the HLS Synthesis Report. You will need to build the kernel without <code class="docutils literal notranslate"><span class="pre">SOLUTION=1</span></code> to <code class="docutils literal notranslate"><span class="pre">generate</span> <span class="pre">link_summary</span></code> as this is not provided as part of tutorial. You can skip this step as well.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>vitis_analyzer $LAB_WORK_DIR/build/single_buffer/kernel_4/hw/runOnfpga_hw.xclbin.link_summary
</pre></div>
</div>
<p>The HLS Synthesis Report shows the number of LUTs, REG, and BRAM utilized for the Bloom4x kernel implementation.</p>
<p><img alt="../../../../_images/kernel_4_util.PNG" src="../../../../_images/kernel_4_util.PNG" /></p>
</div>
<div class="section" id="review-profile-reports-and-timeline-trace">
<h3>Review Profile Reports and Timeline Trace<a class="headerlink" href="#review-profile-reports-and-timeline-trace" title="Permalink to this heading">¶</a></h3>
<p>Use the Vitis analyzer to visualize the <code class="docutils literal notranslate"><span class="pre">run_summary</span></code> report.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>vitis_analyzer $LAB_WORK_DIR/build/single_buffer/kernel_4/hw/runOnfpga_hw.xclbin.run_summary
</pre></div>
</div>
<p>The Profile Summary and Timeline Trace reports are useful tools to analyze the performance of the FPGA-accelerated application.</p>
</div>
<div class="section" id="review-profile-summary-report">
<h3>Review Profile Summary Report<a class="headerlink" href="#review-profile-summary-report" title="Permalink to this heading">¶</a></h3>
<ul>
<li><p><em>Kernels &amp; Compute Unit: Kernel Execution</em> indicates that the Total Time by kernel enqueue is about 292 ms.</p>
<p><img alt="../../../../_images/kernel_4_profile_1.PNG" src="../../../../_images/kernel_4_profile_1.PNG" /></p>
<ul class="simple">
<li><p>4 words in parallel are computed. The accelerator is architected at 300 MHz. In total, you are computing 350,000,000 words (3,500 words/document * 100,000 documents).</p></li>
<li><p>Number of words/(Clock Freq * Parallelization factor in kernel) = 350M/(300M*4) = 291.6 ms. The actual FPGA compute time is almost same as your theoretical calculations.</p></li>
</ul>
</li>
<li><p><em>Host Data Transfer: Host Transfer</em> shows that the Host Write Transfer to DDR is 145 ms and the Host Read Transfer to DDR is 36 ms.
<img alt="../../../../_images/kernel_4_profile_2.PNG" src="../../../../_images/kernel_4_profile_2.PNG" /></p>
<ul class="simple">
<li><p>Host Write transfer using a theoretical PCIe bandwidth of 9GB should be 1399 MB/9GBps = 154 ms</p></li>
<li><p>Host Read transfer using a theoretical PCIe bandwidth of 12GB should be 350 MB/12 GBps = 30 ms</p></li>
<li><p>Reported number indicates that the PCIe transfers are occurring at the maximum bandwidth</p></li>
</ul>
</li>
<li><p><em>Kernels &amp; Compute Unit: Compute Unit Stalls</em> confirms that there are almost no “External Memory Stalls”
<img alt="../../../../_images/Kernel_4_Guidance_Stall.PNG" src="../../../../_images/Kernel_4_Guidance_Stall.PNG" /></p></li>
</ul>
</div>
<div class="section" id="review-the-timeline-trace">
<h3>Review the Timeline Trace<a class="headerlink" href="#review-the-timeline-trace" title="Permalink to this heading">¶</a></h3>
<p>The Timeline Trace shows the data transfer from the host to the FPGA and back to the host as they appear. The Timeline Trace can be visualized so that the transfer from the host to the FPGA and the FPGA compute and transfer from the FPGA to host occur sequentially.</p>
<p><img alt="../../../../_images/Kernel_4_time_1.PNG" src="../../../../_images/Kernel_4_time_1.PNG" /></p>
<ul class="simple">
<li><p>There is a sequential execution of operations starting from the data transferred from the host to the FPGA, followed by compute in the FPGA and transferring back the results from the FPGA to the host.</p></li>
<li><p>At any given time, either the host or FPGA has access to the DDR. In other words, there is no memory contention between the host and kernel accessing the same DDR.</p></li>
<li><p>Using a single buffer will create a kernel itself with lowest latency and most optimized performance.</p></li>
</ul>
</div>
<div class="section" id="throughput-achieved">
<h3>Throughput Achieved<a class="headerlink" href="#throughput-achieved" title="Permalink to this heading">¶</a></h3>
<p>Based on the results, the throughput of the application is 1399 MB/838 ms = approx 1.66 GBs. This is your first attempt to run the application on hardware, and you have four times the performance results compared to the software-only version.</p>
</div>
<div class="section" id="opportunities-for-performance-improvements">
<h3>Opportunities for Performance Improvements<a class="headerlink" href="#opportunities-for-performance-improvements" title="Permalink to this heading">¶</a></h3>
<p>Because there is no external memory access contention for accessing memory, this is the best possible performance for the Kernel computing four words in parallel.</p>
<ul class="simple">
<li><p>The kernel is reading 512-bits of data, but only 128-bits are used to compute 4 words in parallel. The kernel has the potential to compute more words because you have resources available on the FPGA. You can increase the number of words to be processed in parallel and can experiment with 8 words and 16 words in parallel.</p></li>
<li><p>Also note, even though the kernel is operating at its best performance, the kernel has to wait until the complete transfer is done by the host. Usually, it is recommended that you send a larger buffer from the host to DDR, but a very large buffer will add a delay before the kernel can start, impacting overall performance.</p></li>
</ul>
<p>You will continue this lab and create a kernel with 8 words to be computed in parallel. In the next lab, <a class="reference internal" href="5_data-movement.html"><span class="doc">Analyze Data Movement Between Host and Kernel</span></a>, you will experiment with splitting the buffer into multiple chunks, and observe how this affects the performance later in this tutorial.</p>
</div>
</div>
<div class="section" id="bloom8x-kernel-implementation-using-8-words-in-parallel">
<h2>Bloom8x: Kernel Implementation Using 8 Words in Parallel<a class="headerlink" href="#bloom8x-kernel-implementation-using-8-words-in-parallel" title="Permalink to this heading">¶</a></h2>
<p>For config Bloom4x, you read 512-bit input values from the DDR and computed 4 words in parallel which uses only 128-bit input values. This steps enables you to run 8 words in parallel.</p>
<p>You can achieve this by using <code class="docutils literal notranslate"><span class="pre">PF=8</span></code> on the command line. Use the following steps to compute 8 words in parallel.</p>
<div class="section" id="run-hardware-on-the-fpga">
<h3>Run Hardware on the FPGA<a class="headerlink" href="#run-hardware-on-the-fpga" title="Permalink to this heading">¶</a></h3>
<p>Use the following command to run the hardware on the FPGA.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>cd $LAB_WORK_DIR/makefile; make run STEP=single_buffer ITER=1 PF=8 
</pre></div>
</div>
<p>The following output displays.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Single_Buffer</span><span class="p">:</span> <span class="n">Running</span> <span class="k">with</span> <span class="n">a</span> <span class="n">single</span> <span class="n">buffer</span> <span class="n">of</span> <span class="mf">1398.903</span> <span class="n">MBytes</span> <span class="k">for</span> <span class="n">FPGA</span> <span class="n">processing</span>
<span class="o">--------------------------------------------------------------------</span>
 <span class="n">Executed</span> <span class="n">FPGA</span> <span class="n">accelerated</span> <span class="n">version</span>  <span class="o">|</span>   <span class="mf">739.4475</span> <span class="n">ms</span>   <span class="p">(</span> <span class="n">FPGA</span> <span class="mf">315.475</span> <span class="n">ms</span> <span class="p">)</span>
 <span class="n">Executed</span> <span class="n">Software</span><span class="o">-</span><span class="n">Only</span> <span class="n">version</span>     <span class="o">|</span>   <span class="mf">3053.9516</span> <span class="n">ms</span>
<span class="o">--------------------------------------------------------------------</span>
 <span class="n">Verification</span><span class="p">:</span> <span class="n">PASS</span>
</pre></div>
</div>
<ul class="simple">
<li><p>The Total FPGA time is 315 ms. This includes the Host to DDR transfer, Total Compute on FPGA and DDR to Host transfer.</p></li>
<li><p>As expected, when computing 8 words in parallel, the total FPGA Time that includes the data transfer between the host and device, has reduced from 447 ms to 315 ms.</p></li>
</ul>
</div>
<div class="section" id="id1">
<h3>Visualize the Resources Utilized<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h3>
<p>Use the Vitis analyzer to visualize the HLS Synthesis Report. You will need to build the kernel without <code class="docutils literal notranslate"><span class="pre">SOLUTION=1</span></code> to generate link_summary; this is not provided as part of tutorial. You can skip this step.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>vitis_analyzer $LAB_WORK_DIR/build/single_buffer/kernel_8/hw/runOnfpga_hw.xclbin.link_summary
</pre></div>
</div>
<p>From the HLS Synthesis Report, you can see that the number of resources increased for LUTs, REG, and BRAM compared to the Bloom4x kernel implementation.</p>
<p><img alt="../../../../_images/kernel_8_util.PNG" src="../../../../_images/kernel_8_util.PNG" /></p>
</div>
<div class="section" id="review-profile-summary-report-and-timeline-trace">
<h3>Review Profile Summary Report and Timeline Trace<a class="headerlink" href="#review-profile-summary-report-and-timeline-trace" title="Permalink to this heading">¶</a></h3>
<p>Use the Vitis analyzer to visualize the run_summary report.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>vitis_analyzer $LAB_WORK_DIR/build/single_buffer/kernel_8/hw/runOnfpga_hw.xclbin.run_summary
</pre></div>
</div>
<p>Review the profile reports and compare the metrics with configuration Bloom4x</p>
<ol>
<li><p><em>Kernels &amp; Compute Unit:Kernel Execution</em> reports 146 ms compared to the 292 ms. This is exactly half the time as now 8 words are computed in parallel instead of 4 words.</p></li>
<li><p><em>Host Data Transfer: Host Transfer</em> section reports the same delays.</p></li>
<li><p>The overall gain in the application overall gain is only because that kernel now is processing 8 words in parallel compared to 4 words in parallel.</p>
<p><img alt="../../../../_images/Kernel_8_time_1.PNG" src="../../../../_images/Kernel_8_time_1.PNG" /></p>
</li>
</ol>
</div>
<div class="section" id="id2">
<h3>Throughput Achieved<a class="headerlink" href="#id2" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Based on the results, the throughput of the application is 1399 MB/739 ms = approximately 1.9 GBs. You have now 4x performance results compared to software-only version.</p></li>
</ul>
</div>
</div>
<div class="section" id="bloom16x-kernel-implementation-using-16-words-in-parallel">
<h2>Bloom16x : Kernel Implementation Using 16 Words in Parallel<a class="headerlink" href="#bloom16x-kernel-implementation-using-16-words-in-parallel" title="Permalink to this heading">¶</a></h2>
<p>In the previous step, you read 512-bit input values from the DDR and computed 8 words in parallel. You can compute 16 words in parallel by setting <code class="docutils literal notranslate"><span class="pre">PF=16</span></code> on the command line. Use the following steps to compute 16 words in parallel.</p>
<div class="section" id="id3">
<h3>Run Hardware on the FPGA<a class="headerlink" href="#id3" title="Permalink to this heading">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>cd $LAB_WORK_DIR/makefile; make run STEP=single_buffer ITER=1 PF=16
</pre></div>
</div>
<p>The following output displays.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Processing</span> <span class="mf">1398.903</span> <span class="n">MBytes</span> <span class="n">of</span> <span class="n">data</span>
 <span class="n">Single_Buffer</span><span class="p">:</span> <span class="n">Running</span> <span class="k">with</span> <span class="n">a</span> <span class="n">single</span> <span class="n">buffer</span> <span class="n">of</span> <span class="mf">1398.903</span> <span class="n">MBytes</span> <span class="k">for</span> <span class="n">FPGA</span> <span class="n">processing</span>
<span class="o">--------------------------------------------------------------------</span>
 <span class="n">Executed</span> <span class="n">FPGA</span> <span class="n">accelerated</span> <span class="n">version</span>  <span class="o">|</span>   <span class="mf">694.6162</span> <span class="n">ms</span>   <span class="p">(</span> <span class="n">FPGA</span> <span class="mf">270.275</span> <span class="n">ms</span> <span class="p">)</span>
 <span class="n">Executed</span> <span class="n">Software</span><span class="o">-</span><span class="n">Only</span> <span class="n">version</span>     <span class="o">|</span>   <span class="mf">3052.5701</span> <span class="n">ms</span>
<span class="o">--------------------------------------------------------------------</span>
 <span class="n">Verification</span><span class="p">:</span> <span class="n">PASS</span>
</pre></div>
</div>
<p>As previous steps, you can also review profile and timeline trace reports. This is left out as an homework exercise.</p>
</div>
<div class="section" id="id4">
<h3>Opportunities for Performance Improvements<a class="headerlink" href="#id4" title="Permalink to this heading">¶</a></h3>
<p>In this lab, you focused on building on an optimal kernel with 4, 8 and 16 words in parallel using a single buffer and reviewed the reports. As you observed from the Timeline Report that the kernel cannot start until the whole buffer is transferred to the DDR, which is about 145 ms when the single buffer is used. This is a substantial time delay considering the <code class="docutils literal notranslate"><span class="pre">Kernel</span> <span class="pre">execution</span> <span class="pre">time</span></code> is even smaller than the total host transfer time.</p>
</div>
</div>
<div class="section" id="next-steps">
<h2>Next Steps<a class="headerlink" href="#next-steps" title="Permalink to this heading">¶</a></h2>
<p>In the next lab, you <a class="reference internal" href="5_data-movement.html"><span class="doc">explore sending documents in multiple buffers</span></a> rather than sending all of the documents at once from the host and explore how this improves the overall application performance. You will also use the configuration <code class="docutils literal notranslate"><span class="pre">Bloom8x</span></code> kernel and <code class="docutils literal notranslate"><span class="pre">Bloom16x</span></code> kernel for exploration in the next step.</p>
<hr/>
<p align="center" class="sphinxhide"><b><a href="/docs/vitis-getting-started/README.md">Return to Getting Started Pathway</a> — <a href="docs/bloom/README.md">Return to Start of Tutorial</a></b></p><p align="center" class="sphinxhide"><sup>Copyright&copy; 2020 Xilinx</sup></p></div>
</div>


           </div>
          </div>
          
                  <style>
                        .footer {
                        position: fixed;
                        left: 0;
                        bottom: 0;
                        width: 100%;
                        }
                  </style>
				  
				  <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019-2022, Xilinx, Inc. Xilinx is now a part of AMD.
      <span class="lastupdated">Last updated on August 5, 2022.
      </span></p>
  </div>



										<div class="aem-Grid aem-Grid--16">
											<div class="aem-GridColumn aem-GridColumn--xxxlarge--none aem-GridColumn--xsmall--16 aem-GridColumn--offset--xsmall--0 aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--xsmall--none aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
												<div class="container-fluid sub-footer">

													                    <div class="row">
                        <div class="col-xs-24">
                          <p><a target="_blank" href="https://www.amd.com/en/corporate/copyright">Terms and Conditions</a> | <a target="_blank" href="https://www.amd.com/en/corporate/privacy">Privacy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/cookies">Cookie Policy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/trademarks">Trademarks</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/statement-human-trafficking-forced-labor.pdf">Statement on Forced Labor</a> | <a target="_blank" href="https://www.amd.com/en/corporate/competition">Fair and Open Competition</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/amd-uk-tax-strategy.pdf">UK Tax Strategy</a> | <a target="_blank" href="https://docs.xilinx.com/v/u/9x6YvZKuWyhJId7y7RQQKA">Inclusive Terminology</a> | <a href="#cookiessettings" class="ot-sdk-show-settings">Cookies Settings</a></p>
                        </div>
                    </div>
												</div>
											</div>
										</div>
										
</br>


  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>