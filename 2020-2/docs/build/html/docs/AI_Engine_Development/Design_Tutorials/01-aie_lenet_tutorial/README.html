<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
<!-- OneTrust Cookies Consent Notice start for xilinx.github.io -->

<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="03af8d57-0a04-47a6-8f10-322fa00d8fc7" ></script>
<script type="text/javascript">
function OptanonWrapper() { }
</script>
<!-- OneTrust Cookies Consent Notice end for xilinx.github.io -->
  <title>Table of Contents &mdash; Vitis™ Tutorials 2020.2 documentation</title>
      <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
            <a href="../../../../index.html" class="icon icon-home"> Vitis™ Tutorials
            <img src="../../../../_static/xilinx-header-logo.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                2020.2
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">日本語版</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/Vitis-Tutorials/master/docs-jp/README.html">Master</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting Started Pathway</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Getting_Started/Vitis/README.html">Vitis Flow 101 Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Getting_Started/Vitis_HLS/README.html">Vitis HLS Analysis and Optimization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Hardware Accelerators</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Hardware_Accelerators/Introduction/README.html">Introduction to Vitis Hardware Accelerators Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Hardware_Accelerators/Design_Tutorials/02-bloom/README.html">Optimizing Accelerated FPGA Applications: Bloom Filter Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Hardware_Accelerators/Design_Tutorials/01-convolution-tutorial/README.html">Accelerating Video Convolution Filtering Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Hardware_Accelerators/Design_Tutorials/03-rtl_stream_kernel_integration/README.html">Mixed Kernels Design Tutorial with AXI Stream and Vitis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Hardware_Accelerators/Design_Tutorials/04-traveling-salesperson/README.html">The Travelling Salesman Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Hardware_Accelerators/Design_Tutorials/05-bottom_up_rtl_kernel/README.html">Bottom-up RTL Kernel Flow with Vitis for Acceleration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Hardware_Accelerators/Feature_Tutorials/01-rtl_kernel_workflow/README.html">Getting Started with RTL Kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Hardware_Accelerators/Feature_Tutorials/02-mixing-c-rtl-kernels/README.html">Mixing C++ and RTL Kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Hardware_Accelerators/Feature_Tutorials/03-dataflow_debug_and_optimization/README.html">Vitis HLS Analysis and Optimization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Runtime and System Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/Design_Tutorials/01-host-code-opt/README.html">Host Code Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/Design_Tutorials/02-ivas-ml/README.html">IVAS ZCU104 ML Acceleration Reference Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/Feature_Tutorials/01-mult-ddr-banks/README.html">Using Multiple DDR Banks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/Feature_Tutorials/02-using-multiple-cu/README.html">Using Multiple Compute Units</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/Feature_Tutorials/03-controlling-vivado-implementation/README.html">Controlling Vivado Implementation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Runtime_and_System_Optimization/Feature_Tutorials/04-using-hbm/README.html">Using HBM</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Vitis Platform Creation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Vitis_Platform_Creation/Introduction/01-Overview/README.html">Platform Creation Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Vitis_Platform_Creation/Introduction/02-Edge-AI-ZCU104/README.html">Vitis Custom Embedded Platform Creation Example on ZCU104</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Vitis_Platform_Creation/Introduction/03_Edge_VCK190/README.html">Versal Custom Platform Creation Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Versions</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://xilinx.github.io/Vitis-Tutorials/">Main</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: black" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">Vitis™ Tutorials</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Table of Contents</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../_sources/docs/AI_Engine_Development/Design_Tutorials/01-aie_lenet_tutorial/README.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <table>
 <tr>
   <td align="center"><img src="https://raw.githubusercontent.com/Xilinx/Image-Collateral/main/xilinx-logo.png" width="30%"/><h1>2020.2 Versal™ AI Engine LeNet Tutorial</h1>
   </td>
 </tr>
</table><div class="section" id="table-of-contents">
<h1>Table of Contents<a class="headerlink" href="#table-of-contents" title="Permalink to this heading">¶</a></h1>
<p><a class="reference external" href="#introduction">Introduction</a></p>
<p><a class="reference external" href="#Before-you-Begin">Before You Begin</a></p>
<p><a class="reference external" href="#building-the-lenet-design">Building the Lenet Design</a></p>
<p><a class="reference external" href="#hardware-design-details">Hardware Design Details</a></p>
<p><a class="reference external" href="#software-design-details">Software Design Details</a></p>
<p><a class="reference external" href="#references">References</a></p>
</div>
<div class="section" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading">¶</a></h1>
<p>The Xilinx® Versal ACAP is a fully software-programmable, heterogeneous compute platform that combines the Processor System (PS) (Scalar Engines that include the Arm® processors), Programmable Logic (PL) (Adaptable Engines that include the programmable logic blocks and memory) and AI Engines which belong in the Intelligent Engine category.</p>
<p>This tutorial uses the LeNet algorithm to implement a system-level design to perform image classification using the AI Engine and PL logic, including block RAM (BRAM). The design demonstrates functional partitioning between the AI Engine and PL. It also highlights memory partitioning and hierarchy among DDR memory, PL (BRAM) and AI Engine memory.</p>
<p>The tutorial takes you through hardware emulation and hardware flow in the context of a complete Versal ACAP system integration. A Makefile is provided that you can modify to suit your own needs in a different context.</p>
<details>
  <summary>Objectives</summary> <div class="section" id="objectives">
<h2>Objectives<a class="headerlink" href="#objectives" title="Permalink to this heading">¶</a></h2>
<p>After completing the tutorial, you should be able to:</p>
<ul class="simple">
<li><p>Build a complete system design by going through the various steps in the Vitis™ unified software platform flow, including creating the AI Engine Adaptive Data Flow API (ADF) graph, compiling the A72 host application and compiling PL kernels, using the Vitis compiler (V++) to link the AI Engine and HLS kernels with the platform, and packaging the design. You will also be able to run the design through the hardware emulation and hardware flow in a mixed System C/RTL cycle-accurate/QEMU-based simulator</p></li>
<li><p>Develop an understanding of CNN (Convolutional Neural Network) layer details using the LeNet algorithm and how the layers are mapped into data processing and compute blocks</p></li>
<li><p>Develop an understanding of the kernels developed in the design - AI Engine kernels to process fully connected convolutional layers and PL kernels to process the input rearrange and max pool and rearrange functions</p></li>
<li><p>Develop an understanding of the AI Engine IP interface using the AXI4-Stream interface</p></li>
<li><p>Develop an understanding of memory hierarchy in a system-level design involving DDR memory, PL BRAM, and AI Engine memory</p></li>
<li><p>Develop an understanding of graph control APIs to enable run-time updates using the run-time parameter (RTP) interface</p></li>
<li><p>Develop an understanding of performance measurement and functional/throughput debug at the application level</p></li>
</ul>
</details><details>
  <summary>Tutorial overview</summary> </div>
<div class="section" id="tutorial-overview">
<h2>Tutorial Overview<a class="headerlink" href="#tutorial-overview" title="Permalink to this heading">¶</a></h2>
<p>In this application tutorial, the LeNet algorithm is used to perform image classification on an input image using five AI Engine tiles and PL resources including block RAM. A top level block diagram is shown in the following figure. An image is loaded from DDR memory through the NoC to block RAM and then to the AI Engine. The PL input pre-processing unit receives the input image and sends the output to the first AI Engine tile to perform matrix multiplication. The output from the first AI Engine tile goes to a PL unit to perform the first level of maxpool and data rearrangement (M1R1). The output is fed to the second AI Engine tile and the output from that tile is sent to the PL to perform the second level maxpooling and data rearrangement (M2R2). The output is then sent to a fully connected layer (FC1) implemented in two AI Engine tiles and uses the rectified linear unit layer (ReLu) as an activation function. The outputs from the two AI Engine tiles are then fed into a second fully connected layer implemented in the fifth AI Engine tile. The output is sent to a data conversion unit in the PL and then to the DDR memory through the NoC. In between the AI Engine and PL units is a datamover module (refer to the Lenet Controller in the figure below) that contains the following kernels:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mm2s</span></code>: a Memory Mapped to Stream kernel to feed data from DDR memory through the NoC to the AI Engine Array</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">s2mm</span></code>: a Stream to Memory Mapped kernel to feed data from the AI Engine Array through NoC to DDR memory</p></li>
</ul>
<p><img alt="Image of LeNet Block Diagram" src="../../../../_images/Lenet_block_diagram_v1.PNG" /></p>
<p>In the design, there are two major PL kernels. The input pre-processing unit, M1R1 and M2R2 are contained in the <code class="docutils literal notranslate"><span class="pre">lenet_kernel</span></code> RTL kernel which has already been packaged as a Xilinx object <code class="docutils literal notranslate"><span class="pre">.xo</span></code> (XO) file. The datamover kernel <code class="docutils literal notranslate"><span class="pre">dma_hls</span></code> provides the interface between the AI Engine and DDR memory. The five AI Engine kernels all implement matrix multiplication. The matrix dimensions depend on the image dimension, weight dimension, and number of features.</p>
</details><details>
  <summary>Directory Structure</summary> </div>
<div class="section" id="directory-structure">
<h2>Directory Structure<a class="headerlink" href="#directory-structure" title="Permalink to this heading">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">lenet</span>
<span class="o">|</span><span class="n">____design</span><span class="o">......................</span><span class="n">contains</span> <span class="n">AI</span> <span class="n">Engine</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">HLS</span> <span class="n">kernel</span> <span class="n">source</span> <span class="n">files</span><span class="p">,</span> <span class="ow">and</span> <span class="nb">input</span> <span class="n">data</span> <span class="n">files</span>
<span class="o">|</span>    <span class="o">|</span><span class="n">___aie_src</span>
<span class="o">|</span>    <span class="o">|</span>   <span class="o">|</span><span class="n">___data</span>
<span class="o">|</span>    <span class="o">|</span><span class="n">___pl_src</span>
<span class="o">|</span><span class="n">___images</span><span class="o">......................</span><span class="n">contains</span> <span class="n">images</span> <span class="n">that</span> <span class="n">appear</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">README</span><span class="o">.</span><span class="n">md</span>
<span class="o">|</span><span class="n">___Makefiles</span><span class="o">...................</span><span class="n">contains</span> <span class="n">Makefile</span> <span class="ow">and</span> <span class="n">configuration</span> <span class="p">(</span><span class="o">.</span><span class="n">cfg</span><span class="p">)</span> <span class="n">files</span> <span class="ow">and</span> <span class="n">HLS</span> <span class="n">kernel</span> <span class="n">Vivado</span> <span class="n">optimizations</span> <span class="n">Tcl</span> <span class="n">scripts</span>
</pre></div>
</div>
</details></div>
</div>
<div class="section" id="before-you-begin">
<h1>Before You Begin<a class="headerlink" href="#before-you-begin" title="Permalink to this heading">¶</a></h1>
<p>Note: This tutorial targets the VCK190 ES board (see https://www.xilinx.com/products/boards-and-kits/vck190.html). This board is currently available via early access. If you have already purchased this board, download the necessary files from the lounge and ensure you have the correct licenses installed. If you do not have a board and ES license please contact your Xilinx sales contact.</p>
<details><summary>Documentation: Explore AI Engine Architecture</summary> <div class="section" id="documentation-explore-ai-engine-architecture">
<h2><em>Documentation</em>: Explore AI Engine Architecture<a class="headerlink" href="#documentation-explore-ai-engine-architecture" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://www.xilinx.com/support/documentation/architecture-manuals/am009-versal-ai-engine.pdf">AM009 AI Engine Architecture Manual</a></p></li>
<li><p><a class="reference external" href="https://forums.xilinx.com/t5/Design-and-Debug-Techniques-Blog/Versal-ACAP-AI-Engines-for-Dummies/ba-p/1132493">Versal ACAP AI Engines for Dummies</a></p></li>
</ul>
</details><details><summary>Tools: Installing the Tools</summary> </div>
<div class="section" id="tools-installing-the-tools">
<h2><em>Tools</em>: Installing the Tools<a class="headerlink" href="#tools-installing-the-tools" title="Permalink to this heading">¶</a></h2>
<p>Tools Documentation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.xilinx.com/member/versal_ai_tools_ea.html">AI Engine Tools lounge</a></p></li>
<li><p><a class="reference external" href="https://www.xilinx.com/html_docs/xilinx2020_2/vitis_doc/yii1603912637443.html">AI Engine Documentation</a></p></li>
</ul>
<p>To build and run the Lenet tutorial, you will need the following tools downloaded/installed:</p>
<ul class="simple">
<li><p>Install the <a class="reference external" href="https://www.xilinx.com/html_docs/xilinx2020_2/vitis_doc/acceleration_installation.html#dhg1543555360045__ae364401">Vitis Software Platform 2020.2</a></p></li>
<li><p>Obtain a license to enable Beta Devices in Xilinx tools (to use the <code class="docutils literal notranslate"><span class="pre">xilinx_vck190_es1_base_202020_1</span></code> platform)</p></li>
<li><p>Obtain licenses for AI Engine tools</p></li>
<li><p>Follow the instructions in <a class="reference external" href="https://www.xilinx.com/html_docs/xilinx2020_2/vitis_doc/acceleration_installation.html#dhg1543555360045__ae364401">Installing Xilinx Runtime and Platforms</a> (XRT)</p></li>
<li><p>Download and setup the <a class="reference external" href="https://www.xilinx.com/member/vck190_headstart.html#docs">VCK190 Vitis Platform for 2020.2</a></p></li>
</ul>
</details><details>
<summary>Environment: Setting Up the Shell Environment</summary> </div>
<div class="section" id="environment-setting-up-the-shell-environment">
<h2>Environment: Setting Up the Shell Environment<a class="headerlink" href="#environment-setting-up-the-shell-environment" title="Permalink to this heading">¶</a></h2>
<p>When the elements of the Vitis software platform are installed, update the shell environment script. Set the environment variables to your system specific paths.</p>
<p>Edit <code class="docutils literal notranslate"><span class="pre">env_setup_2020.sh</span></code> script with your file paths:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">XILINX_XRT</span><span class="o">=</span>&lt;XRT-LOCATION&gt;
<span class="nb">export</span> <span class="nv">PLATFORM_REPO_PATHS</span><span class="o">=</span>&lt;YOUR-PLATFORM-DIRECTORY&gt; 

<span class="nb">source</span> &lt;XILNX-TOOLS-LOCATION&gt;/Vitis/&lt;TOOLS-BUILD&gt;/settings64.sh
<span class="nb">source</span> <span class="nv">$XILINX_XRT</span>/setup.sh
</pre></div>
</div>
<p>Then source the environment script:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">source</span> env_setup_2020.sh
</pre></div>
</div>
</details><details>
<summary>Validation: Confirming Tool Installation</summary> </div>
<div class="section" id="validation-confirming-tool-installation">
<h2>Validation: Confirming Tool Installation<a class="headerlink" href="#validation-confirming-tool-installation" title="Permalink to this heading">¶</a></h2>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>which vitis
which aiecompiler
</pre></div>
</div>
<p>Confirm you have the VCK190 ES1 Base Platform.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>platforminfo --list <span class="p">|</span> grep -m <span class="m">1</span> -A <span class="m">9</span> vck190_es1
</pre></div>
</div>
<p>Output of the above command should be as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span> <span class="s2">&quot;baseName&quot;</span>: <span class="s2">&quot;xilinx_vck190_es1_base_202020_1&quot;</span>,
            <span class="s2">&quot;version&quot;</span>: <span class="s2">&quot;1.0&quot;</span>,
            <span class="s2">&quot;type&quot;</span>: <span class="s2">&quot;sdsoc&quot;</span>,
            <span class="s2">&quot;dataCenter&quot;</span>: <span class="s2">&quot;false&quot;</span>,
            <span class="s2">&quot;embedded&quot;</span>: <span class="s2">&quot;true&quot;</span>,
            <span class="s2">&quot;externalHost&quot;</span>: <span class="s2">&quot;false&quot;</span>,
            <span class="s2">&quot;serverManaged&quot;</span>: <span class="s2">&quot;false&quot;</span>,
            <span class="s2">&quot;platformState&quot;</span>: <span class="s2">&quot;pre_synth&quot;</span>,
            <span class="s2">&quot;usesPR&quot;</span>: <span class="s2">&quot;false&quot;</span>,
</pre></div>
</div>
</details></div>
</div>
<div class="section" id="building-the-lenet-design">
<h1>Building the LeNet Design<a class="headerlink" href="#building-the-lenet-design" title="Permalink to this heading">¶</a></h1>
<details>
  <summary>LeNet Design Build</summary> <div class="section" id="lenet-design-build">
<h2>LeNet Design Build<a class="headerlink" href="#lenet-design-build" title="Permalink to this heading">¶</a></h2>
<p>In this section, you will build and run the LeNet design. You will compile the AI Engine design and integrate it into a larger system design (including the Programmable Logic (PL) kernels and Processing System (PS) host application). You can review <a class="reference external" href="#ai-engine-documentation">Integrating the Application Section in the AI Engine Documentation</a> for the general flow. The following image shows the Vitis tool flow with the <code class="docutils literal notranslate"><span class="pre">make</span></code> targets (in blue) and input source files and output file generation (in red) at each step.</p>
<p><img alt="Image of LeNet Vitis Tool Flow" src="../../../../_images/Lenet_vitis_toolflow_2020_2.PNG" /></p>
<p>At the end of this section, the design flow will generate a new directory (called <code class="docutils literal notranslate"><span class="pre">build/</span></code>) that contains the <code class="docutils literal notranslate"><span class="pre">Work/</span></code>, <code class="docutils literal notranslate"><span class="pre">hw_emu/</span></code>, and <code class="docutils literal notranslate"><span class="pre">hw/</span></code> subfolders. The <code class="docutils literal notranslate"><span class="pre">Work/</span></code> subfolder is an output from the AI Engine compiler. The <code class="docutils literal notranslate"><span class="pre">hw_emu/</span></code> subfolder contains the build for hardware emulation. The <code class="docutils literal notranslate"><span class="pre">hw/</span></code> subfolder contains the build for hardware run on a VCK190 board.</p>
</details></div>
</div>
<div class="section" id="make-steps">
<h1>Make Steps<a class="headerlink" href="#make-steps" title="Permalink to this heading">¶</a></h1>
<p>To run the following <code class="docutils literal notranslate"><span class="pre">make</span></code> steps (e.g. <code class="docutils literal notranslate"><span class="pre">make</span> <span class="pre">kernels</span></code>, <code class="docutils literal notranslate"><span class="pre">make</span> <span class="pre">graph</span></code>, etc), you must be in the <code class="docutils literal notranslate"><span class="pre">Makefiles/</span></code> folder.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> Makefiles
</pre></div>
</div>
<details>
<summary>Build the Entire Design with a Single Command</summary><div class="section" id="build-the-entire-design-with-a-single-command">
<h2>Build the Entire Design with a Single Command<a class="headerlink" href="#build-the-entire-design-with-a-single-command" title="Permalink to this heading">¶</a></h2>
<p>If you are an advanced user and are already familiar with the AI Engine and Vitis kernel compilation flows, you can build the entire design with one command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>make build <span class="nv">TARGET</span><span class="o">=</span>hw_emu 
</pre></div>
</div>
<p>or</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>make build <span class="nv">TARGET</span><span class="o">=</span>hw
</pre></div>
</div>
<p>This command will run the <code class="docutils literal notranslate"><span class="pre">make</span> <span class="pre">kernels</span></code> <code class="docutils literal notranslate"><span class="pre">make</span> <span class="pre">graph</span></code> <code class="docutils literal notranslate"><span class="pre">make</span> <span class="pre">xclbin</span></code> <code class="docutils literal notranslate"><span class="pre">make</span> <span class="pre">application</span></code> and <code class="docutils literal notranslate"><span class="pre">make</span> <span class="pre">package</span></code> for hardware emulation or to run on hardware (VCK190 board) depending on the <code class="docutils literal notranslate"><span class="pre">TARGET</span></code> you specify.</p>
<p>You can also run the following command to build the entire Lenet tutorial <em>and</em> launch hardware emulation:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>make run <span class="nv">TARGET</span><span class="o">=</span>hw_emu
</pre></div>
</div>
</details><details>
  <summary>make kernels: Compile PL Kernels</summary> </div>
<div class="section" id="make-kernels-compile-pl-kernels">
<h2>make kernels: Compile PL Kernels<a class="headerlink" href="#make-kernels-compile-pl-kernels" title="Permalink to this heading">¶</a></h2>
<p>In this step, the Vitis compiler takes any V++ kernels (RTL or HLS C) in the PL region of the target platform (<code class="docutils literal notranslate"><span class="pre">xilinx_vck190_es1_base_202020_1</span></code>) and the AI Engine kernels and graph and compiles them into their respective XO files. In this design, the <code class="docutils literal notranslate"><span class="pre">dma_hls</span></code> kernel is compiled as an XO file and the <code class="docutils literal notranslate"><span class="pre">Lenet_kernel</span></code> has already been pre-compiled as an XO file. Users can access the source code by unzipping the .xo file</p>
<p><code class="docutils literal notranslate"><span class="pre">unzip</span> <span class="pre">lenet_kernel.xo</span></code></p>
<p>The files will be stored under <code class="docutils literal notranslate"><span class="pre">ip_repo</span></code> folder.</p>
<p>The following commands compiles the kernels (default TARGET=hw_emu).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">kernels</span>
</pre></div>
</div>
<p>The expanded command is as follow:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mkdir</span> <span class="o">-</span><span class="n">p</span> <span class="o">../</span><span class="n">build</span><span class="o">/</span><span class="n">hw_emu</span>

<span class="n">cd</span> <span class="o">../</span><span class="n">build</span><span class="o">/</span><span class="n">hw_emu</span>

<span class="n">v</span><span class="o">++</span>       <span class="o">--</span><span class="n">target</span> <span class="n">hw_emu</span>			     \
          <span class="o">--</span><span class="n">platform</span> <span class="n">xilinx_vck190_es1_base_202020_1</span> \
          <span class="o">--</span><span class="n">save</span><span class="o">-</span><span class="n">temps</span>                               \
	  <span class="o">--</span><span class="n">temp_dir</span> <span class="n">_x</span>	                             \
          <span class="o">--</span><span class="n">verbose</span>                                  \
          <span class="o">-</span><span class="n">c</span> <span class="o">../../</span><span class="n">design</span><span class="o">/</span><span class="n">pl_src</span><span class="o">/</span><span class="n">datamover</span><span class="o">/</span><span class="n">dma_hls</span><span class="o">.</span><span class="n">cpp</span>\
          <span class="o">-</span><span class="n">k</span> <span class="n">dms_hls</span>                                 \
          <span class="o">-</span><span class="n">o</span> <span class="n">dma_hls</span><span class="o">.</span><span class="n">hw_emu</span><span class="o">.</span><span class="n">xo</span> 
 
 <span class="n">cd</span> <span class="o">../../</span><span class="n">Makefiles</span><span class="p">;</span> 
</pre></div>
</div>
<p>|Switch|Description|
|  —  |  —  |
|–target | -t [hw|hw_emu]|Specifies the build target.|
|–platform | -f|Specifies the name of a supported acceleration platform as specified by the $PLATFORM_REPO_PATHS environment variable or the full path to the platform XPFM file.|
|–save-temps | -s|Directs the Vitis compiler command to save intermediate files/directories created during the compilation and link process. Use the <code class="docutils literal notranslate"><span class="pre">--temp_dir</span></code> option to specify a location to write the intermediate files to.|
|–temp_dir <string>|This allows you to manage the location where the tool writes temporary files created during the build process. The temporary results are written by the Vitis compiler, and then removed, unless the <code class="docutils literal notranslate"><span class="pre">--save-temps</span></code> option is also specified.|
|–verbose|Display verbose/debug information.|
|–compile | -c|Required for compilation to generate XO files from kernel source files.|
|–kernel &lt;arg&gt;|-k &lt;arg&gt;|Compile only the specified kernel from the input file. Only one -k option is allowed per Vitis compiler command.|
|–output | -o|Specifies the name of the output file generated by the V++ command. The DMA HLS kernels output should be XO.|</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Input</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>design/pl_src/datamover/dma_hls.cpp</td>
<td>Defines the datamover PL kernel.</td>
</tr>
</tbody>
</table><table border="1" class="docutils">
<thead>
<tr>
<th>Output</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>build/hw_emu/dma_hls.hw_emu.xo</td>
<td>The datamover kernel object file.</td>
</tr>
</tbody>
</table> </details><details>
  <summary>make graph: Creating the AI Engine ADF Graph for Vitis Compiler Flow</summary> </div>
<div class="section" id="make-graph-creating-the-ai-engine-adf-graph-for-vitis-compiler-flow">
<h2>make graph: Creating the AI Engine ADF Graph for Vitis Compiler Flow<a class="headerlink" href="#make-graph-creating-the-ai-engine-adf-graph-for-vitis-compiler-flow" title="Permalink to this heading">¶</a></h2>
<p>An ADF graph can be connected to an extensible Vitis platform (the graph I/Os can be connected either to platform ports or to ports on Vitis kernels through Vitis compiler connectivity directives.</p>
<ul class="simple">
<li><p>The AI Engine ADF C++ graph of the design contains AI Engine kernels and PL kernels.</p></li>
<li><p>All interconnects between kernels are defined in the C++ graph</p></li>
<li><p>All interconnections to external I/O are fully specified in the C++ simulation testbench (<code class="docutils literal notranslate"><span class="pre">graph.cpp</span></code>) that instantiates the C++ ADF graph object. All <code class="docutils literal notranslate"><span class="pre">adf::sim</span></code> platform connections from graph to PLIO map onto ports on the AI Engine subsystem graph that are connected using the Vitis compiler connectivity directives. No dangling ports or implicit connections are allowed by the Vitis compiler.</p></li>
</ul>
<p>To compile the graph using the Makefile flow type:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">graph</span>
</pre></div>
</div>
<p>The following AI Engine compiler command compiles the AI Engine design graph:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="o">../</span><span class="n">build</span><span class="p">;</span>
<span class="n">aiecompiler</span> <span class="o">--</span><span class="n">include</span><span class="o">=</span> <span class="o">../</span><span class="n">design</span><span class="o">/</span><span class="n">aie_src</span> \	
	    <span class="o">--</span><span class="n">include</span><span class="o">=</span> <span class="o">../</span><span class="n">design</span><span class="o">/</span><span class="n">aie_src</span><span class="o">/</span><span class="n">data</span>   \
            <span class="o">--</span><span class="n">verbose</span>                    \
            <span class="o">--</span><span class="n">log</span><span class="o">-</span><span class="n">level</span><span class="o">=</span><span class="mi">5</span>                \
            <span class="o">--</span><span class="n">test</span><span class="o">-</span><span class="n">iterations</span><span class="o">=</span><span class="mi">100</span>        \      
            <span class="o">--</span><span class="n">dataflow</span>                   \
            <span class="o">--</span><span class="n">heapsize</span><span class="o">=</span><span class="mi">2048</span>              \
            <span class="o">--</span><span class="n">workdir</span><span class="o">=</span><span class="n">Work</span>               \
            <span class="o">../</span><span class="n">design</span><span class="o">/</span><span class="n">aie_src</span><span class="o">/</span><span class="n">graph</span><span class="o">.</span><span class="n">cpp</span>
	    
<span class="n">cd</span> <span class="o">../../</span><span class="n">Makefiles</span><span class="p">;</span> 
</pre></div>
</div>
<p>|Switch|Description|
|  —  |  —  |
|–include=&lt;string&gt;|Specify compile-time include directory (zero or more).|
|–verbose|-v|Verbose output of the AI Engine compiler emits compiler messages at various stages of compilation. These debug and tracing logs provide useful messages on the compilation process.|
|–log-level=&lt;int&gt;|Log level for verbose logging (default=1).|
|–workdir=&lt;string&gt;|By default, the compiler writes all outputs to a sub-directory of the current directory, called Work. Use this option to specify a different output directory.|</p>
<p>The following is a description of the output objects that results from executing the AI Engine compiler (<code class="docutils literal notranslate"><span class="pre">aiecompiler</span></code>) command</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Inputs Sources</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>design/aie_src/graph.cpp</td>
<td>Defines the LeNet graph object.</td>
</tr>
</tbody>
</table><table border="1" class="docutils">
<thead>
<tr>
<th>Output Objects</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>build/libadf.a</td>
<td>Compiled AI Engine design graph</td>
</tr>
<tr>
<td>build/Work/</td>
<td>Directory that contains all outputs of the AI Engine compiler.</td>
</tr>
</tbody>
</table> </details><details>
  <summary>make xclbin: Use Vitis Tools to Link AI Engine and HLS Kernels with the Platform</summary> </div>
<div class="section" id="make-xclbin-use-vitis-tools-to-link-ai-engine-and-hls-kernels-with-the-platform">
<h2>make xclbin: Use Vitis Tools to Link AI Engine and HLS Kernels with the Platform<a class="headerlink" href="#make-xclbin-use-vitis-tools-to-link-ai-engine-and-hls-kernels-with-the-platform" title="Permalink to this heading">¶</a></h2>
<p>After the AI Engine kernels and graph and PL HLS kernels have been compiled, you can use the Vitis compiler to link them with the platform to generate both an XCLBIN and a new XSA file.</p>
</div>
<div class="section" id="platform">
<h2>Platform<a class="headerlink" href="#platform" title="Permalink to this heading">¶</a></h2>
<p>The Vitis tools allow you to integrate the AI Engine, HLS, and RTL kernels into an existing extensible platform. This is an automated step from a software developer perspective where the platform chosen is provided by the hardware designer (or you can opt to use one of the many extensible base platforms provided by Xilinx and the Vitis tools build the hardware design and integrate the AI Engine and PL kernels into the design.</p>
<p>To test this feature in this tutorial, use the base VCK190 platform to build the design.</p>
<p>The command to run this step is shown as follows (default TARGET=hw_emu):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">xclbin</span>
</pre></div>
</div>
<p>The expanded command is as follow:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="o">../</span><span class="n">build</span><span class="o">/</span><span class="n">hw_emu</span><span class="p">;</span>

<span class="n">v</span><span class="o">++</span>       <span class="o">-</span><span class="n">l</span>                                                \
          <span class="o">--</span><span class="n">platform</span> <span class="n">xilinx_vck190_es1_base_202020_1</span>        \
          <span class="o">--</span><span class="n">save</span><span class="o">-</span><span class="n">temps</span>                                      \
	  <span class="o">--</span><span class="n">temp_dir</span> <span class="n">_x</span>	                                    \
          <span class="o">--</span><span class="n">verbose</span>                                         \
	  <span class="o">--</span><span class="n">g</span>                                               \
          <span class="o">--</span><span class="n">config</span> <span class="n">system</span><span class="o">.</span><span class="n">cfg</span>                               \
	  <span class="o">-</span><span class="n">t</span> <span class="n">hw_emu</span>                                         \
          <span class="n">dma_hls</span><span class="o">.</span><span class="n">hw_emu</span><span class="o">.</span><span class="n">xo</span>                                 \	  
          <span class="o">../../</span><span class="n">design</span><span class="o">/</span><span class="n">pl_src</span><span class="o">/</span><span class="n">lenet_kernel</span><span class="o">/</span><span class="n">lenet_kernel</span><span class="o">.</span><span class="n">xo</span>  \
          <span class="o">../</span><span class="n">build</span><span class="o">/</span><span class="n">libadf</span><span class="o">.</span><span class="n">a</span>                             \
          <span class="o">-</span><span class="n">o</span> <span class="n">vck190_aie_lenet</span><span class="o">.</span><span class="n">hw_emu</span><span class="o">.</span><span class="n">xclbin</span>   
	  
<span class="n">cd</span> <span class="o">../../</span><span class="n">Makefiles</span><span class="p">;</span> 
 
</pre></div>
</div>
<p>The options to run this step are as follows:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Switch</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>--platform | -f</td>
<td>Specifies the name of a supported acceleration platform as specified by the $PLATFORM_REPO_PATHS environment variable or the full path to the platform XPFM file.</td>
</tr>
<tr>
<td>--save-temps | -s</td>
<td>Directs the V++ command to save intermediate files/directories created during the compilation and link process. Use the <code>--temp_dir</code> option to specify a location to write the intermediate files to.</td>
</tr>
<tr>
<td>--temp_dir <string></td>
<td>This allows you to manage the location where the tool writes temporary files created during the build process. The temporary results are written by the Vitis compiler, and then removed, unless the <code>--save-temps</code> option is also specified.</td>
</tr>
<tr>
<td>--verbose</td>
<td>Display verbose/debug information.</td>
</tr>
<tr>
<td>--config <config_file></td>
<td>Specifies a configuration file containing V++ switches.</td>
</tr>
<tr>
<td>--output | -o</td>
<td>Specifies the name of the output file generated by the V++ command. In this design the outputs of the DMA HLS kernels and the PL kernels interfacing with the AI Engine are in XO files.</td>
</tr>
</tbody>
</table><p>The information to tell the linker how to connect the AI Engine and PL kernels together is described in a configuration file <code class="docutils literal notranslate"><span class="pre">system.cfg</span></code>. The file describes the overall connection scheme of the system.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">connectivity</span><span class="p">]</span>
<span class="n">nk</span><span class="o">=</span><span class="n">dma_hls</span><span class="p">:</span><span class="mi">1</span><span class="p">:</span><span class="n">dma_hls</span>
<span class="n">nk</span><span class="o">=</span><span class="n">lenet_kernel_1_0</span><span class="p">:</span><span class="mi">1</span><span class="p">:</span><span class="n">lenet_kernel</span>
<span class="n">stream_connect</span><span class="o">=</span><span class="n">dma_hls</span><span class="o">.</span><span class="n">strm_out</span><span class="p">:</span><span class="n">lenet_kernel</span><span class="o">.</span><span class="n">s_axis_ipr</span>
<span class="n">stream_connect</span><span class="o">=</span><span class="n">lenet_kernel</span><span class="o">.</span><span class="n">m_axis_ipr</span><span class="p">:</span><span class="n">ai_engine_0</span><span class="o">.</span><span class="n">prod_in1</span>
<span class="n">stream_connect</span><span class="o">=</span><span class="n">lenet_kernel</span><span class="o">.</span><span class="n">m_axis_m1r1</span><span class="p">:</span><span class="n">ai_engine_0</span><span class="o">.</span><span class="n">prod_in3</span>
<span class="n">stream_connect</span><span class="o">=</span><span class="n">lenet_kernel</span><span class="o">.</span><span class="n">m_axis_m2r2_0</span><span class="p">:</span><span class="n">ai_engine_0</span><span class="o">.</span><span class="n">prod_in5</span>
<span class="n">stream_connect</span><span class="o">=</span><span class="n">lenet_kernel</span><span class="o">.</span><span class="n">m_axis_m2r2_1</span><span class="p">:</span><span class="n">ai_engine_0</span><span class="o">.</span><span class="n">prod_in7</span>

<span class="n">stream_connect</span><span class="o">=</span><span class="n">ai_engine_0</span><span class="o">.</span><span class="n">prod_out1</span><span class="p">:</span><span class="n">lenet_kernel</span><span class="o">.</span><span class="n">s_axis_m1r1</span>
<span class="n">stream_connect</span><span class="o">=</span><span class="n">ai_engine_0</span><span class="o">.</span><span class="n">prod_out2</span><span class="p">:</span><span class="n">lenet_kernel</span><span class="o">.</span><span class="n">s_axis_m2r2</span>
<span class="n">stream_connect</span><span class="o">=</span><span class="n">ai_engine_0</span><span class="o">.</span><span class="n">prod_out3</span><span class="p">:</span><span class="n">dma_hls</span><span class="o">.</span><span class="n">strm_in</span>
<span class="p">[</span><span class="n">advanced</span><span class="p">]</span>
<span class="n">param</span><span class="o">=</span><span class="n">hw_em</span><span class="o">.</span><span class="n">enableProfiling</span><span class="o">=</span><span class="n">false</span>
<span class="n">param</span><span class="o">=</span><span class="n">compiler</span><span class="o">.</span><span class="n">addOutputTypes</span><span class="o">=</span><span class="n">hw_export</span>
</pre></div>
</div>
<table border="1" class="docutils">
<thead>
<tr>
<th>Switch</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr>
<td>--connectivity.nk</td>
<td>Number of kernels. <code>mm2s:2:mm2s_0.mm2s_1</code> means that the Vitis compiler should instantiate two MM2S kernels and name those instances 'mm2s_0' and 'mm2s_1'.</td>
</tr>
<tr>
<td>--connectivity.stream_connect</td>
<td>How the kernels will connect to IPs, platforms, or other kernels. The output of the AI Engine compiler tell you the interfaces that need to be connected. <code>mm2s_0.s:ai_engine_0.lte_0</code> means that the Vitis compiler should connect the port 's' of 'mm2s' to the port 'lte_0' of AI Engine port 0. The name of the AI Engine port is one that has been defined in <code>graph.cpp</code> PLIO instantiation.</td>
</tr>
<tr>
<td>param=compiler.addOutputTypes=hw_export</td>
<td>This option tells the Vitis compiler that besides creating an XCLBIN file, it also outputs an XSA file which is needed to create a post-Vivado fixed platform for Vitis software developement.</td>
</tr>
</tbody>
</table><p>Note that the Vitis compiler calls Vivado® IP integrator under the hood to build the design. The platform and kernels are input to the Vivado Design Suite, which produces a simulation XSA or an XSA after running place and route on the design. The point at which the XSA is produced from Vivado is dependent on what <code class="docutils literal notranslate"><span class="pre">-target</span></code> option is set on the the Vitis compiler command line.</p>
<p>Note that you can now view the Vivado project, which is located in the <code class="docutils literal notranslate"><span class="pre">build/[hw|hw_emu]/\_x/link/vivado/vpl/prj</span></code> directory.</p>
<p>Now you have generated the XCLBIN file that will be used to execute your design on the platform.</p>
 </details>  <details>
  <summary>make application: Compile the Host Application</summary> </div>
<div class="section" id="make-application-compile-the-host-application">
<h2>make application: Compile the Host Application<a class="headerlink" href="#make-application-compile-the-host-application" title="Permalink to this heading">¶</a></h2>
<p>You can compile the host application by following the typical cross-compilation flow for the Cortex-A72. To build the application run the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">application</span>
</pre></div>
</div>
<p>or</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>aarch64-linux-gnu-g++   -O							\
                        -c							\
			-D__linux__                         			\
			--sysroot=$(PLATFORM_REPO_PATHS)/sw/versal/xilinx-versal-common-v2020.2/sysroots/aarch64-xilinx-linux \
			-DXAIE_DEBUG						\
                        -I $(PLATFORM_REPO_PATHS)/sw/versal/xilinx-versal-common-v2020.2/sysroots/aarch64-xilinx-linux/usr/include/xrt \
			-I $(XILINX_VITIS_AIETOOLS)/include                     \
			-I $(PLATFORM_REPO_PATHS)/sw/versal/xilinx-versal-common-v2020.2/sysroots/aarch64-xilinx-linux/usr/include \
			-I $(PLATFORM_REPO_PATHS)/sw/versal/xilinx-versal-common-v2020.2/sysroots/aarch64-xilinx-linux/usr/lib \
			../build//Work/ps/c_rts/aie_control_xrt.cpp   \
			-o ../build/app_control.o                   
			
aarch64-linux-gnu-g++   -O							\
                        -c							\
			-D__linux__                         			\
			--sysroot=$(PLATFORM_REPO_PATHS)/sw/versal/xilinx-versal-common-v2020.2/sysroots/aarch64-xilinx-linux \
			-DXAIE_DEBUG						\
                        -I $(PLATFORM_REPO_PATHS)/sw/versal/xilinx-versal-common-v2020.2/sysroots/aarch64-xilinx-linux/usr/include/xrt \
			-I $(XILINX_VITIS_AIETOOLS)/include                     \
			-I $(PLATFORM_REPO_PATHS)/sw/versal/xilinx-versal-common-v2020.2/sysroots/aarch64-xilinx-linux/usr/include \
			-I $(PLATFORM_REPO_PATHS)/sw/versal/xilinx-versal-common-v2020.2/sysroots/aarch64-xilinx-linux/usr/lib \
			../design/aie_src/main.cpp                              \
			-o ../build/lenet_app.o                    

aarch64-linux-gnu-g++   ../build/app_control.o			                \
			../build/lenet_app.o			                \
			--sysroot=$(PLATFORM_REPO_PATHS)/sw/versal/xilinx-versal-common-v2020.2/sysroots/aarch64-xilinx-linux \
			-L$(PLATFORM_REPO_PATHS)/sw/versal/xilinx-versal-common-v2020.2/sysroots/aarch64-xilinx-linux/usr/lib\ 
                        -L$(XILINX_VITIS_AIETOOLS)/lib/aarch64.o    		\
                        -L$(XILINX_VITIS_AIETOOLS)/lib/lnx64.o       		\
                        -ladf_api_xrt                      		        \
                        -lxrt_coreutil                          		\
                        -std=c++14                          		        \
			-o ../build/lenet_xrt.elf 
			
cd ../../Makefiles; 
</pre></div>
</div>
<p>|Switch|Description|
|  —  |  —  |
|-O | Optimize.| Optimizing compilation takes somewhat more time, and a lot more memory for a large function. With -O, the compiler tries to reduce code size and execution time, without performing any optimizations that take a great deal of compilation time.|
|-D__linux__|
|-DXAIE_DEBUG|Enable debug interface capabilities where certain core status, event status, or stack trace can be dumped out.|
|-I &lt;dir&gt;|Add the directory <code class="docutils literal notranslate"><span class="pre">dir</span></code> to the list of directories to be searched for header files.|
|-o &lt;file&gt;|Place output in file <code class="docutils literal notranslate"><span class="pre">&lt;file&gt;</span></code>. This applies regardless of the output being produced, whether it be an executable file, an object file, an assembler file or preprocessed C code.|
|–sysroot=&lt;dir&gt;|Use <code class="docutils literal notranslate"><span class="pre">dir</span></code> as the logical root directory for headers and libraries. For example, if the compiler would normally search for headers in <code class="docutils literal notranslate"><span class="pre">/usr/include</span></code> and libraries in <code class="docutils literal notranslate"><span class="pre">/usr/lib</span></code>, it will instead search <code class="docutils literal notranslate"><span class="pre">dir/usr/include</span></code> and <code class="docutils literal notranslate"><span class="pre">dir/usr/lib</span></code>.|
|-l&lt;library&gt;|Search the library named <code class="docutils literal notranslate"><span class="pre">library</span></code> when linking. The LeNet tutorial requires <code class="docutils literal notranslate"><span class="pre">adf_api</span></code>, <code class="docutils literal notranslate"><span class="pre">xrt_coreutil</span></code>, <code class="docutils literal notranslate"><span class="pre">xrt_core</span></code>, <code class="docutils literal notranslate"><span class="pre">aiengine</span></code>, <code class="docutils literal notranslate"><span class="pre">metal</span></code>, <code class="docutils literal notranslate"><span class="pre">open_amp</span></code> libraries.|
|-L &lt;dir&gt;|Add directory <code class="docutils literal notranslate"><span class="pre">&lt;dir&gt;</span></code> to the list of directories to be searched for -l.|</p>
<p>The following is a description of the input sources compiled by the AI Engine compiler command.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Inputs Sources</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>design/aie_src/main.cpp</td>
<td>Source application file for the <code>lenet_xrt.elf</code> that will run on an A72 processor.</td>
</tr>
<tr>
<td>build/Work/ps/c_rts/aie_control_xrt.cpp</td>
<td>This is the AI Engine control code generated implementing the graph APIs for the Lenet graph.</td>
</tr>
</tbody>
</table><p>The following is a description of the output objects that results from executing the AI Engine compiler command with the above inputs and options.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Output Objects</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>build/lenet_xrt.elf</td>
<td>The executable that will run on an A72 processor.</td>
</tr>
<tr>
<td></details></td>
<td></td>
</tr>
</tbody>
</table><details>
  <summary>make package: Package the Design</summary> </div>
<div class="section" id="make-package-package-the-design">
<h2>make package: Package the Design<a class="headerlink" href="#make-package-package-the-design" title="Permalink to this heading">¶</a></h2>
<p>With the AI Engine outputs created, as well as the new platform, you can now generate the Programmable Device Image (PDI) and a package to be used on an SD card. The PDI contains all executables, bitstreams, configurations of the device. The packaged SD card directory contains everything to boot Linux, the generated applications and <code class="docutils literal notranslate"><span class="pre">.xclbin</span></code>.</p>
<p>The command to run this step is as follows (default TARGET=hw_emu:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">package</span>
</pre></div>
</div>
<p>or</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
v++	-p  							\
 	-t hw_emu					        \
	--save-temps						\
	--temp_dir ../build/hw_emu/_x			        \
	-f xilinx_vck190_es1_base_202020_1			\
	--package.sd_dir $(PLATFORM_REPO_PATHS)/sw/versal/xrt 	\
	--package.rootfs $(PLATFORM_REPO_PATHS)/sw/versal/xilinx-versal-common-v2020.2/rootfs.ext4 \
	--package.kernel_image $(PLATFORM_REPO_PATHS)/sw/versal/xilinx-versal-common-v2020.2/Image \
	--package.boot_mode=sd					\
	--package.out_dir ../build/hw_emu/package	        \
	--package.sd_dir ../design/aie_src/data	                \
	--package.image_format=ext4				\
	--package.sd_file ../build/lenet_xrt.elf ../build/hw_emu/vck190_aie_lenet.hw_emu.xclbin ../build/libadf.a \
	--package.defer_aie_run
	
cd ../../Makefiles; 
</pre></div>
</div>
<p>|Switch|Description|
|  —  |  —  |
|–target | -t [hw|hw_emu]|Specifies the build target.|
|–package | -p|Packages the final product at the end of the Vitis compile and link build process.|
|–package.rootfs &lt;arg&gt;|Where &lt;arg&gt; specifies the absolute or relative path to a processed Linux root file system file. The platform RootFS file is available for download from xilinx.com. Refer to the Vitis Software Platform Installation for more information.|
|–package.kernel_image &lt;arg&gt;|Where &lt;arg&gt; specifies the absolute or relative path to a Linux kernel image file. Overrides the existing image available in the platform. The platform image file is available for download from xilinx.com. Refer to the Vitis Software Platform Installation for more information.|
|–package.boot_mode &lt;arg&gt;|Where &lt;arg&gt; specifies &lt;ospi|qspi|sd&gt; Boot mode used for running the application in emulation or on hardware.|
|–package.image_format|Where &lt;arg&gt; specifies &lt;ext4|fat32&gt; output image file format. <code class="docutils literal notranslate"><span class="pre">ext4</span></code>: Linux file system and <code class="docutils literal notranslate"><span class="pre">fat32</span></code>: Windows file system|
|–package.sd_file|Where &lt;arg&gt; specifies an ELF or other data file to package into the <code class="docutils literal notranslate"><span class="pre">sd_card</span></code> directory/image. This option can be used repeatedly to specify multiple files to add to the <code class="docutils literal notranslate"><span class="pre">sd_card</span></code>.|
|–package.defer_aie_run| Load the AI Engine application with the ELF file, but wait to run it until graph run directs it. Required in PS based AI Engine flow.|</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Inputs Sources</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>$(PLATFORM_REPO_PATHS)/sw/versal/xrt</td>
<td>The PS Host Application needs the XRT headers in this folder to execute.</td>
</tr>
<tr>
<td>$(PLATFORM_REPO_PATHS)/sw/versal/xilinx-versal-common-v2020.2/rootfs.ext4</td>
<td>The Root Filesystem file for Petalinux.</td>
</tr>
<tr>
<td>$(PLATFORM_REPO_PATHS)/sw/versal/xilinx-versal-common-v2020.2/Image</td>
<td>The pre-built Petalinux Image the processor boots from.</td>
</tr>
<tr>
<td>design/aie_src/data</td>
<td>The data folder that contains the input data stored in DDR memory. It also contains the output golden refernece data the PS Host Application uses to verify the output data from the AI Engine.</td>
</tr>
<tr>
<td>build/hw_emu/lenet_xrt.elf</td>
<td>The PS Host Application executabled created in the <code>make application</code> step.</td>
</tr>
<tr>
<td>build/hw_emu/vck190_aie_lenet.hw_emu.xclbin</td>
<td>The XCLBIN file created in the <code>make xclbin</code> step.</td>
</tr>
<tr>
<td>build/libadf.a</td>
<td>The compiled AI Engine design graph created in the <code>make graph</code> step.</td>
</tr>
</tbody>
</table><p>The output of the V++ Package step is the package directory that contains the contents to run hardware emulation.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Output Objects</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>build/hw_emu/package</td>
<td>The hardware emulation package that contains the boot file, hardware emulation launch script, the PLM and PMC boot files, the PMC and QEMU command argument specification files, and the Vivado simulation folder.</td>
</tr>
</tbody>
</table></details><details>
  <summary>make run_emu: Run Hardware Emulation</summary></div>
<div class="section" id="make-run-emu-run-hardware-emulation">
<h2>make run_emu: Run Hardware Emulation<a class="headerlink" href="#make-run-emu-run-hardware-emulation" title="Permalink to this heading">¶</a></h2>
<p>After packaging, everything is set to run emulation on hardware. To run emulation use the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">run_emu</span>
</pre></div>
</div>
<p>or</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="o">../</span><span class="n">build</span><span class="o">/</span><span class="n">hw_emu</span><span class="o">/</span><span class="n">package</span>
<span class="o">./</span><span class="n">launch_hw_emu</span><span class="o">.</span><span class="n">sh</span> 
</pre></div>
</div>
<p>When launched, you will see the QEMU simulator load. Wait for the autoboot countdown to go to zero, and after a few minutes, you will see the root Linux prompt come up:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>root@versal-rootfs-common-2020_2:~#
</pre></div>
</div>
<p>In some cases, the following error may come up on the screen</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">root</span><span class="nd">@versal</span><span class="o">-</span><span class="n">rootfs</span><span class="o">-</span><span class="n">common</span><span class="o">-</span><span class="mi">2020_2</span><span class="p">:</span><span class="o">~</span><span class="c1"># xinit: giving up</span>
<span class="n">xinit</span><span class="p">:</span> <span class="n">unable</span> <span class="n">to</span> <span class="n">connect</span> <span class="n">to</span> <span class="n">X</span> <span class="n">server</span><span class="p">:</span> <span class="n">Connection</span> <span class="n">refused</span>
<span class="n">xinit</span><span class="p">:</span> <span class="n">server</span> <span class="n">error</span>
<span class="n">Enabling</span> <span class="n">notebook</span> <span class="n">extension</span> <span class="n">jupyter</span><span class="o">-</span><span class="n">js</span><span class="o">-</span><span class="n">widgets</span><span class="o">/</span><span class="n">extension</span><span class="o">...</span>
      <span class="o">-</span> <span class="n">Validating</span><span class="p">:</span> <span class="n">OK</span>
<span class="p">[</span><span class="n">C</span> <span class="mi">13</span><span class="p">:</span><span class="mi">46</span><span class="p">:</span><span class="mf">09.233</span> <span class="n">NotebookApp</span><span class="p">]</span> <span class="n">Bad</span> <span class="n">config</span> <span class="n">encountered</span> <span class="n">during</span> <span class="n">initialization</span><span class="p">:</span>
<span class="p">[</span><span class="n">C</span> <span class="mi">13</span><span class="p">:</span><span class="mi">46</span><span class="p">:</span><span class="mf">09.239</span> <span class="n">NotebookApp</span><span class="p">]</span> <span class="n">No</span> <span class="n">such</span> <span class="n">notebook</span> <span class="nb">dir</span><span class="p">:</span> <span class="s1">&#39;&#39;</span><span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">share</span><span class="o">/</span><span class="n">example</span><span class="o">-</span><span class="n">notebooks</span><span class="s1">&#39;&#39;</span>
</pre></div>
</div>
<p>The error can be neglected, press <enter> to return to the root prompt</p>
<p>After the root prompt comes up, run the following commands to run the design:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="o">/</span><span class="n">mnt</span><span class="o">/</span><span class="n">sd</span><span class="o">-</span><span class="n">mmcblk0p1</span>
<span class="n">export</span> <span class="n">XLC_EMULATION_MODE</span><span class="o">=</span><span class="n">hw_emu</span>
<span class="n">export</span> <span class="n">XILINX_XRT</span><span class="o">=/</span><span class="n">usr</span>
<span class="o">./</span><span class="n">lenet_xrt</span><span class="o">.</span><span class="n">elf</span> <span class="n">a</span><span class="o">.</span><span class="n">xclbin</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">lenet_xrt.elf</span></code> should execute, and after a few minutes, you should see the output with <em>TEST PASSED</em> on the console. When this is shown, run the following keyboard command to exit the QEMU instance:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#To exit QEMU Simulation</span>
<span class="n">Press</span> <span class="n">CtrlA</span><span class="p">,</span> <span class="n">let</span> <span class="n">go</span> <span class="n">of</span> <span class="n">the</span> <span class="n">keyboard</span><span class="p">,</span> <span class="ow">and</span> <span class="n">then</span> <span class="n">press</span> <span class="n">x</span> 
</pre></div>
</div>
</details><details>
  <summary>TARGET=hw: Run on Hardware</summary> </div>
<div class="section" id="target-hw-run-on-hardware">
<h2>TARGET=hw: Run on Hardware<a class="headerlink" href="#target-hw-run-on-hardware" title="Permalink to this heading">¶</a></h2>
<p>To run your design on hardware, re-run the following steps with TARGET=hw</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">kernels</span> <span class="n">TARGET</span><span class="o">=</span><span class="n">hw</span>
<span class="n">make</span> <span class="n">xclbin</span> <span class="n">TARGET</span><span class="o">=</span><span class="n">hw</span>
<span class="n">make</span> <span class="n">package</span> <span class="n">TARGET</span><span class="o">=</span><span class="n">hw</span> 
</pre></div>
</div>
<p>These command create a <code class="docutils literal notranslate"><span class="pre">build/hw</span></code> folder with the kernels, <code class="docutils literal notranslate"><span class="pre">xclbin</span></code>, and <code class="docutils literal notranslate"><span class="pre">package</span></code> for a hardware run.</p>
<p>Now follow <strong>Steps 1-9</strong> to run the <code class="docutils literal notranslate"><span class="pre">lenet_xrt.elf</span></code> excutable on your VCK190 board.</p>
<p><strong>Step 1.</strong> Ensure your board is powered off.</p>
<p><strong>Step 2.</strong> Use an SD card writer (such as balenaEtcher) to flash the <code class="docutils literal notranslate"><span class="pre">sd_card.img</span></code> file an SD card.</p>
<p><strong>Step 3.</strong> Plug the flashed SD card into the top slot of the VCK190 board.</p>
<p><strong>Step 4.</strong> Set the switch SW1 Mode[3:0]=1110 = OFF OFF OFF ON</p>
<p><strong>Step 5.</strong> Connect your computer to the VCK190 board using the included USB cable.</p>
<p><strong>Step 6.</strong> Open a TeraTerm terminal and select the correct COM port. Set the port settings to the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Port</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">COMMXX</span><span class="o">&gt;</span>
<span class="n">Speed</span><span class="p">:</span> <span class="mi">115200</span>
<span class="n">Data</span><span class="p">:</span> <span class="mi">8</span> <span class="n">bit</span>
<span class="n">Parity</span><span class="p">:</span> <span class="n">none</span>
<span class="n">Stop</span> <span class="n">Bits</span><span class="p">:</span> <span class="mi">1</span> <span class="n">bit</span>
<span class="n">Flow</span> <span class="n">control</span><span class="p">:</span> <span class="n">none</span>
<span class="n">Transmit</span> <span class="n">delay</span><span class="p">:</span> <span class="mi">0</span> <span class="n">msec</span><span class="o">/</span><span class="n">char</span> <span class="mi">0</span> <span class="n">msec</span><span class="o">/</span><span class="n">line</span>
</pre></div>
</div>
<p><strong>Step 7.</strong> Power on the board.</p>
<p><strong>Step 8.</strong> Wait until you see the <code class="docutils literal notranslate"><span class="pre">root&#64;versal-rootfs-common-2020_2</span></code> Linux command prompt. Press enter a few times to get past any <code class="docutils literal notranslate"><span class="pre">xinit</span></code> errors.</p>
<p><strong>Step 9.</strong> Run the following commands into the TeraTerm terminal:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="o">/</span><span class="n">mnt</span><span class="o">/</span><span class="n">sd</span><span class="o">-</span><span class="n">mmcblk0p1</span>
<span class="n">export</span> <span class="n">XILINX_XRT</span><span class="o">=/</span><span class="n">usr</span>
<span class="o">./</span><span class="n">lenet_xrt</span><span class="o">.</span><span class="n">elf</span> <span class="n">a</span><span class="o">.</span><span class="n">xclbin</span>
</pre></div>
</div>
</details></div>
</div>
<div class="section" id="hardware-design-details">
<h1>Hardware Design Details<a class="headerlink" href="#hardware-design-details" title="Permalink to this heading">¶</a></h1>
<details>
  <summary>LeNet Architecture and AI Engine/PL Function Partitioning</summary><div class="section" id="lenet-architecture-and-ai-engine-pl-function-partitioning">
<h2>LeNet Architecture and AI Engine/PL Function Partitioning<a class="headerlink" href="#lenet-architecture-and-ai-engine-pl-function-partitioning" title="Permalink to this heading">¶</a></h2>
<p>The architecture of the LeNet design is show in the following figure. The details of the individual layers and their implementation will be described in a later section. This design provides an illustration of the functional partitioning between the AI Engine and PL resources, as shown in the block diagram previously. The input rearrange, maxpooling, and rearrange are scalar byte operations and interact with read/write memories to ensure sustained throughput. This set of operations are suitable to be implemented in PL rather than in the AI Engine array. With appropriate data rearrangement, the computation in the convolutional layers are presented as matrix multiplications and they are optimized to be implemented in the AI Engine array.</p>
<p><img alt="Image of LeNet Architecture" src="../../../../_images/Lenet_architecture.PNG" /></p>
</details><details>
  <summary>Design Platform Details</summary></div>
<div class="section" id="design-platform-details">
<h2>Design Platform Details<a class="headerlink" href="#design-platform-details" title="Permalink to this heading">¶</a></h2>
<p>In the base platform, the CIPS, NoC and AI Engine are instantiated and interfaces among them are created. To add the various functions in a system level design, PL kernels are added to the base platform depending on the application developed, that is, the PL kernels present in each design might vary.  An ADF graph is connected to an extensible Vitis platform where the graph I/Os are connected either to the platform ports or to ports on Vitis kernels through the V++ connectivity directives.
For this design, the components are added by v++ -l step (make XCLBIN in the tool flow section above) and include the following:</p>
<ul class="simple">
<li><p>AI Engine kernel <code class="docutils literal notranslate"><span class="pre">graph.o</span></code></p></li>
<li><p>data mover kernel (<code class="docutils literal notranslate"><span class="pre">dma_hls.[hw|hw_emu].xo</span></code>)</p></li>
<li><p>lenet kernel (<code class="docutils literal notranslate"><span class="pre">lenet_kernel.xo</span></code>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ai_engine_system</span></code> block which includes the data width converter and clock converter kernels</p></li>
<li><p>any other necessary connections and interfaces</p></li>
</ul>
<p>To see a schematic view of the design with the extended platform (as shown in the following figure), open in the Vivado  <code class="docutils literal notranslate"><span class="pre">build/[hw|hw_emu]/_x/link/vivado/vpl/prj/prj.xpr</span></code> folder.</p>
<p><img alt="Image of Lenet Block Schematic" src="../../../../_images/Lenet_sch.PNG" /></p>
</details><details>
	<summary>AI Engine and PL Kernel details</summary></div>
<div class="section" id="ai-engine-and-pl-kernel-details">
<h2>AI Engine and PL Kernel Details<a class="headerlink" href="#ai-engine-and-pl-kernel-details" title="Permalink to this heading">¶</a></h2>
<p>The design implements the LeNet CNN to perform digital classification on gray scale images. The AI Engine kernels have been covered in the Tutorial Overview section above and more details will be provided in Software Design Details section.</p>
<p>The PL kernels perform the following functions:</p>
<ul class="simple">
<li><p>loading input images of LeNet into block RAMs through the AXI interfaces</p></li>
<li><p>moving and rearranging data from one AI Engine to another.</p></li>
</ul>
<p>The AI Engine kernels are mainly used to perform matrix multiplication due to their high INT8 MAC performance.</p>
<p>Most of the data processing function is handled in the PL kernel, <code class="docutils literal notranslate"><span class="pre">lenet_kernel</span></code> which comes pre-compiled and contains the following
modules.</p>
<p><strong>Input Rearrange (IPR)</strong></p>
<p>The LeNet algorithm in this design starts with an image of size 28x28 input imported from DDR memory through the NoC. An input rearrange function is implemented in PL to arrange pixels from the input according to a 5x5 convolution kernel and pad with seven zeros to form 32 pixels to form a 576x32 matrix. The matrix is sent to the first AI Engine tile (Conv1) via AXI4-Stream to perform matrix multiplication.</p>
<p><strong>Max Pool and Data Rearrangement set 1 (M1R1)</strong></p>
<p>Pooling is the operation in CNN to enable the detection of the object when presented with different versions of the images by reducing the size of the feature map. Among the types of pooling, the max is chosen to account for distortion.
In this design, the output from the first AI Engine tile (core01) is a 576x8 matrix, which is sent to PL. Each of the columns in the matrix correspond to a 24x24 dimensional image laid out in the row major format. The network being implemented has only six output features for the Conv1 layers and hence two of the eight columns do not contain real images. Then a maxpool operation is performed and a value is returned from a 2x2 matrix, as seen in green squares in the following diagram.</p>
<p><img alt="Image of LeNet Maxpool1" src="../../../../_images/Lenet_maxpool1.PNG" /></p>
<p>The resulting 144 x 8 byte matrix, which is stored in RAMB36 module, then goes through a rearrange operation, where the data is written into six RAMB18s populated with zeros in the appropriate positions and the addresses are generated by the fanout table. Each RAMB18 is configured as 2048 x 8 (depth x width). The arrays then go through a second stage or rearrange operation where each array is configured in read mode and 512 x 32. These block RAMS are rearranged to four block RAMS and five register files After the rearrange function, the data is output as six images each of 64 x 25 dimension. The data for the previous image needs to be sent out to memory mapped AXI4 before the writing of the new image starts.</p>
<p>Also in M1R1 are two instances of the AXI2BRAM module, one at the PL-AI Engine interface and another at the AI Engine-PL interfaces. At the PL-AI Engine interface, data is coming into the module in AXI4-stream format from the AI Engine.</p>
<p>The AXI stream supplies a data rate of 128 bits/cycle at 250 MHz and the is written into four 32-bit RAMB 18. A corresponding set of operations is performed at the AI Engine-PL interface.</p>
<p><strong>Max Pool and Data Rearrangement set 2 (M2R2)</strong></p>
<p>This module performs the similar operations of max pooling and data rearrangement to M1R1 but on a smaller set of the feature map. It moves and rearranges data from AI Engine tile, core02, to AI Engine tiles, core03 and core05. The output from the second AI Engine tile, core02, is sent to the PL as 16 images of 8x8 representing the 2D image as a column in a row major order is laid out as an array of 64 x 16 bytes array. Then a maxpool operation is performed and a value is returned from a 2x2 matrix. The results are stored in a register file configured as 16 images of 4x4 bytes which then are rearranged before being sent out using two AXI4-Stream to the two AI Engine tiles, core03 and core05.</p>
<p><strong>Data Mover Kernel</strong></p>
<p>The PL based data mover kernel consist of MM2S and S2MM kernels. This module gets the initial image from DDR memory through the NoC and sends the data to AI Engine tile, core01 (after input processing unit inside <code class="docutils literal notranslate"><span class="pre">lenet_kernel</span></code>). It also receives data from AI Engine tile, core04, and streams out the data to DDR memory through the NoC. The side facing NoC uses a memory mapped AXI4 interface (MM-AXI4) and the side facing the AI Engine array uses an AXI4-Stream interface.</p>
</details><details>
  <summary>Design Implementation</summary></div>
<div class="section" id="design-implementation">
<h2>Design Implementation<a class="headerlink" href="#design-implementation" title="Permalink to this heading">¶</a></h2>
<p>The following table provides details on the design implementation. It includes image dimensions, weight dimensions, and number of features in each layer.</p>
<p><img alt="Image of Lenet Design Implementation" src="../../../../_images/Lenet_implementation.PNG" /></p>
<p>Notes:</p>
<p>[1] One image on 5x5 kernel with bias value of 1</p>
<p>[2] Rearrange2 fanouts to two AI Engine tiles (core03 and core05) to implement the FC1+RELU layer</p>
</details></div>
</div>
<div class="section" id="software-design-details">
<h1>Software Design Details<a class="headerlink" href="#software-design-details" title="Permalink to this heading">¶</a></h1>
<p>The software design in the Lenet tutorial consists of the following sections:</p>
<details>
  <summary>AI Engine Kernels and Graph Representation</summary><div class="section" id="ai-engine-kernels-and-graph-representation">
<h2>AI Engine Kernels and Graph Representation<a class="headerlink" href="#ai-engine-kernels-and-graph-representation" title="Permalink to this heading">¶</a></h2>
<p>An AI Engine kernel is a C/C++ program written using specialized intrinsic calls that target the VLIW vector processor. The AI Engine compiler compiles the kernel code to produce an executable ELF file for each of the AI Engines being used in the design. Review <a class="reference external" href="#ai-engine-documentation">AI Engine Kernel Programming Section in the AI Engine Documentation</a> for a high-level overview of kernel programming. These kernels can be stitched together to function as AI Engine graphs written in C++.
The AI Engine compiler writes a summary of compilation results called <code class="docutils literal notranslate"><span class="pre">lenet.aiecompile_summary</span></code>. You can view the graph by running the following command:</p>
<p><code class="docutils literal notranslate"><span class="pre">vitis_analyzer</span> <span class="pre">build/Work/lenet.aiecompile_summary</span></code></p>
<p>The following figure shows the graph representation of the AI Engine kernels. The five cores correspond to the description shown in the block diagram in the Tutorial Overview section; core01 implements the first convolutional layer, core02 implements the second convolutional layer, core03 and 05 implement FC1 and ReLu, and core04 implements the FC2.</p>
<p><img alt="Image of LeNet AI Engine Graph" src="../../../../_images/Lenet_graph.PNG" /></p>
<p>Note also defined in the AI Engine graph are the weights (<code class="docutils literal notranslate"><span class="pre">core&lt;xx&gt;lut.h</span></code>). The weights are used in the matrix multiplication with the input matrix running in the AI Engine tiles. Whereas the input feature maps (IFMs) are streamed from the PL to the AI Engine, the weights are stored in the AI Engine tiles.</p>
</details><details>
  <summary>Data Flow Graph</summary></div>
<div class="section" id="data-flow-graph">
<h2>Data Flow Graph<a class="headerlink" href="#data-flow-graph" title="Permalink to this heading">¶</a></h2>
<p>This section describes the overall data-flow graph specification of the LeNet design which is compiled by the AI Engine compiler. Refer to <a class="reference external" href="#ai-engine-documentation">AI Engine Programming Section in the AI Engine Documentation</a> for information on ADF graphs.</p>
<p>The overall graph definition of the design is contained in the <code class="docutils literal notranslate"><span class="pre">graph.cpp</span></code> file. The following steps describe the definition of the graph.</p>
<div class="section" id="define-the-graph-class">
<h3>Define the graph class<a class="headerlink" href="#define-the-graph-class" title="Permalink to this heading">¶</a></h3>
<p>Define the LeNet graph glass by using the objects defined in the appropriate name space. It must include the Adaptive Data Flow (ADF) library. All user graphs are derived from the class graph, for example in this design:</p>
<p><code class="docutils literal notranslate"><span class="pre">class</span> <span class="pre">myGraph</span> <span class="pre">:</span> <span class="pre">public</span> <span class="pre">adf::graph</span></code>.</p>
<p>Declare top level ports to the graph:</p>
<p><code class="docutils literal notranslate"><span class="pre">public:</span> <span class="pre">adf::port&lt;output&gt;</span> <span class="pre">out[3];</span> <span class="pre">adf::port&lt;input&gt;</span> <span class="pre">in[4];</span> </code></p>
</div>
<div class="section" id="define-the-graph-constructor">
<h3>Define the Graph Constructor<a class="headerlink" href="#define-the-graph-constructor" title="Permalink to this heading">¶</a></h3>
<p>Use the <code class="docutils literal notranslate"><span class="pre">kernel::create</span></code> function to instantiate the C++ kernel objects, for example:</p>
<p><code class="docutils literal notranslate"><span class="pre">core01</span> <span class="pre">=</span> <span class="pre">adf::kernel::create(core01_top);</span></code></p>
</div>
<div class="section" id="add-connectivity-information">
<h3>Add Connectivity Information<a class="headerlink" href="#add-connectivity-information" title="Permalink to this heading">¶</a></h3>
<p>This is done by using the templated connect&lt;&gt; object. The connection can be window&lt;&gt; or stream. If a window connection is used, then window parameters must be specified.
In this description, ports are referred to by indices. An example of the connection between the input port of the graph and input of an AI Engine kernel is as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">adf</span><span class="p">::</span><span class="n">connect</span><span class="o">&lt;</span> <span class="n">adf</span><span class="p">::</span><span class="n">window</span><span class="o">&lt;</span><span class="n">ROW_A</span> <span class="o">*</span> <span class="n">COL_A</span><span class="o">&gt;</span> <span class="o">&gt;</span> <span class="p">(</span><span class="ow">in</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">core01</span><span class="o">.</span><span class="ow">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
<span class="n">single_buffer</span><span class="p">(</span><span class="ow">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
<span class="n">single_buffer</span><span class="p">(</span><span class="n">core01</span><span class="o">.</span><span class="ow">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
</pre></div>
</div>
<p>In this case, the parameters correspond to the matrix dimension. Single buffer is selected instead of ping-pong buffer to keep the design simple without an impact on performance.</p>
<p>An example of connection of weights already loaded in AI Engine tile is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">adf</span><span class="p">::</span><span class="n">connect</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">core01lut</span><span class="p">,</span><span class="n">core01</span><span class="p">);</span>
</pre></div>
</div>
<p>Based on the datatype of <code class="docutils literal notranslate"><span class="pre">core01lut</span></code>, the API call is inferred as a look up table in the AI Engine tile.</p>
</div>
<div class="section" id="set-the-source-file-and-tile-use">
<h3>Set the Source File and Tile Use<a class="headerlink" href="#set-the-source-file-and-tile-use" title="Permalink to this heading">¶</a></h3>
<p>Set the source file and tile use for each of the kernels, for example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">adf</span><span class="p">::</span><span class="n">source</span><span class="p">(</span><span class="n">core01</span><span class="p">)</span> <span class="o">=</span> <span class="s2">&quot;core01.cc&quot;</span><span class="p">;</span>
<span class="n">adf</span><span class="p">::</span><span class="n">runtime</span><span class="o">&lt;</span><span class="n">ratio</span><span class="o">&gt;</span><span class="p">(</span><span class="n">core01</span><span class="p">)</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">;</span>
</pre></div>
</div>
<p>The source file <code class="docutils literal notranslate"><span class="pre">core01.cc</span></code> contains the source code for core01. The ratio of the function run time compared to the cycle budget, known as the runtime ratio, must be between 0 and 1.</p>
</div>
<div class="section" id="lenet-top-level-application">
<h3>LeNet Top level Application<a class="headerlink" href="#lenet-top-level-application" title="Permalink to this heading">¶</a></h3>
<p>Define a top level application file (<code class="docutils literal notranslate"><span class="pre">graph.cpp</span></code> in this design) that contains an instance of the graph class and connect the graph to a simulation platform to provide file input and output, for example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>adf::PLIO *attr_i1 = new adf::PLIO(&quot;prod_in1&quot;, adf::plio_128_bits, &quot;data/0_1/matA_in_128plio.txt&quot;);
adf::simulation::platform&lt;4,3&gt; platform(attr_i1,attr_i2,attr_i3,attr_i4,attr_o1,attr_o2,attr_o3);`
myGraph g;
adf::connect&lt;&gt; net010(platform.src[0], g.in[0]);
</pre></div>
</div>
<p>The main program is the driver of the graph. It is used to load,execute and terminate the graph. This is done by using the Run Time Graph control API calls, which in this design are:</p>
<div class="highlight-int main(int argc, char ** argv) notranslate"><div class="highlight"><pre><span></span>   {
      g.init();
      g.run();
      g.end();

      return 0;
   }
</pre></div>
</div>
</details><details>
  <summary>PL Kernels</summary></div>
</div>
<div class="section" id="pl-kernels">
<h2>PL Kernels<a class="headerlink" href="#pl-kernels" title="Permalink to this heading">¶</a></h2>
<p>In addition to kernels operating in the AI Engine array, this design specifies two kernels to run on the PL region of the device (written in HLS C++), <code class="docutils literal notranslate"><span class="pre">lenet_kernel</span></code> and <code class="docutils literal notranslate"><span class="pre">dma_hls</span></code>. Note the <code class="docutils literal notranslate"><span class="pre">dma_hls</span></code> kernel is brought into the design during the Vitis kernel compilation whereas the lenet_kernel is only brought in later in the V++ link stage since the kernel is pre-packaged.</p>
<p>The dma_hls kernel is an IP which contains dma_mm2s and dma_s2mm. dma_mm2s reads data from a memory-mapped AXI4 interface and writes it to an AXI4-Stream interface. <code class="docutils literal notranslate"><span class="pre">dma_s2mm</span></code> reads data from an AXI4-Stream interface and writes it to a memory-mapped AXI4 interface. The kernel specifies the following pragmas:</p>
<ul class="simple">
<li><p>#pragma HLS INTERFACE m_axi</p></li>
<li><p>#pragma HLS INTERFACE axis</p></li>
<li><p>#pragma HLS INTERFACE s_axilite</p></li>
<li><p>#pragma HLS PIPELINE II=1</p></li>
<li><p>#pragma HLS DATAFLOW</p></li>
</ul>
</details><details>
  <summary>PS Host Application</summary></div>
<div class="section" id="ps-host-application">
<h2>PS Host Application<a class="headerlink" href="#ps-host-application" title="Permalink to this heading">¶</a></h2>
<p>The LeNet tutorial uses the Embedded processing system (PS) as an external controller to control the AI Engine graph and data mover PL kernels. Review <a class="reference external" href="#ai-engine-documentation">Programming the PS Host Application Section in the AI Engine Documentation</a> to understand the process to create a host application.</p>
<p>In addition to the PS host application (<code class="docutils literal notranslate"><span class="pre">main.cpp</span></code>), the AI Engine control code must also be compiled. This control code (<code class="docutils literal notranslate"><span class="pre">aie_control_xrt.cpp</span></code>) is generated by the AI Engine compiler when compiling the AI Engine design graph and kernel code.
The AI Engine control code is used by the PS host application for the following reasons:</p>
<ul class="simple">
<li><p>Control the initial loading of the AI Engine kernels</p></li>
<li><p>Run the graph for several iterations, update the run time parameters associated with the graph, exit, and reset the AI Engine tiles.</p></li>
</ul>
<p>The PS Host application stack diagram for the LeNet tutorial is shown in the following diagram.</p>
<p><img alt="Alt Text" src="../../../../_images/Lenet_PS_stack_20202.PNG" /></p>
<p>The steps in the tutorial to run the A72 application are described as follows:</p>
<div class="section" id="include-graph-cpp">
<h3>1. Include graph.cpp<a class="headerlink" href="#include-graph-cpp" title="Permalink to this heading">¶</a></h3>
<p>Include the <code class="docutils literal notranslate"><span class="pre">graph.cpp</span></code> AI Engine application file. This file contains the instantiation of the AI Engine LeNet data flow graph object</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#include graph.cpp</span>
</pre></div>
</div>
</div>
<div class="section" id="check-command-line-argument">
<h3>2. Check Command Line Argument<a class="headerlink" href="#check-command-line-argument" title="Permalink to this heading">¶</a></h3>
<p>The beginning of the A72 application is represented by the main function. It takes in one command line argument: an XCLBIN file.</p>
<p><code class="docutils literal notranslate"><span class="pre">int</span> <span class="pre">main(int</span> <span class="pre">argc,</span> <span class="pre">char**</span> <span class="pre">argv)</span></code></p>
</div>
<div class="section" id="open-xclbin-and-create-data-mover-kernel-handles">
<h3>3. Open XCLBIN and Create Data Mover Kernel Handles<a class="headerlink" href="#open-xclbin-and-create-data-mover-kernel-handles" title="Permalink to this heading">¶</a></h3>
<p>The A72 application loads the XCLBIN binary file and creates the data mover kernels to be executed on the device. The steps are:</p>
<ul class="simple">
<li><p>Open device and load xclbin</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">auto</span> <span class="n">dhdl</span> <span class="o">=</span> <span class="n">xrtDeviceOpen</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="n">auto</span> <span class="n">xclbin</span> <span class="o">=</span> <span class="n">load_xclbin</span><span class="p">(</span><span class="n">dhdl</span><span class="p">,</span> <span class="n">xclbinFilename</span><span class="p">);</span>
<span class="n">auto</span> <span class="n">top</span> <span class="o">=</span> <span class="n">reinterpret_cast</span><span class="o">&lt;</span><span class="n">const</span> <span class="n">axlf</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">xclbin</span><span class="o">.</span><span class="n">data</span><span class="p">());</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create the data mover kernel</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">xrtKernelHandle</span> <span class="pre">dmahls_khdl</span> <span class="pre">=</span> <span class="pre">xrtPLKernelOpen(dhdl,</span> <span class="pre">top-&gt;m_header.uuid,</span> <span class="pre">&quot;dma_hls&quot;);</span></code></p>
</div>
<div class="section" id="allocate-buffers-for-input-data-and-results-in-global-memory">
<h3>4. Allocate Buffers for Input Data and Results in Global Memory<a class="headerlink" href="#allocate-buffers-for-input-data-and-results-in-global-memory" title="Permalink to this heading">¶</a></h3>
<p>The A72 application allocates BO (buffer objects) to store input data and output results in global memory (DDR). For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">xrtBufferHandle</span> <span class="n">in_bohdl</span> <span class="o">=</span> <span class="n">xrtBOAlloc</span><span class="p">(</span><span class="n">dhdl</span><span class="p">,</span> <span class="n">input_size_in_bytes</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
<span class="n">auto</span> <span class="n">in_bomapped</span> <span class="o">=</span> <span class="n">reinterpret_cast</span><span class="o">&lt;</span><span class="n">uint32_t</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">xrtBOMap</span><span class="p">(</span><span class="n">in_bohdl</span><span class="p">));</span>
</pre></div>
</div>
<p>Additionally, the <code class="docutils literal notranslate"><span class="pre">memcpy</span></code> and <code class="docutils literal notranslate"><span class="pre">memset</span></code> functions are used to initialize the data in global memory.</p>
</div>
<div class="section" id="open-graph-obtain-handle-and-execute-graph">
<h3>5. Open Graph, Obtain Handle and Execute Graph<a class="headerlink" href="#open-graph-obtain-handle-and-execute-graph" title="Permalink to this heading">¶</a></h3>
<p>The following registration function is added in 2020.2 for XRT to use ADF API callbacks:</p>
<p><code class="docutils literal notranslate"><span class="pre">adf::registerXRT(dhdl,</span> <span class="pre">top-&gt;m_header.uuid);</span></code></p>
<ul class="simple">
<li><p>The A72 processor opens and obtains its handle using the <code class="docutils literal notranslate"> <span class="pre">xrtGraphOpen</span></code> function.</p></li>
<li><p>The A72 processor resets the graph using the <code class="docutils literal notranslate"><span class="pre">xrtGraphReset</span></code> function and runs the LeNet graph execution using the <code class="docutils literal notranslate"><span class="pre">xrtGraphRun</span></code> function.
Note there is no reading or updating of coefficients in the LeNet design.</p></li>
</ul>
</div>
<div class="section" id="execute-the-data-mover-kernels-and-generate-the-output-results">
<h3>6. Execute the Data Mover Kernels and Generate the Output Results<a class="headerlink" href="#execute-the-data-mover-kernels-and-generate-the-output-results" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Open the PL kernels and obtain handles with <code class="docutils literal notranslate"><span class="pre">xrtPLKernelOpen</span></code> function.</p></li>
<li><p>Create kernel handle to start <code class="docutils literal notranslate"><span class="pre">dma_hls</span></code> PL kernel using <code class="docutils literal notranslate"><span class="pre">xrtRunOpen</span></code> function.</p></li>
<li><p>Set the <code class="docutils literal notranslate"><span class="pre">dma_hls</span></code> kernel arguments using <code class="docutils literal notranslate"><span class="pre">xrtRunSetArg</span></code> function.</p></li>
<li><p>Start the <code class="docutils literal notranslate"><span class="pre">dma_hls</span></code> kernels using <code class="docutils literal notranslate"><span class="pre">xrtRunStart</span></code> function.</p></li>
<li><p>Wait for <code class="docutils literal notranslate"><span class="pre">dma_hls</span></code> execution to finish using <code class="docutils literal notranslate"><span class="pre">xrtRunWait</span></code> runction.</p></li>
<li><p>Close the run handles and close opened kernel handles using <code class="docutils literal notranslate"><span class="pre">xrtRunClose</span></code> and <code class="docutils literal notranslate"><span class="pre">xrtKernelClose</span></code>.</p></li>
</ul>
</div>
<div class="section" id="verify-output-results">
<h3>7. Verify Output Results<a class="headerlink" href="#verify-output-results" title="Permalink to this heading">¶</a></h3>
<p>Compare data in <code class="docutils literal notranslate"><span class="pre">out_bomapped</span></code> to golden reference data in <code class="docutils literal notranslate"><span class="pre">golden.h</span></code>.</p>
</div>
<div class="section" id="release-allocated-resources">
<h3>8. Release Allocated Resources<a class="headerlink" href="#release-allocated-resources" title="Permalink to this heading">¶</a></h3>
<p>After post-processing the data, release the allocated objects using <code class="docutils literal notranslate"><span class="pre">xrtBOFree</span></code>, <code class="docutils literal notranslate"><span class="pre">xrtGraphClose</span></code> and <code class="docutils literal notranslate"><span class="pre">xrtDeviceClose</span></code> functions.</p>
</details></details></div>
</div>
</div>
<div class="section" id="references">
<h1>References<a class="headerlink" href="#references" title="Permalink to this heading">¶</a></h1>
<p>The following documents provide supplemental information for this tutorial.</p>
<div class="section" id="ai-engine-documentation">
<h2><a class="reference external" href="https://www.xilinx.com/html_docs/xilinx2020_2/vitis_doc/yii1603912637443.html">AI Engine Documentation</a><a class="headerlink" href="#ai-engine-documentation" title="Permalink to this heading">¶</a></h2>
<p>Contains sections on how to develop AI Engine graphs, how to use the Ai Engine compiler, and AI Engine simulation, and performance analysis.</p>
</div>
<div class="section" id="xilinx-runtime-xrt-architecture">
<h2><a class="reference external" href="https://xilinx.github.io/XRT/master/html/index.html">Xilinx Runtime (XRT) Architecture</a><a class="headerlink" href="#xilinx-runtime-xrt-architecture" title="Permalink to this heading">¶</a></h2>
<p>Below are links to the XRT information used by this tutorial:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://xilinx.github.io/XRT/master/html/index.html">XRT Documentation</a>: Explains general XRT API calls used in the PS Host Application.</p></li>
<li><p><a class="reference external" href="https://github.com/Xilinx/XRT">XRT Github Repo</a>: Contains the XRT source code.</p></li>
<li><p><a class="reference external" href="https://github.com/Xilinx/XRT/blob/master/src/runtime_src/core/include/experimental/xrt_aie.h">XRT AIE API</a>: Documents the AI Engine XRT API calls</p></li>
</ul>
</div>
<div class="section" id="vitis-unified-software-development-platform-2020-2-documentation">
<h2><a class="reference external" href="https://www.xilinx.com/html_docs/xilinx2020_2/vitis_doc/index.html">Vitis Unified Software Development Platform 2020.2 Documentation</a><a class="headerlink" href="#vitis-unified-software-development-platform-2020-2-documentation" title="Permalink to this heading">¶</a></h2>
<p>Below are links to Vitis related information referenced in this tutorial:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.xilinx.com/html_docs/xilinx2020_2/vitis_doc/kme1569523964461.html">Vitis Application Acceleration Development Flow Documentation</a></p></li>
<li><p><a class="reference external" href="https://github.com/Xilinx/Vitis-Tutorials">Vitis Application Acceleration Development Flow Tutorials</a></p></li>
<li><p><a class="reference external" href="https://www.xilinx.com/html_docs/xilinx2020_2/vitis_doc/irn1582730075765.html">Vitis HLS</a></p></li>
</ul>
</div>
</div>
<div class="section" id="revision-history">
<h1>Revision History<a class="headerlink" href="#revision-history" title="Permalink to this heading">¶</a></h1>
<ul class="simple">
<li><p>Dec 2020 - Initial Release</p></li>
</ul>
<p>© Copyright 2020 Xilinx, Inc.</p>
<p>Licensed under the Apache License, Version 2.0 (the “License”);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="n">licenses</span><span class="o">/</span><span class="n">LICENSE</span><span class="o">-</span><span class="mf">2.0</span>
</pre></div>
</div>
<p>Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an “AS IS” BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.</p>
<p align="center"><sup>XD015</sup></p></div>


           </div>
          </div>
          
                  <style>
                        .footer {
                        position: fixed;
                        left: 0;
                        bottom: 0;
                        width: 100%;
                        }
                  </style>
				  
				  <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019-2022, Xilinx, Inc. Xilinx is now a part of AMD.
      <span class="lastupdated">Last updated on August 5, 2022.
      </span></p>
  </div>



										<div class="aem-Grid aem-Grid--16">
											<div class="aem-GridColumn aem-GridColumn--xxxlarge--none aem-GridColumn--xsmall--16 aem-GridColumn--offset--xsmall--0 aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--xsmall--none aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
												<div class="container-fluid sub-footer">

													                    <div class="row">
                        <div class="col-xs-24">
                          <p><a target="_blank" href="https://www.amd.com/en/corporate/copyright">Terms and Conditions</a> | <a target="_blank" href="https://www.amd.com/en/corporate/privacy">Privacy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/cookies">Cookie Policy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/trademarks">Trademarks</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/statement-human-trafficking-forced-labor.pdf">Statement on Forced Labor</a> | <a target="_blank" href="https://www.amd.com/en/corporate/competition">Fair and Open Competition</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/amd-uk-tax-strategy.pdf">UK Tax Strategy</a> | <a target="_blank" href="https://docs.xilinx.com/v/u/9x6YvZKuWyhJId7y7RQQKA">Inclusive Terminology</a> | <a href="#cookiessettings" class="ot-sdk-show-settings">Cookies Settings</a></p>
                        </div>
                    </div>
												</div>
											</div>
										</div>
										
</br>


  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>